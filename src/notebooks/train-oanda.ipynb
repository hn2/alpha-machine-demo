{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0f023857721c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Adds higher directory to python modules path.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaveToDiskOnBestTrainingRewardCallback\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSaveToDiskOnBestTrainingRewardCallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_paths_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_data_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_pf_fx_env_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_train_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mget_agent_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_model_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'common'"
     ]
    }
   ],
   "source": [
    "#   https://stable-baselines3.readthedocs.io/en/master/modules/sac.html\n",
    "#   https://stable-baselines3.readthedocs.io/en/master/modules/td3.html\n",
    "#   https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
    "#   https://github.com/araffin/rl-baselines-zoo\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from os.path import join as path_join\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "from d3rlpy.wrappers.sb3 import to_mdp_dataset\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "sys.path.append(\"..\")  # Adds higher directory to python modules path.\n",
    "\n",
    "from common.SaveToDiskOnBestTrainingRewardCallback import SaveToDiskOnBestTrainingRewardCallback\n",
    "from common.config_utils import get_paths_params, get_data_params, get_pf_fx_env_params, get_train_params, \\\n",
    "    get_agent_params, get_model_params\n",
    "from common.data_utils import prepare_date_train\n",
    "from common.env_utils import create_env\n",
    "from common.forex_utils import get_forex_7, get_forex_12, get_forex_14, get_forex_18, get_forex_28\n",
    "from common.model_utils import get_model_name, get_online_class_and_policy, get_action_noise_class\n",
    "\n",
    "\n",
    "# ONLINE_ALGORITHM = 'TD3'\n",
    "# NUMBER_OF_TRIALS = 100\n",
    "# TOTAL_TIMESTEPS = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(online_algorithm, train_look_back_period, total_timesteps, config_file):\n",
    "    v_market, v_resolution, v_num_of_instruments, v_spread, v_subdir, \\\n",
    "    v_train_test_split = get_data_params(config_file)\n",
    "\n",
    "    if v_num_of_instruments == 4:\n",
    "        v_instruments, v_pip_size, v_pip_spread = get_forex_7(v_spread)\n",
    "    elif v_num_of_instruments == 7:\n",
    "        v_instruments, v_pip_size, v_pip_spread = get_forex_7(v_spread)\n",
    "    elif v_num_of_instruments == 12:\n",
    "        v_instruments, v_pip_size, v_pip_spread = get_forex_12(v_spread)\n",
    "    elif v_num_of_instruments == 14:\n",
    "        v_instruments, v_pip_size, v_pip_spread = get_forex_14(v_spread)\n",
    "    elif v_num_of_instruments == 18:\n",
    "        v_instruments, v_pip_size, v_pip_spread = get_forex_18(v_spread)\n",
    "    elif v_num_of_instruments == 28:\n",
    "        v_instruments, v_pip_size, v_pip_spread = get_forex_28(v_spread)\n",
    "\n",
    "    # v_subdir, v_train_test_split, v_env_verbose, v_model_verbose, v_callback_verbose, v_save_replay_buffer, \\\n",
    "    # v_tensorboard, v_use_callback, v_check_freq, v_callback_lookback, v_save_freq = get_train_params(config_file)\n",
    "\n",
    "    v_data = prepare_date_train(v_subdir, v_market, v_resolution, v_instruments, train_look_back_period,\n",
    "                                v_train_test_split)\n",
    "\n",
    "    # v_data = prepare_data_train(v_market, v_resolution, v_instruments, v_train_look_back_period)\n",
    "\n",
    "    print(f'Data shape:{np.shape(v_data)}')\n",
    "\n",
    "    v_env_lookback_period, v_random_episode_start, v_cash, v_max_slippage_percent, v_lot_size, v_leverage, \\\n",
    "    v_compute_position, v_compute_indicators, v_compute_reward, v_env_verbose = get_pf_fx_env_params(config_file)\n",
    "\n",
    "    v_env = create_env(v_data,\n",
    "                       v_instruments,\n",
    "                       v_env_lookback_period,\n",
    "                       v_random_episode_start,\n",
    "                       v_cash,\n",
    "                       v_max_slippage_percent,\n",
    "                       v_lot_size,\n",
    "                       v_leverage,\n",
    "                       v_pip_size,\n",
    "                       v_pip_spread,\n",
    "                       v_compute_position,\n",
    "                       v_compute_indicators,\n",
    "                       v_compute_reward,\n",
    "                       v_env_verbose)\n",
    "\n",
    "    print(\n",
    "        f'Instruments:{v_instruments}, lookack:{v_env_lookback_period}, random_episode_start:{v_random_episode_start}, cash:{v_cash}, max_slippage_percent:{v_max_slippage_percent}, lot_size:{v_lot_size}, leverage:{v_leverage}, pip_size:{v_pip_size}, pip_spread:{v_pip_spread}, compute_position:{v_compute_position}, compute_indicators:{v_compute_indicators}, compute_reward:{v_compute_reward}, verbose:{v_env_verbose}')\n",
    "\n",
    "    v_model_verbose, v_callback_verbose, v_save_replay_buffer, v_use_tensorboard, v_use_callback, v_check_freq, \\\n",
    "    v_callback_lookback, v_save_freq, v_learning_rate, v_net_arch, v_action_noise, v_noise_sigma, v_use_sde = get_agent_params(\n",
    "        config_file)\n",
    "\n",
    "    v_delimeter, v_model_prefix = get_model_params(config_file)\n",
    "\n",
    "    v_model_name = get_model_name(v_delimeter, v_model_prefix, v_leverage, v_action_noise, v_use_callback,\n",
    "                                  v_random_episode_start, v_instruments, total_timesteps, train_look_back_period,\n",
    "                                  v_env_lookback_period, v_spread, v_market, v_resolution, online_algorithm.lower(),\n",
    "                                  v_compute_position, v_compute_indicators, v_compute_reward)\n",
    "\n",
    "    print(f'Model name:{v_model_name}')\n",
    "\n",
    "    v_main_dir, v_models_dir, v_logs_dir = get_paths_params(config_file)\n",
    "\n",
    "    v_online_model_dir = path_join(*[v_models_dir, v_resolution, v_subdir, v_model_name, 'online'])\n",
    "    # v_online_model_dir = path_join(v_online_models_dir, online_algorithm.lower())\n",
    "    v_online_model_file_name = path_join(v_online_model_dir, 'model.zip')\n",
    "    v_online_model_file_name_stats = path_join(v_online_model_dir, 'stats.pkl')\n",
    "    v_online_model_replay_buffer = path_join(v_online_model_dir, 'replay_buffer.pkl')\n",
    "    v_online_model_dataset_file_name = path_join(v_online_model_dir, 'dataset.h5')\n",
    "\n",
    "    if not os.path.exists(v_online_model_dir):\n",
    "        os.makedirs(v_online_model_dir.lower())\n",
    "\n",
    "    v_monitor = path_join(v_logs_dir, v_model_name)\n",
    "\n",
    "    v_dummy_vec_env = DummyVecEnv([lambda: Monitor(v_env, v_monitor)])\n",
    "    v_dummy_vec_env.seed(1)\n",
    "\n",
    "    online_class, online_policy = get_online_class_and_policy(online_algorithm)\n",
    "\n",
    "    n_actions = v_dummy_vec_env.action_space.shape[-1]\n",
    "\n",
    "    v_action_noise_class = get_action_noise_class(online_algorithm, v_action_noise, n_actions, v_noise_sigma)\n",
    "\n",
    "    # load recent checkpoint\n",
    "    if os.path.isfile(v_online_model_file_name) and os.path.isfile(v_online_model_file_name_stats):\n",
    "        v_vec_normalize = VecNormalize.load(v_online_model_file_name_stats, v_dummy_vec_env)\n",
    "        v_vec_normalize.reset()\n",
    "        v_online_model = online_class.load(v_online_model_file_name, v_vec_normalize)\n",
    "        print('Model Loaded ...')\n",
    "    else:\n",
    "        #   v_vec_normalize = VecNormalize(v_dummy_vec_env, norm_obs, norm_reward, clip_obs, clip_reward, gamma)\n",
    "        v_vec_normalize = VecNormalize(v_dummy_vec_env)\n",
    "        v_vec_normalize.seed(1)\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': v_learning_rate,\n",
    "        'policy_kwargs': dict(net_arch=v_net_arch)\n",
    "    }\n",
    "\n",
    "    if online_algorithm == 'PPO' or online_algorithm == 'A2C' or online_algorithm == 'SAC':\n",
    "        v_online_model = online_class(env=v_vec_normalize, policy=online_policy, verbose=v_model_verbose, **params,\n",
    "                                      use_sde=v_use_sde, tensorboard_log=v_logs_dir if v_use_tensorboard else None)\n",
    "    elif online_algorithm == 'TD3':\n",
    "        v_online_model = online_class(env=v_vec_normalize, policy=online_policy, action_noise=v_action_noise_class,\n",
    "                                      optimize_memory_usage=True, verbose=v_model_verbose, **params,\n",
    "                                      tensorboard_log=v_logs_dir if v_use_tensorboard else None)\n",
    "\n",
    "    # replay buffer\n",
    "    if os.path.isfile(v_online_model_replay_buffer):\n",
    "        v_online_model.load_replay_buffer(v_online_model_replay_buffer)\n",
    "\n",
    "    print(\"Start training model...\")\n",
    "\n",
    "    if v_use_callback:\n",
    "        callback = SaveToDiskOnBestTrainingRewardCallback(check_freq=v_check_freq, save_freq=v_save_freq,\n",
    "                                                          lookback=v_callback_lookback,\n",
    "                                                          online_algorithm=online_algorithm,\n",
    "                                                          model_file_name=v_online_model_file_name,\n",
    "                                                          model_replay_buffer=v_online_model_replay_buffer,\n",
    "                                                          model_stats=v_online_model_file_name_stats,\n",
    "                                                          save_replay_buffer=v_save_replay_buffer,\n",
    "                                                          verbose=v_callback_verbose)\n",
    "        v_online_model.learn(total_timesteps=total_timesteps, log_interval=1000, reset_num_timesteps=False,\n",
    "                             tb_log_name=v_model_name, callback=callback)\n",
    "    else:\n",
    "        v_online_model.learn(total_timesteps=total_timesteps, log_interval=1000, reset_num_timesteps=False,\n",
    "                             tb_log_name=v_model_name)\n",
    "\n",
    "    if not v_use_callback:\n",
    "        v_online_model.save(v_online_model_file_name.lower())\n",
    "        v_vec_normalize.save(v_online_model_file_name_stats.lower())\n",
    "\n",
    "    if v_save_replay_buffer:\n",
    "        try:\n",
    "            dataset = to_mdp_dataset(v_online_model.replay_buffer)\n",
    "            dataset.dump(v_online_model_dataset_file_name)\n",
    "            os.remove(v_online_model_replay_buffer.lower())\n",
    "            # os.remove(v_online_model_file_name)\n",
    "            # os.remove(v_online_model_file_name_stats)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    print(\"End training online model...\")\n",
    "\n",
    "    v_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_count=4871, start_row=3870, start_date=2017-12-17T22:00:00.000000000, end_row=4870, end_date=2021-10-27T21:00:00.000000000\n",
      "Data shape:(7, 1000, 4)\n",
      "Instruments:['EURUSD', 'USDJPY', 'GBPUSD', 'AUDUSD', 'USDCAD', 'USDCHF', 'NZDUSD'], lookack:30, random_episode_start:True, cash:1000.0, max_slippage_percent:0.01, lot_size:Micro, leverage:20, pip_size:[0.0001, 0.01, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001], pip_spread:[2, 2, 2, 2, 2, 2, 2], compute_position:long_and_short, compute_indicators:all, compute_reward:['log_returns'], verbose:False\n",
      "Model name:fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\n",
      "Using cuda device\n",
      "Start training model...\n",
      "Logging to E:\\\\alpha-machine\\\\logs\\\\forex\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d_0\n",
      "Num timesteps: 100\n",
      "Best mean reward: -inf, Best mean reward step: 0 Last mean reward per episode: -0.0013\n",
      "Last reward =  [-0.01053201]\n",
      "Reward buffer length =  100\n",
      "Num timesteps: 200\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0084\n",
      "Last reward =  [0.00239374]\n",
      "Reward buffer length =  200\n",
      "Num timesteps: 300\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0073\n",
      "Last reward =  [-0.00542919]\n",
      "Reward buffer length =  300\n",
      "Num timesteps: 400\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0020\n",
      "Last reward =  [-0.00698653]\n",
      "Reward buffer length =  400\n",
      "Num timesteps: 500\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0060\n",
      "Last reward =  [-0.04102426]\n",
      "Reward buffer length =  500\n",
      "Num timesteps: 600\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0038\n",
      "Last reward =  [-0.00405563]\n",
      "Reward buffer length =  600\n",
      "Num timesteps: 700\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0055\n",
      "Last reward =  [-0.00077354]\n",
      "Reward buffer length =  700\n",
      "Num timesteps: 800\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0039\n",
      "Last reward =  [-0.00224715]\n",
      "Reward buffer length =  800\n",
      "Num timesteps: 900\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0087\n",
      "Last reward =  [-0.00591344]\n",
      "Reward buffer length =  900\n",
      "Num timesteps: 1000\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0015\n",
      "Last reward =  [0.00551762]\n",
      "Reward buffer length =  1000\n",
      "Num timesteps: 1100\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0087\n",
      "Last reward =  [-0.03643466]\n",
      "Reward buffer length =  1100\n",
      "Num timesteps: 1200\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: -0.0027\n",
      "Last reward =  [0.0106298]\n",
      "Reward buffer length =  1200\n",
      "Num timesteps: 1300\n",
      "Best mean reward: -0.0013, Best mean reward step: 100 Last mean reward per episode: 0.0002\n",
      "Last reward =  [-0.03883338]\n",
      "Reward buffer length =  1300\n",
      "Num timesteps: 1400\n",
      "Best mean reward: 0.0002, Best mean reward step: 1300 Last mean reward per episode: -0.0067\n",
      "Last reward =  [-0.0095001]\n",
      "Reward buffer length =  1400\n",
      "Num timesteps: 1500\n",
      "Best mean reward: 0.0002, Best mean reward step: 1300 Last mean reward per episode: -0.0037\n",
      "Last reward =  [-0.00099089]\n",
      "Reward buffer length =  1500\n",
      "Num timesteps: 1600\n",
      "Best mean reward: 0.0002, Best mean reward step: 1300 Last mean reward per episode: 0.0013\n",
      "Last reward =  [0.00970554]\n",
      "Reward buffer length =  1600\n",
      "Num timesteps: 1700\n",
      "Best mean reward: 0.0013, Best mean reward step: 1600 Last mean reward per episode: -0.0030\n",
      "Last reward =  [0.02269541]\n",
      "Reward buffer length =  1700\n",
      "Num timesteps: 1800\n",
      "Best mean reward: 0.0013, Best mean reward step: 1600 Last mean reward per episode: -0.0040\n",
      "Last reward =  [-0.00905582]\n",
      "Reward buffer length =  1800\n",
      "Num timesteps: 1900\n",
      "Best mean reward: 0.0013, Best mean reward step: 1600 Last mean reward per episode: -0.0061\n",
      "Last reward =  [0.01495397]\n",
      "Reward buffer length =  1900\n",
      "Num timesteps: 2000\n",
      "Best mean reward: 0.0013, Best mean reward step: 1600 Last mean reward per episode: 0.0007\n",
      "Last reward =  [-0.00868138]\n",
      "Reward buffer length =  2000\n",
      "Num timesteps: 2100\n",
      "Best mean reward: 0.0013, Best mean reward step: 1600 Last mean reward per episode: 0.0014\n",
      "Last reward =  [0.14473522]\n",
      "Reward buffer length =  2100\n",
      "Num timesteps: 2200\n",
      "Best mean reward: 0.0014, Best mean reward step: 2100 Last mean reward per episode: 0.0041\n",
      "Last reward =  [-0.01530051]\n",
      "Reward buffer length =  2200\n",
      "Num timesteps: 2300\n",
      "Best mean reward: 0.0041, Best mean reward step: 2200 Last mean reward per episode: -0.0021\n",
      "Last reward =  [0.02579557]\n",
      "Reward buffer length =  2300\n",
      "Num timesteps: 2400\n",
      "Best mean reward: 0.0041, Best mean reward step: 2200 Last mean reward per episode: -0.0004\n",
      "Last reward =  [-0.00943163]\n",
      "Reward buffer length =  2400\n",
      "Num timesteps: 2500\n",
      "Best mean reward: 0.0041, Best mean reward step: 2200 Last mean reward per episode: -0.0010\n",
      "Last reward =  [-0.02041898]\n",
      "Reward buffer length =  2500\n",
      "Num timesteps: 2600\n",
      "Best mean reward: 0.0041, Best mean reward step: 2200 Last mean reward per episode: 0.0006\n",
      "Last reward =  [0.02422086]\n",
      "Reward buffer length =  2600\n",
      "Num timesteps: 2700\n",
      "Best mean reward: 0.0041, Best mean reward step: 2200 Last mean reward per episode: 0.0047\n",
      "Last reward =  [-0.0001269]\n",
      "Reward buffer length =  2700\n",
      "Num timesteps: 2800\n",
      "Best mean reward: 0.0047, Best mean reward step: 2700 Last mean reward per episode: 0.0021\n",
      "Last reward =  [0.01657907]\n",
      "Reward buffer length =  2800\n",
      "Num timesteps: 2900\n",
      "Best mean reward: 0.0047, Best mean reward step: 2700 Last mean reward per episode: 0.0005\n",
      "Last reward =  [-0.05435975]\n",
      "Reward buffer length =  2900\n",
      "Num timesteps: 3000\n",
      "Best mean reward: 0.0047, Best mean reward step: 2700 Last mean reward per episode: 0.0003\n",
      "Last reward =  [0.00618766]\n",
      "Reward buffer length =  3000\n",
      "Num timesteps: 3100\n",
      "Best mean reward: 0.0047, Best mean reward step: 2700 Last mean reward per episode: 0.0035\n",
      "Last reward =  [0.14772636]\n",
      "Reward buffer length =  3100\n",
      "Num timesteps: 3200\n",
      "Best mean reward: 0.0047, Best mean reward step: 2700 Last mean reward per episode: 0.0145\n",
      "Last reward =  [-0.00923878]\n",
      "Reward buffer length =  3200\n",
      "Num timesteps: 3300\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0037\n",
      "Last reward =  [0.06523179]\n",
      "Reward buffer length =  3300\n",
      "Num timesteps: 3400\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0069\n",
      "Last reward =  [0.02805957]\n",
      "Reward buffer length =  3400\n",
      "Num timesteps: 3500\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0020\n",
      "Last reward =  [0.02312361]\n",
      "Reward buffer length =  3500\n",
      "Num timesteps: 3600\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0008\n",
      "Last reward =  [0.00789542]\n",
      "Reward buffer length =  3600\n",
      "Num timesteps: 3700\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0012\n",
      "Last reward =  [0.03086333]\n",
      "Reward buffer length =  3700\n",
      "Num timesteps: 3800\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0076\n",
      "Last reward =  [0.03296651]\n",
      "Reward buffer length =  3800\n",
      "Num timesteps: 3900\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0085\n",
      "Last reward =  [-0.01376447]\n",
      "Reward buffer length =  3900\n",
      "Num timesteps: 4000\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0066\n",
      "Last reward =  [-0.01486932]\n",
      "Reward buffer length =  4000\n",
      "Num timesteps: 4100\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0059\n",
      "Last reward =  [0.0003619]\n",
      "Reward buffer length =  4100\n",
      "Num timesteps: 4200\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0022\n",
      "Last reward =  [0.03122205]\n",
      "Reward buffer length =  4200\n",
      "Num timesteps: 4300\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0085\n",
      "Last reward =  [-0.00562796]\n",
      "Reward buffer length =  4300\n",
      "Num timesteps: 4400\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0037\n",
      "Last reward =  [-0.01085629]\n",
      "Reward buffer length =  4400\n",
      "Num timesteps: 4500\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0059\n",
      "Last reward =  [-0.04251794]\n",
      "Reward buffer length =  4500\n",
      "Num timesteps: 4600\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0042\n",
      "Last reward =  [0.05984667]\n",
      "Reward buffer length =  4600\n",
      "Num timesteps: 4700\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0008\n",
      "Last reward =  [-0.01659797]\n",
      "Reward buffer length =  4700\n",
      "Num timesteps: 4800\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0071\n",
      "Last reward =  [0.00884475]\n",
      "Reward buffer length =  4800\n",
      "Num timesteps: 4900\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0052\n",
      "Last reward =  [-0.01205783]\n",
      "Reward buffer length =  4900\n",
      "Num timesteps: 5000\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: -0.0002\n",
      "Last reward =  [-0.02350379]\n",
      "Reward buffer length =  5000\n",
      "Num timesteps: 5100\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0023\n",
      "Last reward =  [0.02885387]\n",
      "Reward buffer length =  5100\n",
      "Num timesteps: 5200\n",
      "Best mean reward: 0.0145, Best mean reward step: 3200 Last mean reward per episode: 0.0153\n",
      "Last reward =  [0.02982279]\n",
      "Reward buffer length =  5200\n",
      "Num timesteps: 5300\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0067\n",
      "Last reward =  [-0.00966162]\n",
      "Reward buffer length =  5300\n",
      "Num timesteps: 5400\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0080\n",
      "Last reward =  [0.04481091]\n",
      "Reward buffer length =  5400\n",
      "Num timesteps: 5500\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0076\n",
      "Last reward =  [0.01201865]\n",
      "Reward buffer length =  5500\n",
      "Num timesteps: 5600\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0000\n",
      "Last reward =  [-0.00932284]\n",
      "Reward buffer length =  5600\n",
      "Num timesteps: 5700\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: -0.0017\n",
      "Last reward =  [-0.02965823]\n",
      "Reward buffer length =  5700\n",
      "Num timesteps: 5800\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0004\n",
      "Last reward =  [-0.03882798]\n",
      "Reward buffer length =  5800\n",
      "Num timesteps: 5900\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0026\n",
      "Last reward =  [-0.03992787]\n",
      "Reward buffer length =  5900\n",
      "Num timesteps: 6000\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0144\n",
      "Last reward =  [0.07153022]\n",
      "Reward buffer length =  6000\n",
      "Num timesteps: 6100\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0075\n",
      "Last reward =  [0.03483377]\n",
      "Reward buffer length =  6100\n",
      "Num timesteps: 6200\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0079\n",
      "Last reward =  [0.04113651]\n",
      "Reward buffer length =  6200\n",
      "Num timesteps: 6300\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0064\n",
      "Last reward =  [0.00572803]\n",
      "Reward buffer length =  6300\n",
      "Num timesteps: 6400\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0024\n",
      "Last reward =  [0.03205882]\n",
      "Reward buffer length =  6400\n",
      "Num timesteps: 6500\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0001\n",
      "Last reward =  [-0.01717339]\n",
      "Reward buffer length =  6500\n",
      "Num timesteps: 6600\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0055\n",
      "Last reward =  [-0.01969533]\n",
      "Reward buffer length =  6600\n",
      "Num timesteps: 6700\n",
      "Best mean reward: 0.0153, Best mean reward step: 5200 Last mean reward per episode: 0.0210\n",
      "Last reward =  [-0.01812564]\n",
      "Reward buffer length =  6700\n",
      "Num timesteps: 6800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0062\n",
      "Last reward =  [-0.01259342]\n",
      "Reward buffer length =  6800\n",
      "Num timesteps: 6900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0070\n",
      "Last reward =  [-0.04147354]\n",
      "Reward buffer length =  6900\n",
      "Num timesteps: 7000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0033\n",
      "Last reward =  [0.0177711]\n",
      "Reward buffer length =  7000\n",
      "Num timesteps: 7100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0017\n",
      "Last reward =  [0.00935442]\n",
      "Reward buffer length =  7100\n",
      "Num timesteps: 7200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0100\n",
      "Last reward =  [-0.0312573]\n",
      "Reward buffer length =  7200\n",
      "Num timesteps: 7300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0035\n",
      "Last reward =  [0.03726336]\n",
      "Reward buffer length =  7300\n",
      "Num timesteps: 7400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0037\n",
      "Last reward =  [0.00022048]\n",
      "Reward buffer length =  7400\n",
      "Num timesteps: 7500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0072\n",
      "Last reward =  [0.00161294]\n",
      "Reward buffer length =  7500\n",
      "Num timesteps: 7600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0072\n",
      "Last reward =  [0.02178959]\n",
      "Reward buffer length =  7600\n",
      "Num timesteps: 7700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0004\n",
      "Last reward =  [-0.02661304]\n",
      "Reward buffer length =  7700\n",
      "Num timesteps: 7800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0042\n",
      "Last reward =  [0.00657653]\n",
      "Reward buffer length =  7800\n",
      "Num timesteps: 7900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0066\n",
      "Last reward =  [-0.03435903]\n",
      "Reward buffer length =  7900\n",
      "Num timesteps: 8000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0012\n",
      "Last reward =  [0.03350129]\n",
      "Reward buffer length =  8000\n",
      "Num timesteps: 8100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0004\n",
      "Last reward =  [0.00694995]\n",
      "Reward buffer length =  8100\n",
      "Num timesteps: 8200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0017\n",
      "Last reward =  [0.02298964]\n",
      "Reward buffer length =  8200\n",
      "Num timesteps: 8300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0041\n",
      "Last reward =  [0.01549058]\n",
      "Reward buffer length =  8300\n",
      "Num timesteps: 8400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0200\n",
      "Last reward =  [0.01319623]\n",
      "Reward buffer length =  8400\n",
      "Num timesteps: 8500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0028\n",
      "Last reward =  [-0.03600798]\n",
      "Reward buffer length =  8500\n",
      "Num timesteps: 8600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0059\n",
      "Last reward =  [0.02100688]\n",
      "Reward buffer length =  8600\n",
      "Num timesteps: 8700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0003\n",
      "Last reward =  [-0.0131261]\n",
      "Reward buffer length =  8700\n",
      "Num timesteps: 8800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0032\n",
      "Last reward =  [-0.0360738]\n",
      "Reward buffer length =  8800\n",
      "Num timesteps: 8900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0160\n",
      "Last reward =  [-0.01814611]\n",
      "Reward buffer length =  8900\n",
      "Num timesteps: 9000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0063\n",
      "Last reward =  [-0.00741272]\n",
      "Reward buffer length =  9000\n",
      "Num timesteps: 9100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0019\n",
      "Last reward =  [-0.02135703]\n",
      "Reward buffer length =  9100\n",
      "Num timesteps: 9200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0052\n",
      "Last reward =  [0.00068091]\n",
      "Reward buffer length =  9200\n",
      "Num timesteps: 9300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0032\n",
      "Last reward =  [-0.01894269]\n",
      "Reward buffer length =  9300\n",
      "Num timesteps: 9400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0019\n",
      "Last reward =  [0.03396811]\n",
      "Reward buffer length =  9400\n",
      "Num timesteps: 9500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0018\n",
      "Last reward =  [-0.00972825]\n",
      "Reward buffer length =  9500\n",
      "Num timesteps: 9600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0048\n",
      "Last reward =  [0.02772672]\n",
      "Reward buffer length =  9600\n",
      "Num timesteps: 9700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0024\n",
      "Last reward =  [0.03786594]\n",
      "Reward buffer length =  9700\n",
      "Num timesteps: 9800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0049\n",
      "Last reward =  [-0.04687214]\n",
      "Reward buffer length =  9800\n",
      "Num timesteps: 9900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0061\n",
      "Last reward =  [0.01942658]\n",
      "Reward buffer length =  9900\n",
      "Num timesteps: 10000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0014\n",
      "Last reward =  [-0.01982643]\n",
      "Reward buffer length =  10000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 10100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0047\n",
      "Last reward =  [-0.01182281]\n",
      "Reward buffer length =  10100\n",
      "Num timesteps: 10200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0023\n",
      "Last reward =  [-0.02703694]\n",
      "Reward buffer length =  10200\n",
      "Num timesteps: 10300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0044\n",
      "Last reward =  [0.01197762]\n",
      "Reward buffer length =  10300\n",
      "Num timesteps: 10400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0033\n",
      "Last reward =  [0.00023042]\n",
      "Reward buffer length =  10400\n",
      "Num timesteps: 10500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0012\n",
      "Last reward =  [-0.03165479]\n",
      "Reward buffer length =  10500\n",
      "Num timesteps: 10600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0047\n",
      "Last reward =  [0.02630795]\n",
      "Reward buffer length =  10600\n",
      "Num timesteps: 10700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0088\n",
      "Last reward =  [-0.06644947]\n",
      "Reward buffer length =  10700\n",
      "Num timesteps: 10800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0105\n",
      "Last reward =  [-0.03296765]\n",
      "Reward buffer length =  10800\n",
      "Num timesteps: 10900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0022\n",
      "Last reward =  [-0.00975002]\n",
      "Reward buffer length =  10900\n",
      "Num timesteps: 11000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0004\n",
      "Last reward =  [0.01293386]\n",
      "Reward buffer length =  11000\n",
      "Num timesteps: 11100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0071\n",
      "Last reward =  [-0.05560807]\n",
      "Reward buffer length =  11100\n",
      "Num timesteps: 11200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0008\n",
      "Last reward =  [0.00688091]\n",
      "Reward buffer length =  11200\n",
      "Num timesteps: 11300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0022\n",
      "Last reward =  [0.01832446]\n",
      "Reward buffer length =  11300\n",
      "Num timesteps: 11400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0016\n",
      "Last reward =  [-0.06663452]\n",
      "Reward buffer length =  11400\n",
      "Num timesteps: 11500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0180\n",
      "Last reward =  [-0.00016534]\n",
      "Reward buffer length =  11500\n",
      "Num timesteps: 11600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0005\n",
      "Last reward =  [-0.01621437]\n",
      "Reward buffer length =  11600\n",
      "Num timesteps: 11700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0008\n",
      "Last reward =  [-0.00412005]\n",
      "Reward buffer length =  11700\n",
      "Num timesteps: 11800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0065\n",
      "Last reward =  [-0.0279787]\n",
      "Reward buffer length =  11800\n",
      "Num timesteps: 11900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0044\n",
      "Last reward =  [0.03492535]\n",
      "Reward buffer length =  11900\n",
      "Num timesteps: 12000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0004\n",
      "Last reward =  [0.01355738]\n",
      "Reward buffer length =  12000\n",
      "Num timesteps: 12100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0025\n",
      "Last reward =  [-0.0216623]\n",
      "Reward buffer length =  12100\n",
      "Num timesteps: 12200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0076\n",
      "Last reward =  [-0.00481321]\n",
      "Reward buffer length =  12200\n",
      "Num timesteps: 12300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0032\n",
      "Last reward =  [-0.03636082]\n",
      "Reward buffer length =  12300\n",
      "Num timesteps: 12400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0042\n",
      "Last reward =  [-0.04144732]\n",
      "Reward buffer length =  12400\n",
      "Num timesteps: 12500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0006\n",
      "Last reward =  [0.01916415]\n",
      "Reward buffer length =  12500\n",
      "Num timesteps: 12600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0030\n",
      "Last reward =  [0.0414567]\n",
      "Reward buffer length =  12600\n",
      "Num timesteps: 12700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0018\n",
      "Last reward =  [0.02792546]\n",
      "Reward buffer length =  12700\n",
      "Num timesteps: 12800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0176\n",
      "Last reward =  [-0.00774253]\n",
      "Reward buffer length =  12800\n",
      "Num timesteps: 12900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0019\n",
      "Last reward =  [-0.01960021]\n",
      "Reward buffer length =  12900\n",
      "Num timesteps: 13000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0017\n",
      "Last reward =  [-0.04841117]\n",
      "Reward buffer length =  13000\n",
      "Num timesteps: 13100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0052\n",
      "Last reward =  [-0.01290566]\n",
      "Reward buffer length =  13100\n",
      "Num timesteps: 13200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0069\n",
      "Last reward =  [-0.04773769]\n",
      "Reward buffer length =  13200\n",
      "Num timesteps: 13300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0084\n",
      "Last reward =  [0.0283693]\n",
      "Reward buffer length =  13300\n",
      "Num timesteps: 13400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0149\n",
      "Last reward =  [-0.0488068]\n",
      "Reward buffer length =  13400\n",
      "Num timesteps: 13500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0014\n",
      "Last reward =  [0.0685752]\n",
      "Reward buffer length =  13500\n",
      "Num timesteps: 13600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0024\n",
      "Last reward =  [0.00107532]\n",
      "Reward buffer length =  13600\n",
      "Num timesteps: 13700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0032\n",
      "Last reward =  [-0.01476411]\n",
      "Reward buffer length =  13700\n",
      "Num timesteps: 13800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0076\n",
      "Last reward =  [-0.00984498]\n",
      "Reward buffer length =  13800\n",
      "Num timesteps: 13900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0028\n",
      "Last reward =  [-0.02738261]\n",
      "Reward buffer length =  13900\n",
      "Num timesteps: 14000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0039\n",
      "Last reward =  [-0.01508131]\n",
      "Reward buffer length =  14000\n",
      "Num timesteps: 14100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0079\n",
      "Last reward =  [-0.03758783]\n",
      "Reward buffer length =  14100\n",
      "Num timesteps: 14200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0122\n",
      "Last reward =  [0.07863336]\n",
      "Reward buffer length =  14200\n",
      "Num timesteps: 14300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0146\n",
      "Last reward =  [-0.00895622]\n",
      "Reward buffer length =  14300\n",
      "Num timesteps: 14400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0009\n",
      "Last reward =  [0.04819685]\n",
      "Reward buffer length =  14400\n",
      "Num timesteps: 14500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0028\n",
      "Last reward =  [0.01783029]\n",
      "Reward buffer length =  14500\n",
      "Num timesteps: 14600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0032\n",
      "Last reward =  [0.01058789]\n",
      "Reward buffer length =  14600\n",
      "Num timesteps: 14700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0017\n",
      "Last reward =  [0.06919982]\n",
      "Reward buffer length =  14700\n",
      "Num timesteps: 14800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0155\n",
      "Last reward =  [-0.0190177]\n",
      "Reward buffer length =  14800\n",
      "Num timesteps: 14900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0039\n",
      "Last reward =  [-0.00031053]\n",
      "Reward buffer length =  14900\n",
      "Num timesteps: 15000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0048\n",
      "Last reward =  [-0.08464272]\n",
      "Reward buffer length =  15000\n",
      "Num timesteps: 15100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0126\n",
      "Last reward =  [0.05743075]\n",
      "Reward buffer length =  15100\n",
      "Num timesteps: 15200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0004\n",
      "Last reward =  [-0.07766273]\n",
      "Reward buffer length =  15200\n",
      "Num timesteps: 15300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0052\n",
      "Last reward =  [-0.01922948]\n",
      "Reward buffer length =  15300\n",
      "Num timesteps: 15400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0051\n",
      "Last reward =  [0.01754393]\n",
      "Reward buffer length =  15400\n",
      "Num timesteps: 15500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0136\n",
      "Last reward =  [-0.01168111]\n",
      "Reward buffer length =  15500\n",
      "Num timesteps: 15600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0016\n",
      "Last reward =  [-0.02098853]\n",
      "Reward buffer length =  15600\n",
      "Num timesteps: 15700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0027\n",
      "Last reward =  [0.03046528]\n",
      "Reward buffer length =  15700\n",
      "Num timesteps: 15800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0024\n",
      "Last reward =  [-0.01704236]\n",
      "Reward buffer length =  15800\n",
      "Num timesteps: 15900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0153\n",
      "Last reward =  [-0.02144231]\n",
      "Reward buffer length =  15900\n",
      "Num timesteps: 16000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0073\n",
      "Last reward =  [-0.0203248]\n",
      "Reward buffer length =  16000\n",
      "Num timesteps: 16100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0087\n",
      "Last reward =  [-0.02767298]\n",
      "Reward buffer length =  16100\n",
      "Num timesteps: 16200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0133\n",
      "Last reward =  [-0.02806384]\n",
      "Reward buffer length =  16200\n",
      "Num timesteps: 16300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0131\n",
      "Last reward =  [-0.00946836]\n",
      "Reward buffer length =  16300\n",
      "Num timesteps: 16400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0137\n",
      "Last reward =  [-0.04228456]\n",
      "Reward buffer length =  16400\n",
      "Num timesteps: 16500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0028\n",
      "Last reward =  [-0.04689665]\n",
      "Reward buffer length =  16500\n",
      "Num timesteps: 16600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0066\n",
      "Last reward =  [-0.0074702]\n",
      "Reward buffer length =  16600\n",
      "Num timesteps: 16700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0088\n",
      "Last reward =  [-0.05118423]\n",
      "Reward buffer length =  16700\n",
      "Num timesteps: 16800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0139\n",
      "Last reward =  [-0.02088802]\n",
      "Reward buffer length =  16800\n",
      "Num timesteps: 16900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0085\n",
      "Last reward =  [-0.03891204]\n",
      "Reward buffer length =  16900\n",
      "Num timesteps: 17000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0126\n",
      "Last reward =  [-0.0083492]\n",
      "Reward buffer length =  17000\n",
      "Num timesteps: 17100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0129\n",
      "Last reward =  [-0.04817244]\n",
      "Reward buffer length =  17100\n",
      "Num timesteps: 17200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0152\n",
      "Last reward =  [-0.03041113]\n",
      "Reward buffer length =  17200\n",
      "Num timesteps: 17300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0151\n",
      "Last reward =  [-0.04169469]\n",
      "Reward buffer length =  17300\n",
      "Num timesteps: 17400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0147\n",
      "Last reward =  [-0.02672203]\n",
      "Reward buffer length =  17400\n",
      "Num timesteps: 17500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0146\n",
      "Last reward =  [-0.03759195]\n",
      "Reward buffer length =  17500\n",
      "Num timesteps: 17600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0149\n",
      "Last reward =  [-0.03510154]\n",
      "Reward buffer length =  17600\n",
      "Num timesteps: 17700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0101\n",
      "Last reward =  [-0.00469856]\n",
      "Reward buffer length =  17700\n",
      "Num timesteps: 17800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0043\n",
      "Last reward =  [-0.02176241]\n",
      "Reward buffer length =  17800\n",
      "Num timesteps: 17900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0138\n",
      "Last reward =  [-0.02773913]\n",
      "Reward buffer length =  17900\n",
      "Num timesteps: 18000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0182\n",
      "Last reward =  [-0.05301679]\n",
      "Reward buffer length =  18000\n",
      "Num timesteps: 18100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0148\n",
      "Last reward =  [0.01320172]\n",
      "Reward buffer length =  18100\n",
      "Num timesteps: 18200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0002\n",
      "Last reward =  [-0.00773509]\n",
      "Reward buffer length =  18200\n",
      "Num timesteps: 18300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0114\n",
      "Last reward =  [0.00544587]\n",
      "Reward buffer length =  18300\n",
      "Num timesteps: 18400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0141\n",
      "Last reward =  [-0.05814856]\n",
      "Reward buffer length =  18400\n",
      "Num timesteps: 18500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0147\n",
      "Last reward =  [-0.02033879]\n",
      "Reward buffer length =  18500\n",
      "Num timesteps: 18600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0199\n",
      "Last reward =  [-0.06145223]\n",
      "Reward buffer length =  18600\n",
      "Num timesteps: 18700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0061\n",
      "Last reward =  [0.01388107]\n",
      "Reward buffer length =  18700\n",
      "Num timesteps: 18800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0008\n",
      "Last reward =  [0.01130757]\n",
      "Reward buffer length =  18800\n",
      "Num timesteps: 18900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0041\n",
      "Last reward =  [-0.04484785]\n",
      "Reward buffer length =  18900\n",
      "Num timesteps: 19000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0112\n",
      "Last reward =  [-0.06182099]\n",
      "Reward buffer length =  19000\n",
      "Num timesteps: 19100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0137\n",
      "Last reward =  [-0.01130757]\n",
      "Reward buffer length =  19100\n",
      "Num timesteps: 19200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0160\n",
      "Last reward =  [0.00564627]\n",
      "Reward buffer length =  19200\n",
      "Num timesteps: 19300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0229\n",
      "Last reward =  [-0.05391591]\n",
      "Reward buffer length =  19300\n",
      "Num timesteps: 19400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0029\n",
      "Last reward =  [-0.03396047]\n",
      "Reward buffer length =  19400\n",
      "Num timesteps: 19500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0026\n",
      "Last reward =  [0.02696657]\n",
      "Reward buffer length =  19500\n",
      "Num timesteps: 19600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0025\n",
      "Last reward =  [0.00036162]\n",
      "Reward buffer length =  19600\n",
      "Num timesteps: 19700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0056\n",
      "Last reward =  [0.02851205]\n",
      "Reward buffer length =  19700\n",
      "Num timesteps: 19800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0056\n",
      "Last reward =  [0.01087974]\n",
      "Reward buffer length =  19800\n",
      "Num timesteps: 19900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0139\n",
      "Last reward =  [0.03256946]\n",
      "Reward buffer length =  19900\n",
      "Num timesteps: 20000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0211\n",
      "Last reward =  [-0.02525585]\n",
      "Reward buffer length =  20000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 20100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0186\n",
      "Last reward =  [-0.04042599]\n",
      "Reward buffer length =  20100\n",
      "Num timesteps: 20200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0066\n",
      "Last reward =  [-0.01843592]\n",
      "Reward buffer length =  20200\n",
      "Num timesteps: 20300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0158\n",
      "Last reward =  [-0.05100954]\n",
      "Reward buffer length =  20300\n",
      "Num timesteps: 20400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0180\n",
      "Last reward =  [-0.06256867]\n",
      "Reward buffer length =  20400\n",
      "Num timesteps: 20500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0219\n",
      "Last reward =  [-0.0415538]\n",
      "Reward buffer length =  20500\n",
      "Num timesteps: 20600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0170\n",
      "Last reward =  [-0.02674085]\n",
      "Reward buffer length =  20600\n",
      "Num timesteps: 20700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0198\n",
      "Last reward =  [0.00058533]\n",
      "Reward buffer length =  20700\n",
      "Num timesteps: 20800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0241\n",
      "Last reward =  [-0.03520472]\n",
      "Reward buffer length =  20800\n",
      "Num timesteps: 20900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0115\n",
      "Last reward =  [-0.00937123]\n",
      "Reward buffer length =  20900\n",
      "Num timesteps: 21000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0011\n",
      "Last reward =  [-0.00119013]\n",
      "Reward buffer length =  21000\n",
      "Num timesteps: 21100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0048\n",
      "Last reward =  [0.04769107]\n",
      "Reward buffer length =  21100\n",
      "Num timesteps: 21200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0076\n",
      "Last reward =  [0.01048938]\n",
      "Reward buffer length =  21200\n",
      "Num timesteps: 21300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0201\n",
      "Last reward =  [0.01080913]\n",
      "Reward buffer length =  21300\n",
      "Num timesteps: 21400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0251\n",
      "Last reward =  [-0.03925535]\n",
      "Reward buffer length =  21400\n",
      "Num timesteps: 21500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0221\n",
      "Last reward =  [-0.01341494]\n",
      "Reward buffer length =  21500\n",
      "Num timesteps: 21600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0232\n",
      "Last reward =  [-0.01287399]\n",
      "Reward buffer length =  21600\n",
      "Num timesteps: 21700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0243\n",
      "Last reward =  [-0.03201091]\n",
      "Reward buffer length =  21700\n",
      "Num timesteps: 21800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0084\n",
      "Last reward =  [-0.0195051]\n",
      "Reward buffer length =  21800\n",
      "Num timesteps: 21900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0064\n",
      "Last reward =  [-0.01283551]\n",
      "Reward buffer length =  21900\n",
      "Num timesteps: 22000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0133\n",
      "Last reward =  [-0.03029889]\n",
      "Reward buffer length =  22000\n",
      "Num timesteps: 22100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0228\n",
      "Last reward =  [-0.03891218]\n",
      "Reward buffer length =  22100\n",
      "Num timesteps: 22200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0230\n",
      "Last reward =  [-0.04273023]\n",
      "Reward buffer length =  22200\n",
      "Num timesteps: 22300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0278\n",
      "Last reward =  [-0.06574957]\n",
      "Reward buffer length =  22300\n",
      "Num timesteps: 22400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0232\n",
      "Last reward =  [-0.03850905]\n",
      "Reward buffer length =  22400\n",
      "Num timesteps: 22500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0318\n",
      "Last reward =  [-0.01645451]\n",
      "Reward buffer length =  22500\n",
      "Num timesteps: 22600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0272\n",
      "Last reward =  [-0.04278354]\n",
      "Reward buffer length =  22600\n",
      "Num timesteps: 22700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0224\n",
      "Last reward =  [-0.02092586]\n",
      "Reward buffer length =  22700\n",
      "Num timesteps: 22800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0244\n",
      "Last reward =  [-0.04629909]\n",
      "Reward buffer length =  22800\n",
      "Num timesteps: 22900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0314\n",
      "Last reward =  [-0.06517362]\n",
      "Reward buffer length =  22900\n",
      "Num timesteps: 23000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0334\n",
      "Last reward =  [-0.04253757]\n",
      "Reward buffer length =  23000\n",
      "Num timesteps: 23100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0313\n",
      "Last reward =  [-0.03918835]\n",
      "Reward buffer length =  23100\n",
      "Num timesteps: 23200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0025\n",
      "Last reward =  [0.04124647]\n",
      "Reward buffer length =  23200\n",
      "Num timesteps: 23300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0066\n",
      "Last reward =  [0.06811725]\n",
      "Reward buffer length =  23300\n",
      "Num timesteps: 23400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0154\n",
      "Last reward =  [-0.03737307]\n",
      "Reward buffer length =  23400\n",
      "Num timesteps: 23500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0255\n",
      "Last reward =  [-0.0174723]\n",
      "Reward buffer length =  23500\n",
      "Num timesteps: 23600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0249\n",
      "Last reward =  [-0.06408447]\n",
      "Reward buffer length =  23600\n",
      "Num timesteps: 23700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0352\n",
      "Last reward =  [-0.05433523]\n",
      "Reward buffer length =  23700\n",
      "Num timesteps: 23800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0307\n",
      "Last reward =  [0.01423496]\n",
      "Reward buffer length =  23800\n",
      "Num timesteps: 23900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0377\n",
      "Last reward =  [0.00965561]\n",
      "Reward buffer length =  23900\n",
      "Num timesteps: 24000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0308\n",
      "Last reward =  [-0.03628684]\n",
      "Reward buffer length =  24000\n",
      "Num timesteps: 24100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0339\n",
      "Last reward =  [-0.01919584]\n",
      "Reward buffer length =  24100\n",
      "Num timesteps: 24200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0273\n",
      "Last reward =  [-0.05344838]\n",
      "Reward buffer length =  24200\n",
      "Num timesteps: 24300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0388\n",
      "Last reward =  [-0.02889786]\n",
      "Reward buffer length =  24300\n",
      "Num timesteps: 24400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0199\n",
      "Last reward =  [0.00878343]\n",
      "Reward buffer length =  24400\n",
      "Num timesteps: 24500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0270\n",
      "Last reward =  [-0.05500062]\n",
      "Reward buffer length =  24500\n",
      "Num timesteps: 24600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0372\n",
      "Last reward =  [-0.0717961]\n",
      "Reward buffer length =  24600\n",
      "Num timesteps: 24700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0205\n",
      "Last reward =  [0.03177951]\n",
      "Reward buffer length =  24700\n",
      "Num timesteps: 24800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0022\n",
      "Last reward =  [-0.01568964]\n",
      "Reward buffer length =  24800\n",
      "Num timesteps: 24900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0043\n",
      "Last reward =  [0.02376743]\n",
      "Reward buffer length =  24900\n",
      "Num timesteps: 25000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0035\n",
      "Last reward =  [-0.01318295]\n",
      "Reward buffer length =  25000\n",
      "Num timesteps: 25100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0229\n",
      "Last reward =  [-0.00705536]\n",
      "Reward buffer length =  25100\n",
      "Num timesteps: 25200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0267\n",
      "Last reward =  [-0.02525498]\n",
      "Reward buffer length =  25200\n",
      "Num timesteps: 25300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0370\n",
      "Last reward =  [-0.03373699]\n",
      "Reward buffer length =  25300\n",
      "Num timesteps: 25400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0112\n",
      "Last reward =  [0.02127703]\n",
      "Reward buffer length =  25400\n",
      "Num timesteps: 25500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0133\n",
      "Last reward =  [-0.0459959]\n",
      "Reward buffer length =  25500\n",
      "Num timesteps: 25600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0257\n",
      "Last reward =  [-0.03922949]\n",
      "Reward buffer length =  25600\n",
      "Num timesteps: 25700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0297\n",
      "Last reward =  [-0.03612132]\n",
      "Reward buffer length =  25700\n",
      "Num timesteps: 25800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0420\n",
      "Last reward =  [-0.05203157]\n",
      "Reward buffer length =  25800\n",
      "Num timesteps: 25900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0313\n",
      "Last reward =  [0.00596866]\n",
      "Reward buffer length =  25900\n",
      "Num timesteps: 26000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0374\n",
      "Last reward =  [-0.03835569]\n",
      "Reward buffer length =  26000\n",
      "Num timesteps: 26100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0156\n",
      "Last reward =  [-0.00684116]\n",
      "Reward buffer length =  26100\n",
      "Num timesteps: 26200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0059\n",
      "Last reward =  [-0.0268145]\n",
      "Reward buffer length =  26200\n",
      "Num timesteps: 26300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0181\n",
      "Last reward =  [-0.00987297]\n",
      "Reward buffer length =  26300\n",
      "Num timesteps: 26400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0272\n",
      "Last reward =  [-0.05327477]\n",
      "Reward buffer length =  26400\n",
      "Num timesteps: 26500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0372\n",
      "Last reward =  [-0.08559676]\n",
      "Reward buffer length =  26500\n",
      "Num timesteps: 26600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0261\n",
      "Last reward =  [-0.04396557]\n",
      "Reward buffer length =  26600\n",
      "Num timesteps: 26700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0036\n",
      "Last reward =  [-0.02032794]\n",
      "Reward buffer length =  26700\n",
      "Num timesteps: 26800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0150\n",
      "Last reward =  [0.01444867]\n",
      "Reward buffer length =  26800\n",
      "Num timesteps: 26900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0344\n",
      "Last reward =  [-0.07860967]\n",
      "Reward buffer length =  26900\n",
      "Num timesteps: 27000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0353\n",
      "Last reward =  [-0.10844107]\n",
      "Reward buffer length =  27000\n",
      "Num timesteps: 27100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0395\n",
      "Last reward =  [-0.07572497]\n",
      "Reward buffer length =  27100\n",
      "Num timesteps: 27200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0285\n",
      "Last reward =  [-0.10675362]\n",
      "Reward buffer length =  27200\n",
      "Num timesteps: 27300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0381\n",
      "Last reward =  [-0.0856575]\n",
      "Reward buffer length =  27300\n",
      "Num timesteps: 27400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0418\n",
      "Last reward =  [-0.09718973]\n",
      "Reward buffer length =  27400\n",
      "Num timesteps: 27500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0017\n",
      "Last reward =  [0.0300888]\n",
      "Reward buffer length =  27500\n",
      "Num timesteps: 27600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0175\n",
      "Last reward =  [-0.01200063]\n",
      "Reward buffer length =  27600\n",
      "Num timesteps: 27700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0333\n",
      "Last reward =  [-0.00441155]\n",
      "Reward buffer length =  27700\n",
      "Num timesteps: 27800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0384\n",
      "Last reward =  [-0.05555858]\n",
      "Reward buffer length =  27800\n",
      "Num timesteps: 27900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0452\n",
      "Last reward =  [0.00945751]\n",
      "Reward buffer length =  27900\n",
      "Num timesteps: 28000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0039\n",
      "Last reward =  [-0.00825135]\n",
      "Reward buffer length =  28000\n",
      "Num timesteps: 28100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0073\n",
      "Last reward =  [-0.03001558]\n",
      "Reward buffer length =  28100\n",
      "Num timesteps: 28200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0013\n",
      "Last reward =  [-0.00904958]\n",
      "Reward buffer length =  28200\n",
      "Num timesteps: 28300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0267\n",
      "Last reward =  [-0.02073333]\n",
      "Reward buffer length =  28300\n",
      "Num timesteps: 28400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0363\n",
      "Last reward =  [-0.03239982]\n",
      "Reward buffer length =  28400\n",
      "Num timesteps: 28500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0458\n",
      "Last reward =  [-0.02374001]\n",
      "Reward buffer length =  28500\n",
      "Num timesteps: 28600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0270\n",
      "Last reward =  [0.02605441]\n",
      "Reward buffer length =  28600\n",
      "Num timesteps: 28700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0113\n",
      "Last reward =  [-0.04934523]\n",
      "Reward buffer length =  28700\n",
      "Num timesteps: 28800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0096\n",
      "Last reward =  [-0.03596887]\n",
      "Reward buffer length =  28800\n",
      "Num timesteps: 28900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0307\n",
      "Last reward =  [-0.06538487]\n",
      "Reward buffer length =  28900\n",
      "Num timesteps: 29000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0413\n",
      "Last reward =  [-0.00130223]\n",
      "Reward buffer length =  29000\n",
      "Num timesteps: 29100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0474\n",
      "Last reward =  [-0.03689536]\n",
      "Reward buffer length =  29100\n",
      "Num timesteps: 29200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0108\n",
      "Last reward =  [0.00456792]\n",
      "Reward buffer length =  29200\n",
      "Num timesteps: 29300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0181\n",
      "Last reward =  [0.00138843]\n",
      "Reward buffer length =  29300\n",
      "Num timesteps: 29400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0312\n",
      "Last reward =  [-0.02847149]\n",
      "Reward buffer length =  29400\n",
      "Num timesteps: 29500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0416\n",
      "Last reward =  [-0.0151069]\n",
      "Reward buffer length =  29500\n",
      "Num timesteps: 29600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0418\n",
      "Last reward =  [0.05558274]\n",
      "Reward buffer length =  29600\n",
      "Num timesteps: 29700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0362\n",
      "Last reward =  [-0.01158413]\n",
      "Reward buffer length =  29700\n",
      "Num timesteps: 29800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0424\n",
      "Last reward =  [0.00830859]\n",
      "Reward buffer length =  29800\n",
      "Num timesteps: 29900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0480\n",
      "Last reward =  [-0.00721624]\n",
      "Reward buffer length =  29900\n",
      "Num timesteps: 30000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0063\n",
      "Last reward =  [0.02097188]\n",
      "Reward buffer length =  30000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 30100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0148\n",
      "Last reward =  [-0.02582538]\n",
      "Reward buffer length =  30100\n",
      "Num timesteps: 30200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0069\n",
      "Last reward =  [-0.05568133]\n",
      "Reward buffer length =  30200\n",
      "Num timesteps: 30300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0307\n",
      "Last reward =  [-0.07955436]\n",
      "Reward buffer length =  30300\n",
      "Num timesteps: 30400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0416\n",
      "Last reward =  [-0.04866761]\n",
      "Reward buffer length =  30400\n",
      "Num timesteps: 30500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0529\n",
      "Last reward =  [-0.03239126]\n",
      "Reward buffer length =  30500\n",
      "Num timesteps: 30600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0504\n",
      "Last reward =  [-0.02884521]\n",
      "Reward buffer length =  30600\n",
      "Num timesteps: 30700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0512\n",
      "Last reward =  [-0.03104654]\n",
      "Reward buffer length =  30700\n",
      "Num timesteps: 30800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0048\n",
      "Last reward =  [0.01075575]\n",
      "Reward buffer length =  30800\n",
      "Num timesteps: 30900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0129\n",
      "Last reward =  [0.12461843]\n",
      "Reward buffer length =  30900\n",
      "Num timesteps: 31000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0120\n",
      "Last reward =  [-0.03567334]\n",
      "Reward buffer length =  31000\n",
      "Num timesteps: 31100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0304\n",
      "Last reward =  [-0.01881411]\n",
      "Reward buffer length =  31100\n",
      "Num timesteps: 31200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0450\n",
      "Last reward =  [-0.08479694]\n",
      "Reward buffer length =  31200\n",
      "Num timesteps: 31300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0530\n",
      "Last reward =  [-0.04989376]\n",
      "Reward buffer length =  31300\n",
      "Num timesteps: 31400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0135\n",
      "Last reward =  [-0.00912722]\n",
      "Reward buffer length =  31400\n",
      "Num timesteps: 31500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0154\n",
      "Last reward =  [-0.01385246]\n",
      "Reward buffer length =  31500\n",
      "Num timesteps: 31600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0064\n",
      "Last reward =  [-0.05778642]\n",
      "Reward buffer length =  31600\n",
      "Num timesteps: 31700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0305\n",
      "Last reward =  [-0.04578923]\n",
      "Reward buffer length =  31700\n",
      "Num timesteps: 31800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0399\n",
      "Last reward =  [-0.04948881]\n",
      "Reward buffer length =  31800\n",
      "Num timesteps: 31900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0546\n",
      "Last reward =  [-0.08280331]\n",
      "Reward buffer length =  31900\n",
      "Num timesteps: 32000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0226\n",
      "Last reward =  [-0.03243207]\n",
      "Reward buffer length =  32000\n",
      "Num timesteps: 32100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0151\n",
      "Last reward =  [-0.06133225]\n",
      "Reward buffer length =  32100\n",
      "Num timesteps: 32200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0053\n",
      "Last reward =  [0.00916844]\n",
      "Reward buffer length =  32200\n",
      "Num timesteps: 32300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0302\n",
      "Last reward =  [-0.12461463]\n",
      "Reward buffer length =  32300\n",
      "Num timesteps: 32400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0396\n",
      "Last reward =  [-0.07509083]\n",
      "Reward buffer length =  32400\n",
      "Num timesteps: 32500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0533\n",
      "Last reward =  [-0.0785652]\n",
      "Reward buffer length =  32500\n",
      "Num timesteps: 32600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0368\n",
      "Last reward =  [-0.05646687]\n",
      "Reward buffer length =  32600\n",
      "Num timesteps: 32700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0198\n",
      "Last reward =  [-0.00246165]\n",
      "Reward buffer length =  32700\n",
      "Num timesteps: 32800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0114\n",
      "Last reward =  [-0.0471745]\n",
      "Reward buffer length =  32800\n",
      "Num timesteps: 32900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0335\n",
      "Last reward =  [-0.04647518]\n",
      "Reward buffer length =  32900\n",
      "Num timesteps: 33000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0463\n",
      "Last reward =  [-0.01665209]\n",
      "Reward buffer length =  33000\n",
      "Num timesteps: 33100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0552\n",
      "Last reward =  [-0.04587435]\n",
      "Reward buffer length =  33100\n",
      "Num timesteps: 33200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0451\n",
      "Last reward =  [-0.06521563]\n",
      "Reward buffer length =  33200\n",
      "Num timesteps: 33300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0524\n",
      "Last reward =  [-0.07056474]\n",
      "Reward buffer length =  33300\n",
      "Num timesteps: 33400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0310\n",
      "Last reward =  [-0.05654177]\n",
      "Reward buffer length =  33400\n",
      "Num timesteps: 33500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0089\n",
      "Last reward =  [-0.04523187]\n",
      "Reward buffer length =  33500\n",
      "Num timesteps: 33600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0329\n",
      "Last reward =  [-0.05108821]\n",
      "Reward buffer length =  33600\n",
      "Num timesteps: 33700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0459\n",
      "Last reward =  [-0.05024929]\n",
      "Reward buffer length =  33700\n",
      "Num timesteps: 33800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0537\n",
      "Last reward =  [-0.05889741]\n",
      "Reward buffer length =  33800\n",
      "Num timesteps: 33900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0247\n",
      "Last reward =  [-0.02965173]\n",
      "Reward buffer length =  33900\n",
      "Num timesteps: 34000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0363\n",
      "Last reward =  [-0.0881748]\n",
      "Reward buffer length =  34000\n",
      "Num timesteps: 34100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0487\n",
      "Last reward =  [-0.0766111]\n",
      "Reward buffer length =  34100\n",
      "Num timesteps: 34200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0591\n",
      "Last reward =  [-0.11324896]\n",
      "Reward buffer length =  34200\n",
      "Num timesteps: 34300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0175\n",
      "Last reward =  [-0.0635519]\n",
      "Reward buffer length =  34300\n",
      "Num timesteps: 34400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0363\n",
      "Last reward =  [-0.08313489]\n",
      "Reward buffer length =  34400\n",
      "Num timesteps: 34500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0448\n",
      "Last reward =  [0.0019961]\n",
      "Reward buffer length =  34500\n",
      "Num timesteps: 34600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0585\n",
      "Last reward =  [-8.208144e-05]\n",
      "Reward buffer length =  34600\n",
      "Num timesteps: 34700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0503\n",
      "Last reward =  [-0.0118157]\n",
      "Reward buffer length =  34700\n",
      "Num timesteps: 34800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0599\n",
      "Last reward =  [-0.02353122]\n",
      "Reward buffer length =  34800\n",
      "Num timesteps: 34900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0043\n",
      "Last reward =  [-0.01892653]\n",
      "Reward buffer length =  34900\n",
      "Num timesteps: 35000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0108\n",
      "Last reward =  [-0.01225117]\n",
      "Reward buffer length =  35000\n",
      "Num timesteps: 35100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0207\n",
      "Last reward =  [0.05740008]\n",
      "Reward buffer length =  35100\n",
      "Num timesteps: 35200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0181\n",
      "Last reward =  [-0.02318993]\n",
      "Reward buffer length =  35200\n",
      "Num timesteps: 35300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0361\n",
      "Last reward =  [-0.06718434]\n",
      "Reward buffer length =  35300\n",
      "Num timesteps: 35400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0500\n",
      "Last reward =  [-0.10906762]\n",
      "Reward buffer length =  35400\n",
      "Num timesteps: 35500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0621\n",
      "Last reward =  [-0.05981042]\n",
      "Reward buffer length =  35500\n",
      "Num timesteps: 35600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0229\n",
      "Last reward =  [-0.05375671]\n",
      "Reward buffer length =  35600\n",
      "Num timesteps: 35700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0106\n",
      "Last reward =  [-0.05384221]\n",
      "Reward buffer length =  35700\n",
      "Num timesteps: 35800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0307\n",
      "Last reward =  [-0.06118271]\n",
      "Reward buffer length =  35800\n",
      "Num timesteps: 35900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0478\n",
      "Last reward =  [-0.0673946]\n",
      "Reward buffer length =  35900\n",
      "Num timesteps: 36000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0528\n",
      "Last reward =  [-0.07449952]\n",
      "Reward buffer length =  36000\n",
      "Num timesteps: 36100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0457\n",
      "Last reward =  [0.05168344]\n",
      "Reward buffer length =  36100\n",
      "Num timesteps: 36200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0041\n",
      "Last reward =  [0.0241356]\n",
      "Reward buffer length =  36200\n",
      "Num timesteps: 36300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0027\n",
      "Last reward =  [-0.03022681]\n",
      "Reward buffer length =  36300\n",
      "Num timesteps: 36400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0121\n",
      "Last reward =  [-0.03178433]\n",
      "Reward buffer length =  36400\n",
      "Num timesteps: 36500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0192\n",
      "Last reward =  [0.03491127]\n",
      "Reward buffer length =  36500\n",
      "Num timesteps: 36600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0263\n",
      "Last reward =  [0.00540367]\n",
      "Reward buffer length =  36600\n",
      "Num timesteps: 36700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0399\n",
      "Last reward =  [-0.05924135]\n",
      "Reward buffer length =  36700\n",
      "Num timesteps: 36800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0552\n",
      "Last reward =  [-0.01780234]\n",
      "Reward buffer length =  36800\n",
      "Num timesteps: 36900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0652\n",
      "Last reward =  [-0.08876198]\n",
      "Reward buffer length =  36900\n",
      "Num timesteps: 37000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0060\n",
      "Last reward =  [0.04450509]\n",
      "Reward buffer length =  37000\n",
      "Num timesteps: 37100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0015\n",
      "Last reward =  [0.01145649]\n",
      "Reward buffer length =  37100\n",
      "Num timesteps: 37200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0112\n",
      "Last reward =  [-0.023011]\n",
      "Reward buffer length =  37200\n",
      "Num timesteps: 37300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0250\n",
      "Last reward =  [-0.04125286]\n",
      "Reward buffer length =  37300\n",
      "Num timesteps: 37400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0171\n",
      "Last reward =  [-0.10834473]\n",
      "Reward buffer length =  37400\n",
      "Num timesteps: 37500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0415\n",
      "Last reward =  [-0.03107767]\n",
      "Reward buffer length =  37500\n",
      "Num timesteps: 37600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0593\n",
      "Last reward =  [-0.11578031]\n",
      "Reward buffer length =  37600\n",
      "Num timesteps: 37700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0637\n",
      "Last reward =  [-0.07615622]\n",
      "Reward buffer length =  37700\n",
      "Num timesteps: 37800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.01896179]\n",
      "Reward buffer length =  37800\n",
      "Num timesteps: 37900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0399\n",
      "Last reward =  [-0.05004016]\n",
      "Reward buffer length =  37900\n",
      "Num timesteps: 38000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0528\n",
      "Last reward =  [-0.06608324]\n",
      "Reward buffer length =  38000\n",
      "Num timesteps: 38100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0644\n",
      "Last reward =  [-0.12301818]\n",
      "Reward buffer length =  38100\n",
      "Num timesteps: 38200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0486\n",
      "Last reward =  [0.00587945]\n",
      "Reward buffer length =  38200\n",
      "Num timesteps: 38300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0201\n",
      "Last reward =  [-0.08827499]\n",
      "Reward buffer length =  38300\n",
      "Num timesteps: 38400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0444\n",
      "Last reward =  [-0.04472867]\n",
      "Reward buffer length =  38400\n",
      "Num timesteps: 38500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0602\n",
      "Last reward =  [-0.03749219]\n",
      "Reward buffer length =  38500\n",
      "Num timesteps: 38600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0664\n",
      "Last reward =  [-0.05943492]\n",
      "Reward buffer length =  38600\n",
      "Num timesteps: 38700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0277\n",
      "Last reward =  [-0.05615378]\n",
      "Reward buffer length =  38700\n",
      "Num timesteps: 38800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0226\n",
      "Last reward =  [0.08612586]\n",
      "Reward buffer length =  38800\n",
      "Num timesteps: 38900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0344\n",
      "Last reward =  [-0.02363157]\n",
      "Reward buffer length =  38900\n",
      "Num timesteps: 39000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0497\n",
      "Last reward =  [-0.06323555]\n",
      "Reward buffer length =  39000\n",
      "Num timesteps: 39100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0610\n",
      "Last reward =  [-0.11568015]\n",
      "Reward buffer length =  39100\n",
      "Num timesteps: 39200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0676\n",
      "Last reward =  [-0.12636492]\n",
      "Reward buffer length =  39200\n",
      "Num timesteps: 39300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0410\n",
      "Last reward =  [-0.10789613]\n",
      "Reward buffer length =  39300\n",
      "Num timesteps: 39400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0505\n",
      "Last reward =  [-0.09597146]\n",
      "Reward buffer length =  39400\n",
      "Num timesteps: 39500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0606\n",
      "Last reward =  [-0.08312516]\n",
      "Reward buffer length =  39500\n",
      "Num timesteps: 39600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0657\n",
      "Last reward =  [-0.07212435]\n",
      "Reward buffer length =  39600\n",
      "Num timesteps: 39700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0441\n",
      "Last reward =  [-0.01271394]\n",
      "Reward buffer length =  39700\n",
      "Num timesteps: 39800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0654\n",
      "Last reward =  [-0.07391332]\n",
      "Reward buffer length =  39800\n",
      "Num timesteps: 39900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0646\n",
      "Last reward =  [0.01742998]\n",
      "Reward buffer length =  39900\n",
      "Num timesteps: 40000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0407\n",
      "Last reward =  [0.00824642]\n",
      "Reward buffer length =  40000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 40100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0240\n",
      "Last reward =  [-0.06062296]\n",
      "Reward buffer length =  40100\n",
      "Num timesteps: 40200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0469\n",
      "Last reward =  [-0.09543633]\n",
      "Reward buffer length =  40200\n",
      "Num timesteps: 40300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0632\n",
      "Last reward =  [-0.04722645]\n",
      "Reward buffer length =  40300\n",
      "Num timesteps: 40400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0668\n",
      "Last reward =  [-0.08860216]\n",
      "Reward buffer length =  40400\n",
      "Num timesteps: 40500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0682\n",
      "Last reward =  [-0.06242112]\n",
      "Reward buffer length =  40500\n",
      "Num timesteps: 40600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0522\n",
      "Last reward =  [-0.00132002]\n",
      "Reward buffer length =  40600\n",
      "Num timesteps: 40700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0206\n",
      "Last reward =  [-0.0214661]\n",
      "Reward buffer length =  40700\n",
      "Num timesteps: 40800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0388\n",
      "Last reward =  [-0.0327069]\n",
      "Reward buffer length =  40800\n",
      "Num timesteps: 40900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0571\n",
      "Last reward =  [-0.08948442]\n",
      "Reward buffer length =  40900\n",
      "Num timesteps: 41000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0648\n",
      "Last reward =  [-0.06045785]\n",
      "Reward buffer length =  41000\n",
      "Num timesteps: 41100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0724\n",
      "Last reward =  [-0.09355266]\n",
      "Reward buffer length =  41100\n",
      "Num timesteps: 41200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0628\n",
      "Last reward =  [-0.11766419]\n",
      "Reward buffer length =  41200\n",
      "Num timesteps: 41300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0735\n",
      "Last reward =  [-0.07814417]\n",
      "Reward buffer length =  41300\n",
      "Num timesteps: 41400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0569\n",
      "Last reward =  [-0.03806287]\n",
      "Reward buffer length =  41400\n",
      "Num timesteps: 41500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0530\n",
      "Last reward =  [-0.02274349]\n",
      "Reward buffer length =  41500\n",
      "Num timesteps: 41600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0682\n",
      "Last reward =  [-0.09399516]\n",
      "Reward buffer length =  41600\n",
      "Num timesteps: 41700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0732\n",
      "Last reward =  [-0.0466665]\n",
      "Reward buffer length =  41700\n",
      "Num timesteps: 41800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0574\n",
      "Last reward =  [-0.07151827]\n",
      "Reward buffer length =  41800\n",
      "Num timesteps: 41900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0664\n",
      "Last reward =  [-0.0106608]\n",
      "Reward buffer length =  41900\n",
      "Num timesteps: 42000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0744\n",
      "Last reward =  [-0.05315574]\n",
      "Reward buffer length =  42000\n",
      "Num timesteps: 42100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0185\n",
      "Last reward =  [-0.00939194]\n",
      "Reward buffer length =  42100\n",
      "Num timesteps: 42200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0099\n",
      "Last reward =  [-0.01023916]\n",
      "Reward buffer length =  42200\n",
      "Num timesteps: 42300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0264\n",
      "Last reward =  [0.0015016]\n",
      "Reward buffer length =  42300\n",
      "Num timesteps: 42400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0244\n",
      "Last reward =  [-0.04365675]\n",
      "Reward buffer length =  42400\n",
      "Num timesteps: 42500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0458\n",
      "Last reward =  [-0.05630871]\n",
      "Reward buffer length =  42500\n",
      "Num timesteps: 42600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0657\n",
      "Last reward =  [-0.10754204]\n",
      "Reward buffer length =  42600\n",
      "Num timesteps: 42700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0772\n",
      "Last reward =  [-0.0801602]\n",
      "Reward buffer length =  42700\n",
      "Num timesteps: 42800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0405\n",
      "Last reward =  [-0.00753532]\n",
      "Reward buffer length =  42800\n",
      "Num timesteps: 42900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0389\n",
      "Last reward =  [-0.04776067]\n",
      "Reward buffer length =  42900\n",
      "Num timesteps: 43000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0572\n",
      "Last reward =  [-0.09334505]\n",
      "Reward buffer length =  43000\n",
      "Num timesteps: 43100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0672\n",
      "Last reward =  [-0.03732875]\n",
      "Reward buffer length =  43100\n",
      "Num timesteps: 43200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0692\n",
      "Last reward =  [-0.03100122]\n",
      "Reward buffer length =  43200\n",
      "Num timesteps: 43300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0460\n",
      "Last reward =  [-0.03829991]\n",
      "Reward buffer length =  43300\n",
      "Num timesteps: 43400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0628\n",
      "Last reward =  [0.02060112]\n",
      "Reward buffer length =  43400\n",
      "Num timesteps: 43500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0777\n",
      "Last reward =  [-0.05529006]\n",
      "Reward buffer length =  43500\n",
      "Num timesteps: 43600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0617\n",
      "Last reward =  [-0.09989112]\n",
      "Reward buffer length =  43600\n",
      "Num timesteps: 43700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0688\n",
      "Last reward =  [-0.08624966]\n",
      "Reward buffer length =  43700\n",
      "Num timesteps: 43800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0801\n",
      "Last reward =  [-0.03193929]\n",
      "Reward buffer length =  43800\n",
      "Num timesteps: 43900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0273\n",
      "Last reward =  [0.01935956]\n",
      "Reward buffer length =  43900\n",
      "Num timesteps: 44000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: 0.0001\n",
      "Last reward =  [-0.00095431]\n",
      "Reward buffer length =  44000\n",
      "Num timesteps: 44100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0076\n",
      "Last reward =  [-0.03089151]\n",
      "Reward buffer length =  44100\n",
      "Num timesteps: 44200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0137\n",
      "Last reward =  [-0.00969578]\n",
      "Reward buffer length =  44200\n",
      "Num timesteps: 44300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0270\n",
      "Last reward =  [-0.05986138]\n",
      "Reward buffer length =  44300\n",
      "Num timesteps: 44400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0367\n",
      "Last reward =  [-0.04681704]\n",
      "Reward buffer length =  44400\n",
      "Num timesteps: 44500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0543\n",
      "Last reward =  [-0.06667538]\n",
      "Reward buffer length =  44500\n",
      "Num timesteps: 44600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0720\n",
      "Last reward =  [-0.07243034]\n",
      "Reward buffer length =  44600\n",
      "Num timesteps: 44700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0775\n",
      "Last reward =  [-0.01966516]\n",
      "Reward buffer length =  44700\n",
      "Num timesteps: 44800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0138\n",
      "Last reward =  [-0.02120327]\n",
      "Reward buffer length =  44800\n",
      "Num timesteps: 44900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0139\n",
      "Last reward =  [-0.00636087]\n",
      "Reward buffer length =  44900\n",
      "Num timesteps: 45000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0194\n",
      "Last reward =  [-0.05375591]\n",
      "Reward buffer length =  45000\n",
      "Num timesteps: 45100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0241\n",
      "Last reward =  [-0.07004377]\n",
      "Reward buffer length =  45100\n",
      "Num timesteps: 45200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0423\n",
      "Last reward =  [-0.07623808]\n",
      "Reward buffer length =  45200\n",
      "Num timesteps: 45300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0575\n",
      "Last reward =  [-0.01142522]\n",
      "Reward buffer length =  45300\n",
      "Num timesteps: 45400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0695\n",
      "Last reward =  [-0.11293158]\n",
      "Reward buffer length =  45400\n",
      "Num timesteps: 45500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0733\n",
      "Last reward =  [0.06609064]\n",
      "Reward buffer length =  45500\n",
      "Num timesteps: 45600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0035\n",
      "Last reward =  [-0.00258997]\n",
      "Reward buffer length =  45600\n",
      "Num timesteps: 45700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0074\n",
      "Last reward =  [-0.03389651]\n",
      "Reward buffer length =  45700\n",
      "Num timesteps: 45800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0172\n",
      "Last reward =  [-0.02411036]\n",
      "Reward buffer length =  45800\n",
      "Num timesteps: 45900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0294\n",
      "Last reward =  [-0.04574348]\n",
      "Reward buffer length =  45900\n",
      "Num timesteps: 46000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0300\n",
      "Last reward =  [-0.05909805]\n",
      "Reward buffer length =  46000\n",
      "Num timesteps: 46100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0505\n",
      "Last reward =  [-0.00210593]\n",
      "Reward buffer length =  46100\n",
      "Num timesteps: 46200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0685\n",
      "Last reward =  [-0.09126835]\n",
      "Reward buffer length =  46200\n",
      "Num timesteps: 46300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0840\n",
      "Last reward =  [-0.09000619]\n",
      "Reward buffer length =  46300\n",
      "Num timesteps: 46400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0404\n",
      "Last reward =  [-0.00882397]\n",
      "Reward buffer length =  46400\n",
      "Num timesteps: 46500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0229\n",
      "Last reward =  [-0.05603118]\n",
      "Reward buffer length =  46500\n",
      "Num timesteps: 46600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0261\n",
      "Last reward =  [-0.06976928]\n",
      "Reward buffer length =  46600\n",
      "Num timesteps: 46700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0413\n",
      "Last reward =  [-0.08351019]\n",
      "Reward buffer length =  46700\n",
      "Num timesteps: 46800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0581\n",
      "Last reward =  [-0.02421369]\n",
      "Reward buffer length =  46800\n",
      "Num timesteps: 46900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0709\n",
      "Last reward =  [-0.11600617]\n",
      "Reward buffer length =  46900\n",
      "Num timesteps: 47000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0804\n",
      "Last reward =  [-0.0862631]\n",
      "Reward buffer length =  47000\n",
      "Num timesteps: 47100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0424\n",
      "Last reward =  [-0.00945622]\n",
      "Reward buffer length =  47100\n",
      "Num timesteps: 47200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0612\n",
      "Last reward =  [-0.06321156]\n",
      "Reward buffer length =  47200\n",
      "Num timesteps: 47300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0761\n",
      "Last reward =  [-0.09879655]\n",
      "Reward buffer length =  47300\n",
      "Num timesteps: 47400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0730\n",
      "Last reward =  [-0.0939272]\n",
      "Reward buffer length =  47400\n",
      "Num timesteps: 47500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0821\n",
      "Last reward =  [-0.06447235]\n",
      "Reward buffer length =  47500\n",
      "Num timesteps: 47600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0502\n",
      "Last reward =  [0.03763226]\n",
      "Reward buffer length =  47600\n",
      "Num timesteps: 47700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0094\n",
      "Last reward =  [-0.01775798]\n",
      "Reward buffer length =  47700\n",
      "Num timesteps: 47800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0220\n",
      "Last reward =  [-0.04549313]\n",
      "Reward buffer length =  47800\n",
      "Num timesteps: 47900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0381\n",
      "Last reward =  [0.01622918]\n",
      "Reward buffer length =  47900\n",
      "Num timesteps: 48000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0335\n",
      "Last reward =  [-0.10729571]\n",
      "Reward buffer length =  48000\n",
      "Num timesteps: 48100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0552\n",
      "Last reward =  [-0.06426428]\n",
      "Reward buffer length =  48100\n",
      "Num timesteps: 48200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0782\n",
      "Last reward =  [0.00702782]\n",
      "Reward buffer length =  48200\n",
      "Num timesteps: 48300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0865\n",
      "Last reward =  [-0.03014101]\n",
      "Reward buffer length =  48300\n",
      "Num timesteps: 48400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0230\n",
      "Last reward =  [-0.01766138]\n",
      "Reward buffer length =  48400\n",
      "Num timesteps: 48500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0212\n",
      "Last reward =  [-0.06586594]\n",
      "Reward buffer length =  48500\n",
      "Num timesteps: 48600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0316\n",
      "Last reward =  [-0.0442437]\n",
      "Reward buffer length =  48600\n",
      "Num timesteps: 48700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0325\n",
      "Last reward =  [-0.05521728]\n",
      "Reward buffer length =  48700\n",
      "Num timesteps: 48800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0474\n",
      "Last reward =  [-0.04847957]\n",
      "Reward buffer length =  48800\n",
      "Num timesteps: 48900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0636\n",
      "Last reward =  [-0.05449549]\n",
      "Reward buffer length =  48900\n",
      "Num timesteps: 49000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0858\n",
      "Last reward =  [-0.1663874]\n",
      "Reward buffer length =  49000\n",
      "Num timesteps: 49100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0845\n",
      "Last reward =  [-0.08028926]\n",
      "Reward buffer length =  49100\n",
      "Num timesteps: 49200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0828\n",
      "Last reward =  [-0.00665659]\n",
      "Reward buffer length =  49200\n",
      "Num timesteps: 49300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0628\n",
      "Last reward =  [-0.14863734]\n",
      "Reward buffer length =  49300\n",
      "Num timesteps: 49400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0708\n",
      "Last reward =  [-0.05844971]\n",
      "Reward buffer length =  49400\n",
      "Num timesteps: 49500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0936\n",
      "Last reward =  [-0.13459446]\n",
      "Reward buffer length =  49500\n",
      "Num timesteps: 49600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0491\n",
      "Last reward =  [-0.07209363]\n",
      "Reward buffer length =  49600\n",
      "Num timesteps: 49700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0625\n",
      "Last reward =  [-0.10715466]\n",
      "Reward buffer length =  49700\n",
      "Num timesteps: 49800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0859\n",
      "Last reward =  [-0.15861864]\n",
      "Reward buffer length =  49800\n",
      "Num timesteps: 49900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0636\n",
      "Last reward =  [-0.1001856]\n",
      "Reward buffer length =  49900\n",
      "Num timesteps: 50000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0631\n",
      "Last reward =  [-0.11974265]\n",
      "Reward buffer length =  50000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 50100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0793\n",
      "Last reward =  [-0.11972713]\n",
      "Reward buffer length =  50100\n",
      "Num timesteps: 50200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0930\n",
      "Last reward =  [-0.10597183]\n",
      "Reward buffer length =  50200\n",
      "Num timesteps: 50300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0787\n",
      "Last reward =  [-0.08150087]\n",
      "Reward buffer length =  50300\n",
      "Num timesteps: 50400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0234\n",
      "Last reward =  [-0.069811]\n",
      "Reward buffer length =  50400\n",
      "Num timesteps: 50500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0313\n",
      "Last reward =  [-0.01484846]\n",
      "Reward buffer length =  50500\n",
      "Num timesteps: 50600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0464\n",
      "Last reward =  [-0.06296865]\n",
      "Reward buffer length =  50600\n",
      "Num timesteps: 50700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0567\n",
      "Last reward =  [-0.0363129]\n",
      "Reward buffer length =  50700\n",
      "Num timesteps: 50800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0774\n",
      "Last reward =  [-0.13101633]\n",
      "Reward buffer length =  50800\n",
      "Num timesteps: 50900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0932\n",
      "Last reward =  [0.03681814]\n",
      "Reward buffer length =  50900\n",
      "Num timesteps: 51000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0042\n",
      "Last reward =  [0.02180129]\n",
      "Reward buffer length =  51000\n",
      "Num timesteps: 51100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0169\n",
      "Last reward =  [-0.02147442]\n",
      "Reward buffer length =  51100\n",
      "Num timesteps: 51200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0238\n",
      "Last reward =  [-0.03174073]\n",
      "Reward buffer length =  51200\n",
      "Num timesteps: 51300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0334\n",
      "Last reward =  [-0.0351715]\n",
      "Reward buffer length =  51300\n",
      "Num timesteps: 51400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0423\n",
      "Last reward =  [-0.09702814]\n",
      "Reward buffer length =  51400\n",
      "Num timesteps: 51500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0575\n",
      "Last reward =  [-0.09497069]\n",
      "Reward buffer length =  51500\n",
      "Num timesteps: 51600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0753\n",
      "Last reward =  [-0.07025945]\n",
      "Reward buffer length =  51600\n",
      "Num timesteps: 51700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0955\n",
      "Last reward =  [-0.06145902]\n",
      "Reward buffer length =  51700\n",
      "Num timesteps: 51800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0409\n",
      "Last reward =  [-0.01680703]\n",
      "Reward buffer length =  51800\n",
      "Num timesteps: 51900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0179\n",
      "Last reward =  [-0.06727155]\n",
      "Reward buffer length =  51900\n",
      "Num timesteps: 52000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0243\n",
      "Last reward =  [-0.02624657]\n",
      "Reward buffer length =  52000\n",
      "Num timesteps: 52100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0379\n",
      "Last reward =  [-0.14366718]\n",
      "Reward buffer length =  52100\n",
      "Num timesteps: 52200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0407\n",
      "Last reward =  [-0.05982203]\n",
      "Reward buffer length =  52200\n",
      "Num timesteps: 52300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0611\n",
      "Last reward =  [-0.12305082]\n",
      "Reward buffer length =  52300\n",
      "Num timesteps: 52400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0769\n",
      "Last reward =  [-0.00386686]\n",
      "Reward buffer length =  52400\n",
      "Num timesteps: 52500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1005\n",
      "Last reward =  [-0.10320977]\n",
      "Reward buffer length =  52500\n",
      "Num timesteps: 52600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0841\n",
      "Last reward =  [-0.0615363]\n",
      "Reward buffer length =  52600\n",
      "Num timesteps: 52700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0892\n",
      "Last reward =  [-0.0564443]\n",
      "Reward buffer length =  52700\n",
      "Num timesteps: 52800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0330\n",
      "Last reward =  [-0.02273784]\n",
      "Reward buffer length =  52800\n",
      "Num timesteps: 52900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0507\n",
      "Last reward =  [0.01055379]\n",
      "Reward buffer length =  52900\n",
      "Num timesteps: 53000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0670\n",
      "Last reward =  [0.02400677]\n",
      "Reward buffer length =  53000\n",
      "Num timesteps: 53100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0885\n",
      "Last reward =  [-0.12871344]\n",
      "Reward buffer length =  53100\n",
      "Num timesteps: 53200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0925\n",
      "Last reward =  [-0.04743846]\n",
      "Reward buffer length =  53200\n",
      "Num timesteps: 53300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0446\n",
      "Last reward =  [-0.1299879]\n",
      "Reward buffer length =  53300\n",
      "Num timesteps: 53400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0359\n",
      "Last reward =  [-0.00629818]\n",
      "Reward buffer length =  53400\n",
      "Num timesteps: 53500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0589\n",
      "Last reward =  [-0.02702838]\n",
      "Reward buffer length =  53500\n",
      "Num timesteps: 53600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0895\n",
      "Last reward =  [-0.08207623]\n",
      "Reward buffer length =  53600\n",
      "Num timesteps: 53700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0977\n",
      "Last reward =  [-0.14130372]\n",
      "Reward buffer length =  53700\n",
      "Num timesteps: 53800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0540\n",
      "Last reward =  [0.03675997]\n",
      "Reward buffer length =  53800\n",
      "Num timesteps: 53900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0457\n",
      "Last reward =  [-0.05343211]\n",
      "Reward buffer length =  53900\n",
      "Num timesteps: 54000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0618\n",
      "Last reward =  [-0.09662186]\n",
      "Reward buffer length =  54000\n",
      "Num timesteps: 54100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0814\n",
      "Last reward =  [-0.16269422]\n",
      "Reward buffer length =  54100\n",
      "Num timesteps: 54200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1015\n",
      "Last reward =  [-0.1784829]\n",
      "Reward buffer length =  54200\n",
      "Num timesteps: 54300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0555\n",
      "Last reward =  [-0.00376232]\n",
      "Reward buffer length =  54300\n",
      "Num timesteps: 54400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0629\n",
      "Last reward =  [-0.09375735]\n",
      "Reward buffer length =  54400\n",
      "Num timesteps: 54500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0857\n",
      "Last reward =  [-0.06097804]\n",
      "Reward buffer length =  54500\n",
      "Num timesteps: 54600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0976\n",
      "Last reward =  [-0.08297788]\n",
      "Reward buffer length =  54600\n",
      "Num timesteps: 54700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0904\n",
      "Last reward =  [-0.00377909]\n",
      "Reward buffer length =  54700\n",
      "Num timesteps: 54800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0194\n",
      "Last reward =  [-0.00089094]\n",
      "Reward buffer length =  54800\n",
      "Num timesteps: 54900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0278\n",
      "Last reward =  [-0.02368019]\n",
      "Reward buffer length =  54900\n",
      "Num timesteps: 55000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0393\n",
      "Last reward =  [-0.03516265]\n",
      "Reward buffer length =  55000\n",
      "Num timesteps: 55100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0526\n",
      "Last reward =  [-0.05308398]\n",
      "Reward buffer length =  55100\n",
      "Num timesteps: 55200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0661\n",
      "Last reward =  [-0.06966135]\n",
      "Reward buffer length =  55200\n",
      "Num timesteps: 55300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0880\n",
      "Last reward =  [-0.03891612]\n",
      "Reward buffer length =  55300\n",
      "Num timesteps: 55400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1063\n",
      "Last reward =  [-0.00681223]\n",
      "Reward buffer length =  55400\n",
      "Num timesteps: 55500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0075\n",
      "Last reward =  [-0.05395555]\n",
      "Reward buffer length =  55500\n",
      "Num timesteps: 55600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0128\n",
      "Last reward =  [-0.01920828]\n",
      "Reward buffer length =  55600\n",
      "Num timesteps: 55700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0237\n",
      "Last reward =  [-0.01325877]\n",
      "Reward buffer length =  55700\n",
      "Num timesteps: 55800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0409\n",
      "Last reward =  [-0.07714538]\n",
      "Reward buffer length =  55800\n",
      "Num timesteps: 55900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0420\n",
      "Last reward =  [-0.0856984]\n",
      "Reward buffer length =  55900\n",
      "Num timesteps: 56000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0630\n",
      "Last reward =  [-0.09252285]\n",
      "Reward buffer length =  56000\n",
      "Num timesteps: 56100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0837\n",
      "Last reward =  [-0.13433807]\n",
      "Reward buffer length =  56100\n",
      "Num timesteps: 56200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1041\n",
      "Last reward =  [-0.12192217]\n",
      "Reward buffer length =  56200\n",
      "Num timesteps: 56300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0660\n",
      "Last reward =  [-0.07605278]\n",
      "Reward buffer length =  56300\n",
      "Num timesteps: 56400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0416\n",
      "Last reward =  [-0.07270949]\n",
      "Reward buffer length =  56400\n",
      "Num timesteps: 56500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0622\n",
      "Last reward =  [0.0010863]\n",
      "Reward buffer length =  56500\n",
      "Num timesteps: 56600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0774\n",
      "Last reward =  [-0.10952044]\n",
      "Reward buffer length =  56600\n",
      "Num timesteps: 56700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0993\n",
      "Last reward =  [-0.10416763]\n",
      "Reward buffer length =  56700\n",
      "Num timesteps: 56800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0653\n",
      "Last reward =  [0.01887644]\n",
      "Reward buffer length =  56800\n",
      "Num timesteps: 56900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0317\n",
      "Last reward =  [-0.0345066]\n",
      "Reward buffer length =  56900\n",
      "Num timesteps: 57000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0420\n",
      "Last reward =  [-0.04584653]\n",
      "Reward buffer length =  57000\n",
      "Num timesteps: 57100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0620\n",
      "Last reward =  [-0.06772776]\n",
      "Reward buffer length =  57100\n",
      "Num timesteps: 57200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0750\n",
      "Last reward =  [-0.06759222]\n",
      "Reward buffer length =  57200\n",
      "Num timesteps: 57300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0895\n",
      "Last reward =  [-0.13523117]\n",
      "Reward buffer length =  57300\n",
      "Num timesteps: 57400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1099\n",
      "Last reward =  [-0.02062254]\n",
      "Reward buffer length =  57400\n",
      "Num timesteps: 57500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0948\n",
      "Last reward =  [-0.06895407]\n",
      "Reward buffer length =  57500\n",
      "Num timesteps: 57600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0677\n",
      "Last reward =  [-0.00525784]\n",
      "Reward buffer length =  57600\n",
      "Num timesteps: 57700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0793\n",
      "Last reward =  [-0.09017094]\n",
      "Reward buffer length =  57700\n",
      "Num timesteps: 57800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0803\n",
      "Last reward =  [-0.11138847]\n",
      "Reward buffer length =  57800\n",
      "Num timesteps: 57900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1013\n",
      "Last reward =  [-0.08137996]\n",
      "Reward buffer length =  57900\n",
      "Num timesteps: 58000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0760\n",
      "Last reward =  [-0.05509939]\n",
      "Reward buffer length =  58000\n",
      "Num timesteps: 58100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0995\n",
      "Last reward =  [-0.11963589]\n",
      "Reward buffer length =  58100\n",
      "Num timesteps: 58200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0800\n",
      "Last reward =  [-0.06005567]\n",
      "Reward buffer length =  58200\n",
      "Num timesteps: 58300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0990\n",
      "Last reward =  [-0.02201675]\n",
      "Reward buffer length =  58300\n",
      "Num timesteps: 58400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0875\n",
      "Last reward =  [-0.06243612]\n",
      "Reward buffer length =  58400\n",
      "Num timesteps: 58500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0989\n",
      "Last reward =  [-0.0493979]\n",
      "Reward buffer length =  58500\n",
      "Num timesteps: 58600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0397\n",
      "Last reward =  [-0.08943447]\n",
      "Reward buffer length =  58600\n",
      "Num timesteps: 58700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0605\n",
      "Last reward =  [-0.12253486]\n",
      "Reward buffer length =  58700\n",
      "Num timesteps: 58800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0764\n",
      "Last reward =  [-0.05042601]\n",
      "Reward buffer length =  58800\n",
      "Num timesteps: 58900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0826\n",
      "Last reward =  [-0.1603357]\n",
      "Reward buffer length =  58900\n",
      "Num timesteps: 59000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0993\n",
      "Last reward =  [-0.12091096]\n",
      "Reward buffer length =  59000\n",
      "Num timesteps: 59100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0757\n",
      "Last reward =  [-0.02343274]\n",
      "Reward buffer length =  59100\n",
      "Num timesteps: 59200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0842\n",
      "Last reward =  [-0.10224144]\n",
      "Reward buffer length =  59200\n",
      "Num timesteps: 59300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1023\n",
      "Last reward =  [-0.09939032]\n",
      "Reward buffer length =  59300\n",
      "Num timesteps: 59400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0153\n",
      "Last reward =  [-0.03253921]\n",
      "Reward buffer length =  59400\n",
      "Num timesteps: 59500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0293\n",
      "Last reward =  [-0.07637815]\n",
      "Reward buffer length =  59500\n",
      "Num timesteps: 59600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0460\n",
      "Last reward =  [-0.02939363]\n",
      "Reward buffer length =  59600\n",
      "Num timesteps: 59700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0497\n",
      "Last reward =  [-0.130576]\n",
      "Reward buffer length =  59700\n",
      "Num timesteps: 59800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0735\n",
      "Last reward =  [-0.08515816]\n",
      "Reward buffer length =  59800\n",
      "Num timesteps: 59900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0905\n",
      "Last reward =  [-0.10161574]\n",
      "Reward buffer length =  59900\n",
      "Num timesteps: 60000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1022\n",
      "Last reward =  [-0.12660897]\n",
      "Reward buffer length =  60000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 60100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0799\n",
      "Last reward =  [-0.03498846]\n",
      "Reward buffer length =  60100\n",
      "Num timesteps: 60200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0810\n",
      "Last reward =  [-0.05125274]\n",
      "Reward buffer length =  60200\n",
      "Num timesteps: 60300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0842\n",
      "Last reward =  [-0.08541922]\n",
      "Reward buffer length =  60300\n",
      "Num timesteps: 60400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1116\n",
      "Last reward =  [-0.05143036]\n",
      "Reward buffer length =  60400\n",
      "Num timesteps: 60500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1035\n",
      "Last reward =  [-0.12085304]\n",
      "Reward buffer length =  60500\n",
      "Num timesteps: 60600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1012\n",
      "Last reward =  [-0.00197478]\n",
      "Reward buffer length =  60600\n",
      "Num timesteps: 60700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0520\n",
      "Last reward =  [-0.12956998]\n",
      "Reward buffer length =  60700\n",
      "Num timesteps: 60800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0745\n",
      "Last reward =  [0.01650085]\n",
      "Reward buffer length =  60800\n",
      "Num timesteps: 60900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0899\n",
      "Last reward =  [-0.03631125]\n",
      "Reward buffer length =  60900\n",
      "Num timesteps: 61000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1021\n",
      "Last reward =  [-0.09342334]\n",
      "Reward buffer length =  61000\n",
      "Num timesteps: 61100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0811\n",
      "Last reward =  [-0.11940593]\n",
      "Reward buffer length =  61100\n",
      "Num timesteps: 61200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0934\n",
      "Last reward =  [-0.20516358]\n",
      "Reward buffer length =  61200\n",
      "Num timesteps: 61300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1043\n",
      "Last reward =  [-0.11014921]\n",
      "Reward buffer length =  61300\n",
      "Num timesteps: 61400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0940\n",
      "Last reward =  [-0.07633486]\n",
      "Reward buffer length =  61400\n",
      "Num timesteps: 61500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0923\n",
      "Last reward =  [-0.07678188]\n",
      "Reward buffer length =  61500\n",
      "Num timesteps: 61600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1207\n",
      "Last reward =  [-0.11764736]\n",
      "Reward buffer length =  61600\n",
      "Num timesteps: 61700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1084\n",
      "Last reward =  [-0.19058833]\n",
      "Reward buffer length =  61700\n",
      "Num timesteps: 61800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1199\n",
      "Last reward =  [-0.22763626]\n",
      "Reward buffer length =  61800\n",
      "Num timesteps: 61900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1136\n",
      "Last reward =  [-0.1567609]\n",
      "Reward buffer length =  61900\n",
      "Num timesteps: 62000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0725\n",
      "Last reward =  [-0.03874991]\n",
      "Reward buffer length =  62000\n",
      "Num timesteps: 62100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0689\n",
      "Last reward =  [-0.07613176]\n",
      "Reward buffer length =  62100\n",
      "Num timesteps: 62200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0830\n",
      "Last reward =  [0.01927583]\n",
      "Reward buffer length =  62200\n",
      "Num timesteps: 62300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0976\n",
      "Last reward =  [-0.05839361]\n",
      "Reward buffer length =  62300\n",
      "Num timesteps: 62400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1189\n",
      "Last reward =  [-0.09005448]\n",
      "Reward buffer length =  62400\n",
      "Num timesteps: 62500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0434\n",
      "Last reward =  [-0.05795733]\n",
      "Reward buffer length =  62500\n",
      "Num timesteps: 62600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0735\n",
      "Last reward =  [-0.09718121]\n",
      "Reward buffer length =  62600\n",
      "Num timesteps: 62700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0917\n",
      "Last reward =  [-0.12121397]\n",
      "Reward buffer length =  62700\n",
      "Num timesteps: 62800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1098\n",
      "Last reward =  [-0.13813113]\n",
      "Reward buffer length =  62800\n",
      "Num timesteps: 62900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0719\n",
      "Last reward =  [-0.03695743]\n",
      "Reward buffer length =  62900\n",
      "Num timesteps: 63000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0060\n",
      "Last reward =  [-0.04684676]\n",
      "Reward buffer length =  63000\n",
      "Num timesteps: 63100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0148\n",
      "Last reward =  [-0.02056685]\n",
      "Reward buffer length =  63100\n",
      "Num timesteps: 63200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0276\n",
      "Last reward =  [-0.0011314]\n",
      "Reward buffer length =  63200\n",
      "Num timesteps: 63300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0448\n",
      "Last reward =  [-0.03552894]\n",
      "Reward buffer length =  63300\n",
      "Num timesteps: 63400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0543\n",
      "Last reward =  [-0.11103605]\n",
      "Reward buffer length =  63400\n",
      "Num timesteps: 63500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0771\n",
      "Last reward =  [-0.01084055]\n",
      "Reward buffer length =  63500\n",
      "Num timesteps: 63600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1042\n",
      "Last reward =  [-0.20895298]\n",
      "Reward buffer length =  63600\n",
      "Num timesteps: 63700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1059\n",
      "Last reward =  [-0.12257512]\n",
      "Reward buffer length =  63700\n",
      "Num timesteps: 63800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0396\n",
      "Last reward =  [0.01736922]\n",
      "Reward buffer length =  63800\n",
      "Num timesteps: 63900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0209\n",
      "Last reward =  [-0.08257401]\n",
      "Reward buffer length =  63900\n",
      "Num timesteps: 64000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0309\n",
      "Last reward =  [-0.06250206]\n",
      "Reward buffer length =  64000\n",
      "Num timesteps: 64100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0462\n",
      "Last reward =  [0.03488107]\n",
      "Reward buffer length =  64100\n",
      "Num timesteps: 64200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0609\n",
      "Last reward =  [-0.07539945]\n",
      "Reward buffer length =  64200\n",
      "Num timesteps: 64300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0811\n",
      "Last reward =  [-0.12771651]\n",
      "Reward buffer length =  64300\n",
      "Num timesteps: 64400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1009\n",
      "Last reward =  [-0.14568038]\n",
      "Reward buffer length =  64400\n",
      "Num timesteps: 64500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1158\n",
      "Last reward =  [-0.22007057]\n",
      "Reward buffer length =  64500\n",
      "Num timesteps: 64600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0270\n",
      "Last reward =  [0.02471541]\n",
      "Reward buffer length =  64600\n",
      "Num timesteps: 64700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0121\n",
      "Last reward =  [-0.00658642]\n",
      "Reward buffer length =  64700\n",
      "Num timesteps: 64800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0259\n",
      "Last reward =  [-0.00398721]\n",
      "Reward buffer length =  64800\n",
      "Num timesteps: 64900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0438\n",
      "Last reward =  [-0.04099665]\n",
      "Reward buffer length =  64900\n",
      "Num timesteps: 65000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0503\n",
      "Last reward =  [-0.06378777]\n",
      "Reward buffer length =  65000\n",
      "Num timesteps: 65100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0755\n",
      "Last reward =  [-0.11683025]\n",
      "Reward buffer length =  65100\n",
      "Num timesteps: 65200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0942\n",
      "Last reward =  [-0.0813218]\n",
      "Reward buffer length =  65200\n",
      "Num timesteps: 65300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1140\n",
      "Last reward =  [-0.19798689]\n",
      "Reward buffer length =  65300\n",
      "Num timesteps: 65400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0966\n",
      "Last reward =  [-0.03377352]\n",
      "Reward buffer length =  65400\n",
      "Num timesteps: 65500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0440\n",
      "Last reward =  [-0.01949847]\n",
      "Reward buffer length =  65500\n",
      "Num timesteps: 65600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0522\n",
      "Last reward =  [-0.09120832]\n",
      "Reward buffer length =  65600\n",
      "Num timesteps: 65700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0817\n",
      "Last reward =  [-0.11892515]\n",
      "Reward buffer length =  65700\n",
      "Num timesteps: 65800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0927\n",
      "Last reward =  [-0.01349701]\n",
      "Reward buffer length =  65800\n",
      "Num timesteps: 65900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1253\n",
      "Last reward =  [-0.14338374]\n",
      "Reward buffer length =  65900\n",
      "Num timesteps: 66000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0816\n",
      "Last reward =  [-0.04064321]\n",
      "Reward buffer length =  66000\n",
      "Num timesteps: 66100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0563\n",
      "Last reward =  [-0.11609913]\n",
      "Reward buffer length =  66100\n",
      "Num timesteps: 66200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0778\n",
      "Last reward =  [-0.02093971]\n",
      "Reward buffer length =  66200\n",
      "Num timesteps: 66300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1108\n",
      "Last reward =  [-0.21875194]\n",
      "Reward buffer length =  66300\n",
      "Num timesteps: 66400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1119\n",
      "Last reward =  [-0.12106773]\n",
      "Reward buffer length =  66400\n",
      "Num timesteps: 66500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0483\n",
      "Last reward =  [-0.02449164]\n",
      "Reward buffer length =  66500\n",
      "Num timesteps: 66600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0270\n",
      "Last reward =  [-0.01584526]\n",
      "Reward buffer length =  66600\n",
      "Num timesteps: 66700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0394\n",
      "Last reward =  [-0.04651561]\n",
      "Reward buffer length =  66700\n",
      "Num timesteps: 66800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0487\n",
      "Last reward =  [-0.00403127]\n",
      "Reward buffer length =  66800\n",
      "Num timesteps: 66900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0766\n",
      "Last reward =  [-0.05768771]\n",
      "Reward buffer length =  66900\n",
      "Num timesteps: 67000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0885\n",
      "Last reward =  [-0.0049855]\n",
      "Reward buffer length =  67000\n",
      "Num timesteps: 67100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1073\n",
      "Last reward =  [-0.02369871]\n",
      "Reward buffer length =  67100\n",
      "Num timesteps: 67200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1232\n",
      "Last reward =  [-0.01955353]\n",
      "Reward buffer length =  67200\n",
      "Num timesteps: 67300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1259\n",
      "Last reward =  [-0.18072057]\n",
      "Reward buffer length =  67300\n",
      "Num timesteps: 67400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0975\n",
      "Last reward =  [-0.09917491]\n",
      "Reward buffer length =  67400\n",
      "Num timesteps: 67500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1233\n",
      "Last reward =  [-0.10471081]\n",
      "Reward buffer length =  67500\n",
      "Num timesteps: 67600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1102\n",
      "Last reward =  [-0.23430914]\n",
      "Reward buffer length =  67600\n",
      "Num timesteps: 67700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0925\n",
      "Last reward =  [-0.05676358]\n",
      "Reward buffer length =  67700\n",
      "Num timesteps: 67800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0890\n",
      "Last reward =  [-0.10833942]\n",
      "Reward buffer length =  67800\n",
      "Num timesteps: 67900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1098\n",
      "Last reward =  [0.00488632]\n",
      "Reward buffer length =  67900\n",
      "Num timesteps: 68000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1237\n",
      "Last reward =  [-0.04308845]\n",
      "Reward buffer length =  68000\n",
      "Num timesteps: 68100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0518\n",
      "Last reward =  [-0.11381492]\n",
      "Reward buffer length =  68100\n",
      "Num timesteps: 68200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0835\n",
      "Last reward =  [-0.15682788]\n",
      "Reward buffer length =  68200\n",
      "Num timesteps: 68300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0955\n",
      "Last reward =  [-0.06445428]\n",
      "Reward buffer length =  68300\n",
      "Num timesteps: 68400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1213\n",
      "Last reward =  [-0.19073834]\n",
      "Reward buffer length =  68400\n",
      "Num timesteps: 68500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1357\n",
      "Last reward =  [-0.0625524]\n",
      "Reward buffer length =  68500\n",
      "Num timesteps: 68600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0784\n",
      "Last reward =  [-0.02023489]\n",
      "Reward buffer length =  68600\n",
      "Num timesteps: 68700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0280\n",
      "Last reward =  [-0.02592051]\n",
      "Reward buffer length =  68700\n",
      "Num timesteps: 68800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0354\n",
      "Last reward =  [-0.06056212]\n",
      "Reward buffer length =  68800\n",
      "Num timesteps: 68900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0546\n",
      "Last reward =  [-0.10258853]\n",
      "Reward buffer length =  68900\n",
      "Num timesteps: 69000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0761\n",
      "Last reward =  [-0.15021133]\n",
      "Reward buffer length =  69000\n",
      "Num timesteps: 69100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0925\n",
      "Last reward =  [-0.13472463]\n",
      "Reward buffer length =  69100\n",
      "Num timesteps: 69200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1103\n",
      "Last reward =  [-0.12374382]\n",
      "Reward buffer length =  69200\n",
      "Num timesteps: 69300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1299\n",
      "Last reward =  [-0.09672012]\n",
      "Reward buffer length =  69300\n",
      "Num timesteps: 69400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0284\n",
      "Last reward =  [-0.04055856]\n",
      "Reward buffer length =  69400\n",
      "Num timesteps: 69500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0342\n",
      "Last reward =  [-0.04796656]\n",
      "Reward buffer length =  69500\n",
      "Num timesteps: 69600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0580\n",
      "Last reward =  [0.00627298]\n",
      "Reward buffer length =  69600\n",
      "Num timesteps: 69700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0676\n",
      "Last reward =  [0.00403862]\n",
      "Reward buffer length =  69700\n",
      "Num timesteps: 69800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0848\n",
      "Last reward =  [-0.015581]\n",
      "Reward buffer length =  69800\n",
      "Num timesteps: 69900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1140\n",
      "Last reward =  [-0.0925676]\n",
      "Reward buffer length =  69900\n",
      "Num timesteps: 70000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1224\n",
      "Last reward =  [-0.137933]\n",
      "Reward buffer length =  70000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 70100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0848\n",
      "Last reward =  [-0.12741357]\n",
      "Reward buffer length =  70100\n",
      "Num timesteps: 70200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0869\n",
      "Last reward =  [-0.04229194]\n",
      "Reward buffer length =  70200\n",
      "Num timesteps: 70300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1180\n",
      "Last reward =  [-0.22542733]\n",
      "Reward buffer length =  70300\n",
      "Num timesteps: 70400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1212\n",
      "Last reward =  [-0.10638487]\n",
      "Reward buffer length =  70400\n",
      "Num timesteps: 70500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1062\n",
      "Last reward =  [-0.13117239]\n",
      "Reward buffer length =  70500\n",
      "Num timesteps: 70600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0892\n",
      "Last reward =  [0.01352249]\n",
      "Reward buffer length =  70600\n",
      "Num timesteps: 70700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1189\n",
      "Last reward =  [-0.15402582]\n",
      "Reward buffer length =  70700\n",
      "Num timesteps: 70800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1224\n",
      "Last reward =  [-0.00218312]\n",
      "Reward buffer length =  70800\n",
      "Num timesteps: 70900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0295\n",
      "Last reward =  [-0.0224815]\n",
      "Reward buffer length =  70900\n",
      "Num timesteps: 71000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0485\n",
      "Last reward =  [-0.07381819]\n",
      "Reward buffer length =  71000\n",
      "Num timesteps: 71100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0551\n",
      "Last reward =  [-0.05835099]\n",
      "Reward buffer length =  71100\n",
      "Num timesteps: 71200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0890\n",
      "Last reward =  [-0.14115414]\n",
      "Reward buffer length =  71200\n",
      "Num timesteps: 71300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1034\n",
      "Last reward =  [-0.1703348]\n",
      "Reward buffer length =  71300\n",
      "Num timesteps: 71400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1242\n",
      "Last reward =  [0.00271822]\n",
      "Reward buffer length =  71400\n",
      "Num timesteps: 71500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1112\n",
      "Last reward =  [-0.00895125]\n",
      "Reward buffer length =  71500\n",
      "Num timesteps: 71600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0103\n",
      "Last reward =  [-0.02477834]\n",
      "Reward buffer length =  71600\n",
      "Num timesteps: 71700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0299\n",
      "Last reward =  [-0.08249915]\n",
      "Reward buffer length =  71700\n",
      "Num timesteps: 71800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0361\n",
      "Last reward =  [-0.05410901]\n",
      "Reward buffer length =  71800\n",
      "Num timesteps: 71900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0590\n",
      "Last reward =  [-0.11083413]\n",
      "Reward buffer length =  71900\n",
      "Num timesteps: 72000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0743\n",
      "Last reward =  [-0.1020971]\n",
      "Reward buffer length =  72000\n",
      "Num timesteps: 72100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0967\n",
      "Last reward =  [-0.18278186]\n",
      "Reward buffer length =  72100\n",
      "Num timesteps: 72200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1201\n",
      "Last reward =  [-0.03378213]\n",
      "Reward buffer length =  72200\n",
      "Num timesteps: 72300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1332\n",
      "Last reward =  [-0.12631412]\n",
      "Reward buffer length =  72300\n",
      "Num timesteps: 72400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1037\n",
      "Last reward =  [-0.10434712]\n",
      "Reward buffer length =  72400\n",
      "Num timesteps: 72500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1122\n",
      "Last reward =  [-0.17980984]\n",
      "Reward buffer length =  72500\n",
      "Num timesteps: 72600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1386\n",
      "Last reward =  [-0.2605407]\n",
      "Reward buffer length =  72600\n",
      "Num timesteps: 72700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1001\n",
      "Last reward =  [-0.09499252]\n",
      "Reward buffer length =  72700\n",
      "Num timesteps: 72800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0584\n",
      "Last reward =  [-0.09410583]\n",
      "Reward buffer length =  72800\n",
      "Num timesteps: 72900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0903\n",
      "Last reward =  [-0.13976556]\n",
      "Reward buffer length =  72900\n",
      "Num timesteps: 73000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0947\n",
      "Last reward =  [0.00919367]\n",
      "Reward buffer length =  73000\n",
      "Num timesteps: 73100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1240\n",
      "Last reward =  [-0.18399556]\n",
      "Reward buffer length =  73100\n",
      "Num timesteps: 73200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1366\n",
      "Last reward =  [-0.14819627]\n",
      "Reward buffer length =  73200\n",
      "Num timesteps: 73300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0941\n",
      "Last reward =  [-0.04116654]\n",
      "Reward buffer length =  73300\n",
      "Num timesteps: 73400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1066\n",
      "Last reward =  [-0.11880307]\n",
      "Reward buffer length =  73400\n",
      "Num timesteps: 73500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1360\n",
      "Last reward =  [-0.24980782]\n",
      "Reward buffer length =  73500\n",
      "Num timesteps: 73600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1232\n",
      "Last reward =  [-0.04181529]\n",
      "Reward buffer length =  73600\n",
      "Num timesteps: 73700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1242\n",
      "Last reward =  [-0.18204977]\n",
      "Reward buffer length =  73700\n",
      "Num timesteps: 73800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1418\n",
      "Last reward =  [-0.19884609]\n",
      "Reward buffer length =  73800\n",
      "Num timesteps: 73900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1125\n",
      "Last reward =  [0.07572442]\n",
      "Reward buffer length =  73900\n",
      "Num timesteps: 74000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0133\n",
      "Last reward =  [-0.0554566]\n",
      "Reward buffer length =  74000\n",
      "Num timesteps: 74100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0309\n",
      "Last reward =  [-0.07489834]\n",
      "Reward buffer length =  74100\n",
      "Num timesteps: 74200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0426\n",
      "Last reward =  [-0.050995]\n",
      "Reward buffer length =  74200\n",
      "Num timesteps: 74300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0608\n",
      "Last reward =  [-0.0298568]\n",
      "Reward buffer length =  74300\n",
      "Num timesteps: 74400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0928\n",
      "Last reward =  [-0.14014012]\n",
      "Reward buffer length =  74400\n",
      "Num timesteps: 74500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1056\n",
      "Last reward =  [-0.20294034]\n",
      "Reward buffer length =  74500\n",
      "Num timesteps: 74600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1287\n",
      "Last reward =  [-0.09892226]\n",
      "Reward buffer length =  74600\n",
      "Num timesteps: 74700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1527\n",
      "Last reward =  [-0.01575983]\n",
      "Reward buffer length =  74700\n",
      "Num timesteps: 74800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0334\n",
      "Last reward =  [-0.0327975]\n",
      "Reward buffer length =  74800\n",
      "Num timesteps: 74900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0449\n",
      "Last reward =  [-0.08546964]\n",
      "Reward buffer length =  74900\n",
      "Num timesteps: 75000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0608\n",
      "Last reward =  [-0.02624091]\n",
      "Reward buffer length =  75000\n",
      "Num timesteps: 75100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0897\n",
      "Last reward =  [-0.0807224]\n",
      "Reward buffer length =  75100\n",
      "Num timesteps: 75200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1059\n",
      "Last reward =  [-0.09182389]\n",
      "Reward buffer length =  75200\n",
      "Num timesteps: 75300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1269\n",
      "Last reward =  [-0.1899913]\n",
      "Reward buffer length =  75300\n",
      "Num timesteps: 75400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1503\n",
      "Last reward =  [-0.12969112]\n",
      "Reward buffer length =  75400\n",
      "Num timesteps: 75500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0631\n",
      "Last reward =  [-0.1131123]\n",
      "Reward buffer length =  75500\n",
      "Num timesteps: 75600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0662\n",
      "Last reward =  [0.00546848]\n",
      "Reward buffer length =  75600\n",
      "Num timesteps: 75700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1006\n",
      "Last reward =  [-0.08849223]\n",
      "Reward buffer length =  75700\n",
      "Num timesteps: 75800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1307\n",
      "Last reward =  [-0.25404394]\n",
      "Reward buffer length =  75800\n",
      "Num timesteps: 75900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1411\n",
      "Last reward =  [-0.1404112]\n",
      "Reward buffer length =  75900\n",
      "Num timesteps: 76000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1103\n",
      "Last reward =  [-0.12458041]\n",
      "Reward buffer length =  76000\n",
      "Num timesteps: 76100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1353\n",
      "Last reward =  [-0.14585179]\n",
      "Reward buffer length =  76100\n",
      "Num timesteps: 76200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1390\n",
      "Last reward =  [-0.0573051]\n",
      "Reward buffer length =  76200\n",
      "Num timesteps: 76300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0563\n",
      "Last reward =  [-0.04018669]\n",
      "Reward buffer length =  76300\n",
      "Num timesteps: 76400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0348\n",
      "Last reward =  [-0.06788574]\n",
      "Reward buffer length =  76400\n",
      "Num timesteps: 76500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0541\n",
      "Last reward =  [-0.12431016]\n",
      "Reward buffer length =  76500\n",
      "Num timesteps: 76600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0624\n",
      "Last reward =  [-0.10549618]\n",
      "Reward buffer length =  76600\n",
      "Num timesteps: 76700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1008\n",
      "Last reward =  [-0.12580441]\n",
      "Reward buffer length =  76700\n",
      "Num timesteps: 76800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1175\n",
      "Last reward =  [-0.21655633]\n",
      "Reward buffer length =  76800\n",
      "Num timesteps: 76900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1418\n",
      "Last reward =  [-0.20210932]\n",
      "Reward buffer length =  76900\n",
      "Num timesteps: 77000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1707\n",
      "Last reward =  [-0.2895532]\n",
      "Reward buffer length =  77000\n",
      "Num timesteps: 77100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1255\n",
      "Last reward =  [-0.07981532]\n",
      "Reward buffer length =  77100\n",
      "Num timesteps: 77200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0481\n",
      "Last reward =  [-0.04988871]\n",
      "Reward buffer length =  77200\n",
      "Num timesteps: 77300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0629\n",
      "Last reward =  [-0.0416044]\n",
      "Reward buffer length =  77300\n",
      "Num timesteps: 77400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0968\n",
      "Last reward =  [-0.16169536]\n",
      "Reward buffer length =  77400\n",
      "Num timesteps: 77500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1044\n",
      "Last reward =  [-0.2326448]\n",
      "Reward buffer length =  77500\n",
      "Num timesteps: 77600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1306\n",
      "Last reward =  [-0.09633084]\n",
      "Reward buffer length =  77600\n",
      "Num timesteps: 77700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1570\n",
      "Last reward =  [-0.04357068]\n",
      "Reward buffer length =  77700\n",
      "Num timesteps: 77800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0441\n",
      "Last reward =  [-0.07476265]\n",
      "Reward buffer length =  77800\n",
      "Num timesteps: 77900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0696\n",
      "Last reward =  [-0.07026685]\n",
      "Reward buffer length =  77900\n",
      "Num timesteps: 78000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0742\n",
      "Last reward =  [-0.04632096]\n",
      "Reward buffer length =  78000\n",
      "Num timesteps: 78100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1016\n",
      "Last reward =  [-0.16664489]\n",
      "Reward buffer length =  78100\n",
      "Num timesteps: 78200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1375\n",
      "Last reward =  [-0.14848308]\n",
      "Reward buffer length =  78200\n",
      "Num timesteps: 78300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1457\n",
      "Last reward =  [-0.21258527]\n",
      "Reward buffer length =  78300\n",
      "Num timesteps: 78400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1449\n",
      "Last reward =  [-0.17905378]\n",
      "Reward buffer length =  78400\n",
      "Num timesteps: 78500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1410\n",
      "Last reward =  [-0.03253531]\n",
      "Reward buffer length =  78500\n",
      "Num timesteps: 78600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0104\n",
      "Last reward =  [-0.02665084]\n",
      "Reward buffer length =  78600\n",
      "Num timesteps: 78700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0277\n",
      "Last reward =  [-0.02463181]\n",
      "Reward buffer length =  78700\n",
      "Num timesteps: 78800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0424\n",
      "Last reward =  [-0.03346041]\n",
      "Reward buffer length =  78800\n",
      "Num timesteps: 78900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0634\n",
      "Last reward =  [-0.08255925]\n",
      "Reward buffer length =  78900\n",
      "Num timesteps: 79000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0757\n",
      "Last reward =  [-0.14796652]\n",
      "Reward buffer length =  79000\n",
      "Num timesteps: 79100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1055\n",
      "Last reward =  [-0.02817077]\n",
      "Reward buffer length =  79100\n",
      "Num timesteps: 79200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1258\n",
      "Last reward =  [-0.21440032]\n",
      "Reward buffer length =  79200\n",
      "Num timesteps: 79300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1605\n",
      "Last reward =  [0.00511101]\n",
      "Reward buffer length =  79300\n",
      "Num timesteps: 79400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1190\n",
      "Last reward =  [-0.17740774]\n",
      "Reward buffer length =  79400\n",
      "Num timesteps: 79500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1047\n",
      "Last reward =  [-0.22218949]\n",
      "Reward buffer length =  79500\n",
      "Num timesteps: 79600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1348\n",
      "Last reward =  [-0.00773503]\n",
      "Reward buffer length =  79600\n",
      "Num timesteps: 79700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1469\n",
      "Last reward =  [0.00980412]\n",
      "Reward buffer length =  79700\n",
      "Num timesteps: 79800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0741\n",
      "Last reward =  [-0.00655516]\n",
      "Reward buffer length =  79800\n",
      "Num timesteps: 79900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0686\n",
      "Last reward =  [0.00817141]\n",
      "Reward buffer length =  79900\n",
      "Num timesteps: 80000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0852\n",
      "Last reward =  [-0.06765052]\n",
      "Reward buffer length =  80000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 80100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1028\n",
      "Last reward =  [-0.14712743]\n",
      "Reward buffer length =  80100\n",
      "Num timesteps: 80200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1335\n",
      "Last reward =  [0.0100153]\n",
      "Reward buffer length =  80200\n",
      "Num timesteps: 80300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1482\n",
      "Last reward =  [-0.14799123]\n",
      "Reward buffer length =  80300\n",
      "Num timesteps: 80400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1452\n",
      "Last reward =  [-0.11568409]\n",
      "Reward buffer length =  80400\n",
      "Num timesteps: 80500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1577\n",
      "Last reward =  [-0.21000907]\n",
      "Reward buffer length =  80500\n",
      "Num timesteps: 80600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0191\n",
      "Last reward =  [-0.05011]\n",
      "Reward buffer length =  80600\n",
      "Num timesteps: 80700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0401\n",
      "Last reward =  [-0.03399093]\n",
      "Reward buffer length =  80700\n",
      "Num timesteps: 80800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0542\n",
      "Last reward =  [-0.06324093]\n",
      "Reward buffer length =  80800\n",
      "Num timesteps: 80900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0639\n",
      "Last reward =  [-0.09865313]\n",
      "Reward buffer length =  80900\n",
      "Num timesteps: 81000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1037\n",
      "Last reward =  [-0.02366805]\n",
      "Reward buffer length =  81000\n",
      "Num timesteps: 81100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1013\n",
      "Last reward =  [-0.227542]\n",
      "Reward buffer length =  81100\n",
      "Num timesteps: 81200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1380\n",
      "Last reward =  [-0.2308952]\n",
      "Reward buffer length =  81200\n",
      "Num timesteps: 81300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1474\n",
      "Last reward =  [-0.06700585]\n",
      "Reward buffer length =  81300\n",
      "Num timesteps: 81400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1573\n",
      "Last reward =  [-0.0958828]\n",
      "Reward buffer length =  81400\n",
      "Num timesteps: 81500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1624\n",
      "Last reward =  [-0.1777357]\n",
      "Reward buffer length =  81500\n",
      "Num timesteps: 81600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1087\n",
      "Last reward =  [-0.01901978]\n",
      "Reward buffer length =  81600\n",
      "Num timesteps: 81700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1311\n",
      "Last reward =  [-0.09864581]\n",
      "Reward buffer length =  81700\n",
      "Num timesteps: 81800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1649\n",
      "Last reward =  [-0.15978594]\n",
      "Reward buffer length =  81800\n",
      "Num timesteps: 81900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1341\n",
      "Last reward =  [-0.20395522]\n",
      "Reward buffer length =  81900\n",
      "Num timesteps: 82000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1536\n",
      "Last reward =  [-0.02370664]\n",
      "Reward buffer length =  82000\n",
      "Num timesteps: 82100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1023\n",
      "Last reward =  [-0.07590791]\n",
      "Reward buffer length =  82100\n",
      "Num timesteps: 82200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0940\n",
      "Last reward =  [-0.14984131]\n",
      "Reward buffer length =  82200\n",
      "Num timesteps: 82300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1088\n",
      "Last reward =  [-0.04013273]\n",
      "Reward buffer length =  82300\n",
      "Num timesteps: 82400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1357\n",
      "Last reward =  [-0.05617553]\n",
      "Reward buffer length =  82400\n",
      "Num timesteps: 82500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1645\n",
      "Last reward =  [-0.3167175]\n",
      "Reward buffer length =  82500\n",
      "Num timesteps: 82600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0739\n",
      "Last reward =  [-0.08367349]\n",
      "Reward buffer length =  82600\n",
      "Num timesteps: 82700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0661\n",
      "Last reward =  [-0.1073271]\n",
      "Reward buffer length =  82700\n",
      "Num timesteps: 82800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1065\n",
      "Last reward =  [-0.08149685]\n",
      "Reward buffer length =  82800\n",
      "Num timesteps: 82900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1084\n",
      "Last reward =  [-0.19035861]\n",
      "Reward buffer length =  82900\n",
      "Num timesteps: 83000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1493\n",
      "Last reward =  [-0.22714578]\n",
      "Reward buffer length =  83000\n",
      "Num timesteps: 83100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1703\n",
      "Last reward =  [-0.21219467]\n",
      "Reward buffer length =  83100\n",
      "Num timesteps: 83200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1530\n",
      "Last reward =  [-0.10513116]\n",
      "Reward buffer length =  83200\n",
      "Num timesteps: 83300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1270\n",
      "Last reward =  [0.00908891]\n",
      "Reward buffer length =  83300\n",
      "Num timesteps: 83400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0191\n",
      "Last reward =  [-0.04239799]\n",
      "Reward buffer length =  83400\n",
      "Num timesteps: 83500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0411\n",
      "Last reward =  [-0.03763002]\n",
      "Reward buffer length =  83500\n",
      "Num timesteps: 83600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0599\n",
      "Last reward =  [-0.08774751]\n",
      "Reward buffer length =  83600\n",
      "Num timesteps: 83700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0655\n",
      "Last reward =  [-0.0061954]\n",
      "Reward buffer length =  83700\n",
      "Num timesteps: 83800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1014\n",
      "Last reward =  [-0.09561055]\n",
      "Reward buffer length =  83800\n",
      "Num timesteps: 83900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1105\n",
      "Last reward =  [-0.09605557]\n",
      "Reward buffer length =  83900\n",
      "Num timesteps: 84000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1503\n",
      "Last reward =  [-0.12362434]\n",
      "Reward buffer length =  84000\n",
      "Num timesteps: 84100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1562\n",
      "Last reward =  [-0.13601945]\n",
      "Reward buffer length =  84100\n",
      "Num timesteps: 84200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1345\n",
      "Last reward =  [-0.17891337]\n",
      "Reward buffer length =  84200\n",
      "Num timesteps: 84300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0980\n",
      "Last reward =  [-0.15812269]\n",
      "Reward buffer length =  84300\n",
      "Num timesteps: 84400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1309\n",
      "Last reward =  [-0.13040458]\n",
      "Reward buffer length =  84400\n",
      "Num timesteps: 84500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1253\n",
      "Last reward =  [-0.13453743]\n",
      "Reward buffer length =  84500\n",
      "Num timesteps: 84600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1066\n",
      "Last reward =  [-0.08997156]\n",
      "Reward buffer length =  84600\n",
      "Num timesteps: 84700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0925\n",
      "Last reward =  [-0.09409748]\n",
      "Reward buffer length =  84700\n",
      "Num timesteps: 84800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1313\n",
      "Last reward =  [-0.16511552]\n",
      "Reward buffer length =  84800\n",
      "Num timesteps: 84900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1145\n",
      "Last reward =  [-0.09455375]\n",
      "Reward buffer length =  84900\n",
      "Num timesteps: 85000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1224\n",
      "Last reward =  [-0.08244827]\n",
      "Reward buffer length =  85000\n",
      "Num timesteps: 85100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1063\n",
      "Last reward =  [-0.07092145]\n",
      "Reward buffer length =  85100\n",
      "Num timesteps: 85200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1323\n",
      "Last reward =  [-0.04568924]\n",
      "Reward buffer length =  85200\n",
      "Num timesteps: 85300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1294\n",
      "Last reward =  [0.02568918]\n",
      "Reward buffer length =  85300\n",
      "Num timesteps: 85400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1237\n",
      "Last reward =  [-0.08600413]\n",
      "Reward buffer length =  85400\n",
      "Num timesteps: 85500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1080\n",
      "Last reward =  [-0.13331458]\n",
      "Reward buffer length =  85500\n",
      "Num timesteps: 85600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1195\n",
      "Last reward =  [-0.21092406]\n",
      "Reward buffer length =  85600\n",
      "Num timesteps: 85700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1404\n",
      "Last reward =  [-0.07989026]\n",
      "Reward buffer length =  85700\n",
      "Num timesteps: 85800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0837\n",
      "Last reward =  [-0.0218858]\n",
      "Reward buffer length =  85800\n",
      "Num timesteps: 85900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1021\n",
      "Last reward =  [-0.02496229]\n",
      "Reward buffer length =  85900\n",
      "Num timesteps: 86000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1096\n",
      "Last reward =  [-0.11128305]\n",
      "Reward buffer length =  86000\n",
      "Num timesteps: 86100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1332\n",
      "Last reward =  [-0.18528226]\n",
      "Reward buffer length =  86100\n",
      "Num timesteps: 86200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1336\n",
      "Last reward =  [-0.20710304]\n",
      "Reward buffer length =  86200\n",
      "Num timesteps: 86300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0652\n",
      "Last reward =  [-0.13979167]\n",
      "Reward buffer length =  86300\n",
      "Num timesteps: 86400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0958\n",
      "Last reward =  [-0.13097833]\n",
      "Reward buffer length =  86400\n",
      "Num timesteps: 86500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1058\n",
      "Last reward =  [-0.21975763]\n",
      "Reward buffer length =  86500\n",
      "Num timesteps: 86600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1365\n",
      "Last reward =  [-0.08762624]\n",
      "Reward buffer length =  86600\n",
      "Num timesteps: 86700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1375\n",
      "Last reward =  [-0.17261608]\n",
      "Reward buffer length =  86700\n",
      "Num timesteps: 86800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0371\n",
      "Last reward =  [-0.03219433]\n",
      "Reward buffer length =  86800\n",
      "Num timesteps: 86900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0353\n",
      "Last reward =  [-0.03271357]\n",
      "Reward buffer length =  86900\n",
      "Num timesteps: 87000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0491\n",
      "Last reward =  [-0.05459676]\n",
      "Reward buffer length =  87000\n",
      "Num timesteps: 87100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0602\n",
      "Last reward =  [-0.0078816]\n",
      "Reward buffer length =  87100\n",
      "Num timesteps: 87200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0963\n",
      "Last reward =  [-0.13154928]\n",
      "Reward buffer length =  87200\n",
      "Num timesteps: 87300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1033\n",
      "Last reward =  [-0.14030102]\n",
      "Reward buffer length =  87300\n",
      "Num timesteps: 87400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1365\n",
      "Last reward =  [-0.19126034]\n",
      "Reward buffer length =  87400\n",
      "Num timesteps: 87500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1310\n",
      "Last reward =  [-0.03641373]\n",
      "Reward buffer length =  87500\n",
      "Num timesteps: 87600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1141\n",
      "Last reward =  [-0.08834388]\n",
      "Reward buffer length =  87600\n",
      "Num timesteps: 87700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1036\n",
      "Last reward =  [-0.17485745]\n",
      "Reward buffer length =  87700\n",
      "Num timesteps: 87800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1405\n",
      "Last reward =  [-0.02189707]\n",
      "Reward buffer length =  87800\n",
      "Num timesteps: 87900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1343\n",
      "Last reward =  [-0.10262321]\n",
      "Reward buffer length =  87900\n",
      "Num timesteps: 88000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0874\n",
      "Last reward =  [-0.02421685]\n",
      "Reward buffer length =  88000\n",
      "Num timesteps: 88100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1056\n",
      "Last reward =  [-0.08522955]\n",
      "Reward buffer length =  88100\n",
      "Num timesteps: 88200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1093\n",
      "Last reward =  [-0.13403553]\n",
      "Reward buffer length =  88200\n",
      "Num timesteps: 88300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1324\n",
      "Last reward =  [-0.24783881]\n",
      "Reward buffer length =  88300\n",
      "Num timesteps: 88400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1405\n",
      "Last reward =  [-0.20427585]\n",
      "Reward buffer length =  88400\n",
      "Num timesteps: 88500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0576\n",
      "Last reward =  [-0.0061064]\n",
      "Reward buffer length =  88500\n",
      "Num timesteps: 88600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0673\n",
      "Last reward =  [-0.0543534]\n",
      "Reward buffer length =  88600\n",
      "Num timesteps: 88700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1064\n",
      "Last reward =  [-0.1385814]\n",
      "Reward buffer length =  88700\n",
      "Num timesteps: 88800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1119\n",
      "Last reward =  [-0.1368007]\n",
      "Reward buffer length =  88800\n",
      "Num timesteps: 88900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1372\n",
      "Last reward =  [-0.25752264]\n",
      "Reward buffer length =  88900\n",
      "Num timesteps: 89000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1450\n",
      "Last reward =  [-0.15641245]\n",
      "Reward buffer length =  89000\n",
      "Num timesteps: 89100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1336\n",
      "Last reward =  [-0.21952236]\n",
      "Reward buffer length =  89100\n",
      "Num timesteps: 89200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1420\n",
      "Last reward =  [-0.14287525]\n",
      "Reward buffer length =  89200\n",
      "Num timesteps: 89300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1474\n",
      "Last reward =  [0.05428093]\n",
      "Reward buffer length =  89300\n",
      "Num timesteps: 89400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0927\n",
      "Last reward =  [-0.03988215]\n",
      "Reward buffer length =  89400\n",
      "Num timesteps: 89500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0559\n",
      "Last reward =  [-0.06998289]\n",
      "Reward buffer length =  89500\n",
      "Num timesteps: 89600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0694\n",
      "Last reward =  [-0.0836648]\n",
      "Reward buffer length =  89600\n",
      "Num timesteps: 89700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1152\n",
      "Last reward =  [-0.09207401]\n",
      "Reward buffer length =  89700\n",
      "Num timesteps: 89800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1197\n",
      "Last reward =  [-0.1432847]\n",
      "Reward buffer length =  89800\n",
      "Num timesteps: 89900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1498\n",
      "Last reward =  [-0.21470144]\n",
      "Reward buffer length =  89900\n",
      "Num timesteps: 90000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1487\n",
      "Last reward =  [-0.04305181]\n",
      "Reward buffer length =  90000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 90100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0729\n",
      "Last reward =  [-0.09517494]\n",
      "Reward buffer length =  90100\n",
      "Num timesteps: 90200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1129\n",
      "Last reward =  [-0.11389003]\n",
      "Reward buffer length =  90200\n",
      "Num timesteps: 90300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1251\n",
      "Last reward =  [-0.06963687]\n",
      "Reward buffer length =  90300\n",
      "Num timesteps: 90400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1474\n",
      "Last reward =  [-0.13756174]\n",
      "Reward buffer length =  90400\n",
      "Num timesteps: 90500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1539\n",
      "Last reward =  [-0.07165817]\n",
      "Reward buffer length =  90500\n",
      "Num timesteps: 90600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0554\n",
      "Last reward =  [-0.07652773]\n",
      "Reward buffer length =  90600\n",
      "Num timesteps: 90700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0706\n",
      "Last reward =  [-0.069013]\n",
      "Reward buffer length =  90700\n",
      "Num timesteps: 90800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1130\n",
      "Last reward =  [-0.13285846]\n",
      "Reward buffer length =  90800\n",
      "Num timesteps: 90900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1224\n",
      "Last reward =  [-0.10951116]\n",
      "Reward buffer length =  90900\n",
      "Num timesteps: 91000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1392\n",
      "Last reward =  [-0.11711791]\n",
      "Reward buffer length =  91000\n",
      "Num timesteps: 91100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1350\n",
      "Last reward =  [-0.06738023]\n",
      "Reward buffer length =  91100\n",
      "Num timesteps: 91200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0469\n",
      "Last reward =  [-0.0265444]\n",
      "Reward buffer length =  91200\n",
      "Num timesteps: 91300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0668\n",
      "Last reward =  [0.00606557]\n",
      "Reward buffer length =  91300\n",
      "Num timesteps: 91400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0889\n",
      "Last reward =  [-0.13898003]\n",
      "Reward buffer length =  91400\n",
      "Num timesteps: 91500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1146\n",
      "Last reward =  [-0.10831366]\n",
      "Reward buffer length =  91500\n",
      "Num timesteps: 91600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1465\n",
      "Last reward =  [-0.24910699]\n",
      "Reward buffer length =  91600\n",
      "Num timesteps: 91700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1544\n",
      "Last reward =  [-0.08517999]\n",
      "Reward buffer length =  91700\n",
      "Num timesteps: 91800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0814\n",
      "Last reward =  [-0.02852349]\n",
      "Reward buffer length =  91800\n",
      "Num timesteps: 91900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0440\n",
      "Last reward =  [-0.06479509]\n",
      "Reward buffer length =  91900\n",
      "Num timesteps: 92000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0563\n",
      "Last reward =  [-0.13321686]\n",
      "Reward buffer length =  92000\n",
      "Num timesteps: 92100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0774\n",
      "Last reward =  [-0.10943556]\n",
      "Reward buffer length =  92100\n",
      "Num timesteps: 92200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1199\n",
      "Last reward =  [-0.16204567]\n",
      "Reward buffer length =  92200\n",
      "Num timesteps: 92300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1273\n",
      "Last reward =  [0.02369761]\n",
      "Reward buffer length =  92300\n",
      "Num timesteps: 92400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1482\n",
      "Last reward =  [-0.1365608]\n",
      "Reward buffer length =  92400\n",
      "Num timesteps: 92500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1562\n",
      "Last reward =  [-0.16936333]\n",
      "Reward buffer length =  92500\n",
      "Num timesteps: 92600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1182\n",
      "Last reward =  [-0.22479625]\n",
      "Reward buffer length =  92600\n",
      "Num timesteps: 92700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1420\n",
      "Last reward =  [-0.1309809]\n",
      "Reward buffer length =  92700\n",
      "Num timesteps: 92800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1548\n",
      "Last reward =  [-0.2790379]\n",
      "Reward buffer length =  92800\n",
      "Num timesteps: 92900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1275\n",
      "Last reward =  [-0.04910265]\n",
      "Reward buffer length =  92900\n",
      "Num timesteps: 93000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0554\n",
      "Last reward =  [-0.0559406]\n",
      "Reward buffer length =  93000\n",
      "Num timesteps: 93100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0758\n",
      "Last reward =  [-0.16657479]\n",
      "Reward buffer length =  93100\n",
      "Num timesteps: 93200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1002\n",
      "Last reward =  [-0.05943142]\n",
      "Reward buffer length =  93200\n",
      "Num timesteps: 93300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1190\n",
      "Last reward =  [-0.21304919]\n",
      "Reward buffer length =  93300\n",
      "Num timesteps: 93400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1447\n",
      "Last reward =  [-0.03529742]\n",
      "Reward buffer length =  93400\n",
      "Num timesteps: 93500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1485\n",
      "Last reward =  [-0.08861494]\n",
      "Reward buffer length =  93500\n",
      "Num timesteps: 93600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1065\n",
      "Last reward =  [-0.1939828]\n",
      "Reward buffer length =  93600\n",
      "Num timesteps: 93700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1198\n",
      "Last reward =  [-0.01891579]\n",
      "Reward buffer length =  93700\n",
      "Num timesteps: 93800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1422\n",
      "Last reward =  [-0.09899183]\n",
      "Reward buffer length =  93800\n",
      "Num timesteps: 93900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1559\n",
      "Last reward =  [-0.02724342]\n",
      "Reward buffer length =  93900\n",
      "Num timesteps: 94000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1012\n",
      "Last reward =  [-0.0258996]\n",
      "Reward buffer length =  94000\n",
      "Num timesteps: 94100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0164\n",
      "Last reward =  [-0.05928573]\n",
      "Reward buffer length =  94100\n",
      "Num timesteps: 94200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0338\n",
      "Last reward =  [-0.03392409]\n",
      "Reward buffer length =  94200\n",
      "Num timesteps: 94300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0521\n",
      "Last reward =  [-0.03681023]\n",
      "Reward buffer length =  94300\n",
      "Num timesteps: 94400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0690\n",
      "Last reward =  [-0.14814994]\n",
      "Reward buffer length =  94400\n",
      "Num timesteps: 94500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1018\n",
      "Last reward =  [-0.16090742]\n",
      "Reward buffer length =  94500\n",
      "Num timesteps: 94600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1199\n",
      "Last reward =  [-0.03510794]\n",
      "Reward buffer length =  94600\n",
      "Num timesteps: 94700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1485\n",
      "Last reward =  [-0.20201525]\n",
      "Reward buffer length =  94700\n",
      "Num timesteps: 94800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1578\n",
      "Last reward =  [0.01855831]\n",
      "Reward buffer length =  94800\n",
      "Num timesteps: 94900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1357\n",
      "Last reward =  [-0.17334864]\n",
      "Reward buffer length =  94900\n",
      "Num timesteps: 95000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1299\n",
      "Last reward =  [-0.26320842]\n",
      "Reward buffer length =  95000\n",
      "Num timesteps: 95100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1589\n",
      "Last reward =  [-0.2475747]\n",
      "Reward buffer length =  95100\n",
      "Num timesteps: 95200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1456\n",
      "Last reward =  [0.02133322]\n",
      "Reward buffer length =  95200\n",
      "Num timesteps: 95300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0234\n",
      "Last reward =  [-0.07680525]\n",
      "Reward buffer length =  95300\n",
      "Num timesteps: 95400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0520\n",
      "Last reward =  [-0.02873517]\n",
      "Reward buffer length =  95400\n",
      "Num timesteps: 95500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0618\n",
      "Last reward =  [-0.04026495]\n",
      "Reward buffer length =  95500\n",
      "Num timesteps: 95600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0836\n",
      "Last reward =  [-0.10198735]\n",
      "Reward buffer length =  95600\n",
      "Num timesteps: 95700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1300\n",
      "Last reward =  [-0.08109542]\n",
      "Reward buffer length =  95700\n",
      "Num timesteps: 95800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1355\n",
      "Last reward =  [-0.09786577]\n",
      "Reward buffer length =  95800\n",
      "Num timesteps: 95900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1639\n",
      "Last reward =  [-0.07481822]\n",
      "Reward buffer length =  95900\n",
      "Num timesteps: 96000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1469\n",
      "Last reward =  [-0.08865947]\n",
      "Reward buffer length =  96000\n",
      "Num timesteps: 96100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1053\n",
      "Last reward =  [-0.16200352]\n",
      "Reward buffer length =  96100\n",
      "Num timesteps: 96200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1282\n",
      "Last reward =  [-0.23051791]\n",
      "Reward buffer length =  96200\n",
      "Num timesteps: 96300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1606\n",
      "Last reward =  [-0.15328327]\n",
      "Reward buffer length =  96300\n",
      "Num timesteps: 96400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1533\n",
      "Last reward =  [-0.28829855]\n",
      "Reward buffer length =  96400\n",
      "Num timesteps: 96500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1023\n",
      "Last reward =  [-0.08387027]\n",
      "Reward buffer length =  96500\n",
      "Num timesteps: 96600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0922\n",
      "Last reward =  [-0.08259027]\n",
      "Reward buffer length =  96600\n",
      "Num timesteps: 96700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1293\n",
      "Last reward =  [-0.09053795]\n",
      "Reward buffer length =  96700\n",
      "Num timesteps: 96800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1460\n",
      "Last reward =  [-0.22324587]\n",
      "Reward buffer length =  96800\n",
      "Num timesteps: 96900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1599\n",
      "Last reward =  [-0.08529184]\n",
      "Reward buffer length =  96900\n",
      "Num timesteps: 97000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1361\n",
      "Last reward =  [-0.1495806]\n",
      "Reward buffer length =  97000\n",
      "Num timesteps: 97100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1354\n",
      "Last reward =  [-0.09738752]\n",
      "Reward buffer length =  97100\n",
      "Num timesteps: 97200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1643\n",
      "Last reward =  [-0.29031652]\n",
      "Reward buffer length =  97200\n",
      "Num timesteps: 97300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1583\n",
      "Last reward =  [-0.35950074]\n",
      "Reward buffer length =  97300\n",
      "Num timesteps: 97400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1634\n",
      "Last reward =  [-0.13752384]\n",
      "Reward buffer length =  97400\n",
      "Num timesteps: 97500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1576\n",
      "Last reward =  [-0.07853573]\n",
      "Reward buffer length =  97500\n",
      "Num timesteps: 97600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1794\n",
      "Last reward =  [-0.09970806]\n",
      "Reward buffer length =  97600\n",
      "Num timesteps: 97700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1102\n",
      "Last reward =  [-0.05197699]\n",
      "Reward buffer length =  97700\n",
      "Num timesteps: 97800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0580\n",
      "Last reward =  [-0.09754959]\n",
      "Reward buffer length =  97800\n",
      "Num timesteps: 97900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0785\n",
      "Last reward =  [-0.07433786]\n",
      "Reward buffer length =  97900\n",
      "Num timesteps: 98000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1121\n",
      "Last reward =  [-0.2348841]\n",
      "Reward buffer length =  98000\n",
      "Num timesteps: 98100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1300\n",
      "Last reward =  [0.0210571]\n",
      "Reward buffer length =  98100\n",
      "Num timesteps: 98200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1723\n",
      "Last reward =  [-0.1915594]\n",
      "Reward buffer length =  98200\n",
      "Num timesteps: 98300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1629\n",
      "Last reward =  [-0.1241959]\n",
      "Reward buffer length =  98300\n",
      "Num timesteps: 98400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1517\n",
      "Last reward =  [-0.10575965]\n",
      "Reward buffer length =  98400\n",
      "Num timesteps: 98500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1420\n",
      "Last reward =  [-0.26534846]\n",
      "Reward buffer length =  98500\n",
      "Num timesteps: 98600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1717\n",
      "Last reward =  [-0.11882667]\n",
      "Reward buffer length =  98600\n",
      "Num timesteps: 98700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1488\n",
      "Last reward =  [-0.04561013]\n",
      "Reward buffer length =  98700\n",
      "Num timesteps: 98800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0655\n",
      "Last reward =  [-0.0961008]\n",
      "Reward buffer length =  98800\n",
      "Num timesteps: 98900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0940\n",
      "Last reward =  [-0.17352825]\n",
      "Reward buffer length =  98900\n",
      "Num timesteps: 99000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1355\n",
      "Last reward =  [-0.08187826]\n",
      "Reward buffer length =  99000\n",
      "Num timesteps: 99100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1535\n",
      "Last reward =  [-0.09680592]\n",
      "Reward buffer length =  99100\n",
      "Num timesteps: 99200\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1843\n",
      "Last reward =  [-0.15594876]\n",
      "Reward buffer length =  99200\n",
      "Num timesteps: 99300\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1286\n",
      "Last reward =  [-0.0433553]\n",
      "Reward buffer length =  99300\n",
      "Num timesteps: 99400\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.0867\n",
      "Last reward =  [-0.12923111]\n",
      "Reward buffer length =  99400\n",
      "Num timesteps: 99500\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1351\n",
      "Last reward =  [-0.15475614]\n",
      "Reward buffer length =  99500\n",
      "Num timesteps: 99600\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1417\n",
      "Last reward =  [-0.23790726]\n",
      "Reward buffer length =  99600\n",
      "Num timesteps: 99700\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1736\n",
      "Last reward =  [-0.24773669]\n",
      "Reward buffer length =  99700\n",
      "Num timesteps: 99800\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1661\n",
      "Last reward =  [-0.15493928]\n",
      "Reward buffer length =  99800\n",
      "Num timesteps: 99900\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1426\n",
      "Last reward =  [-0.06665384]\n",
      "Reward buffer length =  99900\n",
      "Num timesteps: 100000\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1633\n",
      "Last reward =  [-0.22716887]\n",
      "Reward buffer length =  100000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-16e3231d\\online\\model.zip\n",
      "Num timesteps: 100100\n",
      "Best mean reward: 0.0210, Best mean reward step: 6700 Last mean reward per episode: -0.1738\n",
      "Last reward =  [0.061605]\n",
      "Reward buffer length =  100100\n",
      "End training online model...\n",
      "row_count=4871, start_row=3870, start_date=2017-12-17T22:00:00.000000000, end_row=4870, end_date=2021-10-27T21:00:00.000000000\n",
      "Data shape:(7, 1000, 4)\n",
      "Instruments:['EURUSD', 'USDJPY', 'GBPUSD', 'AUDUSD', 'USDCAD', 'USDCHF', 'NZDUSD'], lookack:30, random_episode_start:True, cash:1000.0, max_slippage_percent:0.01, lot_size:Micro, leverage:20, pip_size:[0.0001, 0.01, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001], pip_spread:[2, 2, 2, 2, 2, 2, 2], compute_position:long_and_short, compute_indicators:all, compute_reward:['log_returns'], verbose:False\n",
      "Model name:fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\n",
      "Using cuda device\n",
      "Start training model...\n",
      "Logging to E:\\\\alpha-machine\\\\logs\\\\forex\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81_0\n",
      "Num timesteps: 100\n",
      "Best mean reward: -inf, Best mean reward step: 0 Last mean reward per episode: -0.0027\n",
      "Last reward =  [0.00058662]\n",
      "Reward buffer length =  100\n",
      "Num timesteps: 200\n",
      "Best mean reward: -0.0027, Best mean reward step: 100 Last mean reward per episode: -0.0034\n",
      "Last reward =  [0.02460669]\n",
      "Reward buffer length =  200\n",
      "Num timesteps: 300\n",
      "Best mean reward: -0.0027, Best mean reward step: 100 Last mean reward per episode: -0.0024\n",
      "Last reward =  [0.00417736]\n",
      "Reward buffer length =  300\n",
      "Num timesteps: 400\n",
      "Best mean reward: -0.0024, Best mean reward step: 300 Last mean reward per episode: -0.0073\n",
      "Last reward =  [-0.03001129]\n",
      "Reward buffer length =  400\n",
      "Num timesteps: 500\n",
      "Best mean reward: -0.0024, Best mean reward step: 300 Last mean reward per episode: -0.0008\n",
      "Last reward =  [-0.02476173]\n",
      "Reward buffer length =  500\n",
      "Num timesteps: 600\n",
      "Best mean reward: -0.0008, Best mean reward step: 500 Last mean reward per episode: -0.0042\n",
      "Last reward =  [0.02077382]\n",
      "Reward buffer length =  600\n",
      "Num timesteps: 700\n",
      "Best mean reward: -0.0008, Best mean reward step: 500 Last mean reward per episode: 0.0053\n",
      "Last reward =  [0.01322619]\n",
      "Reward buffer length =  700\n",
      "Num timesteps: 800\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: 0.0027\n",
      "Last reward =  [-0.01940288]\n",
      "Reward buffer length =  800\n",
      "Num timesteps: 900\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0005\n",
      "Last reward =  [-0.00832287]\n",
      "Reward buffer length =  900\n",
      "Num timesteps: 1000\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0035\n",
      "Last reward =  [-0.03550075]\n",
      "Reward buffer length =  1000\n",
      "Num timesteps: 1100\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0005\n",
      "Last reward =  [-0.00027807]\n",
      "Reward buffer length =  1100\n",
      "Num timesteps: 1200\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0066\n",
      "Last reward =  [-0.05996277]\n",
      "Reward buffer length =  1200\n",
      "Num timesteps: 1300\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: 0.0021\n",
      "Last reward =  [-0.08060861]\n",
      "Reward buffer length =  1300\n",
      "Num timesteps: 1400\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: 0.0047\n",
      "Last reward =  [0.00336974]\n",
      "Reward buffer length =  1400\n",
      "Num timesteps: 1500\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0052\n",
      "Last reward =  [0.07581311]\n",
      "Reward buffer length =  1500\n",
      "Num timesteps: 1600\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0041\n",
      "Last reward =  [-0.03446376]\n",
      "Reward buffer length =  1600\n",
      "Num timesteps: 1700\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0044\n",
      "Last reward =  [-0.09907013]\n",
      "Reward buffer length =  1700\n",
      "Num timesteps: 1800\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0032\n",
      "Last reward =  [0.05009831]\n",
      "Reward buffer length =  1800\n",
      "Num timesteps: 1900\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: 0.0020\n",
      "Last reward =  [0.02439227]\n",
      "Reward buffer length =  1900\n",
      "Num timesteps: 2000\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0009\n",
      "Last reward =  [0.05895512]\n",
      "Reward buffer length =  2000\n",
      "Num timesteps: 2100\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0052\n",
      "Last reward =  [-0.00236358]\n",
      "Reward buffer length =  2100\n",
      "Num timesteps: 2200\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0071\n",
      "Last reward =  [0.00093186]\n",
      "Reward buffer length =  2200\n",
      "Num timesteps: 2300\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0051\n",
      "Last reward =  [-0.00724252]\n",
      "Reward buffer length =  2300\n",
      "Num timesteps: 2400\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0069\n",
      "Last reward =  [0.00874947]\n",
      "Reward buffer length =  2400\n",
      "Num timesteps: 2500\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: -0.0071\n",
      "Last reward =  [-0.08037565]\n",
      "Reward buffer length =  2500\n",
      "Num timesteps: 2600\n",
      "Best mean reward: 0.0053, Best mean reward step: 700 Last mean reward per episode: 0.0073\n",
      "Last reward =  [-0.10376446]\n",
      "Reward buffer length =  2600\n",
      "Num timesteps: 2700\n",
      "Best mean reward: 0.0073, Best mean reward step: 2600 Last mean reward per episode: -0.0000\n",
      "Last reward =  [-0.01184401]\n",
      "Reward buffer length =  2700\n",
      "Num timesteps: 2800\n",
      "Best mean reward: 0.0073, Best mean reward step: 2600 Last mean reward per episode: -0.0044\n",
      "Last reward =  [-0.0121822]\n",
      "Reward buffer length =  2800\n",
      "Num timesteps: 2900\n",
      "Best mean reward: 0.0073, Best mean reward step: 2600 Last mean reward per episode: -0.0120\n",
      "Last reward =  [0.03020296]\n",
      "Reward buffer length =  2900\n",
      "Num timesteps: 3000\n",
      "Best mean reward: 0.0073, Best mean reward step: 2600 Last mean reward per episode: -0.0030\n",
      "Last reward =  [0.01883471]\n",
      "Reward buffer length =  3000\n",
      "Num timesteps: 3100\n",
      "Best mean reward: 0.0073, Best mean reward step: 2600 Last mean reward per episode: -0.0126\n",
      "Last reward =  [-0.2293478]\n",
      "Reward buffer length =  3100\n",
      "Num timesteps: 3200\n",
      "Best mean reward: 0.0073, Best mean reward step: 2600 Last mean reward per episode: 0.0119\n",
      "Last reward =  [0.04247799]\n",
      "Reward buffer length =  3200\n",
      "Num timesteps: 3300\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0021\n",
      "Last reward =  [0.0399117]\n",
      "Reward buffer length =  3300\n",
      "Num timesteps: 3400\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0035\n",
      "Last reward =  [0.07931229]\n",
      "Reward buffer length =  3400\n",
      "Num timesteps: 3500\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0139\n",
      "Last reward =  [0.04177839]\n",
      "Reward buffer length =  3500\n",
      "Num timesteps: 3600\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0000\n",
      "Last reward =  [0.00038109]\n",
      "Reward buffer length =  3600\n",
      "Num timesteps: 3700\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0028\n",
      "Last reward =  [0.05761756]\n",
      "Reward buffer length =  3700\n",
      "Num timesteps: 3800\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0023\n",
      "Last reward =  [-0.00111194]\n",
      "Reward buffer length =  3800\n",
      "Num timesteps: 3900\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0012\n",
      "Last reward =  [0.01233135]\n",
      "Reward buffer length =  3900\n",
      "Num timesteps: 4000\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0042\n",
      "Last reward =  [-0.01786684]\n",
      "Reward buffer length =  4000\n",
      "Num timesteps: 4100\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0082\n",
      "Last reward =  [0.02601288]\n",
      "Reward buffer length =  4100\n",
      "Num timesteps: 4200\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0050\n",
      "Last reward =  [-0.00161172]\n",
      "Reward buffer length =  4200\n",
      "Num timesteps: 4300\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0009\n",
      "Last reward =  [-0.00448]\n",
      "Reward buffer length =  4300\n",
      "Num timesteps: 4400\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0018\n",
      "Last reward =  [0.00650486]\n",
      "Reward buffer length =  4400\n",
      "Num timesteps: 4500\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0041\n",
      "Last reward =  [0.01555998]\n",
      "Reward buffer length =  4500\n",
      "Num timesteps: 4600\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0101\n",
      "Last reward =  [-0.06264123]\n",
      "Reward buffer length =  4600\n",
      "Num timesteps: 4700\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0014\n",
      "Last reward =  [-0.0078597]\n",
      "Reward buffer length =  4700\n",
      "Num timesteps: 4800\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0046\n",
      "Last reward =  [0.01833616]\n",
      "Reward buffer length =  4800\n",
      "Num timesteps: 4900\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0018\n",
      "Last reward =  [-0.01947685]\n",
      "Reward buffer length =  4900\n",
      "Num timesteps: 5000\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0003\n",
      "Last reward =  [-0.02064946]\n",
      "Reward buffer length =  5000\n",
      "Num timesteps: 5100\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0048\n",
      "Last reward =  [-0.02729097]\n",
      "Reward buffer length =  5100\n",
      "Num timesteps: 5200\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0043\n",
      "Last reward =  [-0.10524893]\n",
      "Reward buffer length =  5200\n",
      "Num timesteps: 5300\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0057\n",
      "Last reward =  [0.05802462]\n",
      "Reward buffer length =  5300\n",
      "Num timesteps: 5400\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0041\n",
      "Last reward =  [0.09286621]\n",
      "Reward buffer length =  5400\n",
      "Num timesteps: 5500\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0032\n",
      "Last reward =  [0.03684644]\n",
      "Reward buffer length =  5500\n",
      "Num timesteps: 5600\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0017\n",
      "Last reward =  [-0.02752366]\n",
      "Reward buffer length =  5600\n",
      "Num timesteps: 5700\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0025\n",
      "Last reward =  [0.03841363]\n",
      "Reward buffer length =  5700\n",
      "Num timesteps: 5800\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0068\n",
      "Last reward =  [0.00820618]\n",
      "Reward buffer length =  5800\n",
      "Num timesteps: 5900\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0013\n",
      "Last reward =  [-0.04961101]\n",
      "Reward buffer length =  5900\n",
      "Num timesteps: 6000\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0008\n",
      "Last reward =  [-0.00660946]\n",
      "Reward buffer length =  6000\n",
      "Num timesteps: 6100\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0017\n",
      "Last reward =  [-0.01304012]\n",
      "Reward buffer length =  6100\n",
      "Num timesteps: 6200\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0041\n",
      "Last reward =  [0.0077189]\n",
      "Reward buffer length =  6200\n",
      "Num timesteps: 6300\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0085\n",
      "Last reward =  [-0.0111667]\n",
      "Reward buffer length =  6300\n",
      "Num timesteps: 6400\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0056\n",
      "Last reward =  [0.01277946]\n",
      "Reward buffer length =  6400\n",
      "Num timesteps: 6500\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0008\n",
      "Last reward =  [0.00258177]\n",
      "Reward buffer length =  6500\n",
      "Num timesteps: 6600\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0043\n",
      "Last reward =  [-0.00158093]\n",
      "Reward buffer length =  6600\n",
      "Num timesteps: 6700\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0069\n",
      "Last reward =  [-0.00804114]\n",
      "Reward buffer length =  6700\n",
      "Num timesteps: 6800\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0003\n",
      "Last reward =  [-0.00181609]\n",
      "Reward buffer length =  6800\n",
      "Num timesteps: 6900\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0016\n",
      "Last reward =  [0.02170991]\n",
      "Reward buffer length =  6900\n",
      "Num timesteps: 7000\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0007\n",
      "Last reward =  [-0.07187941]\n",
      "Reward buffer length =  7000\n",
      "Num timesteps: 7100\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0023\n",
      "Last reward =  [0.04056682]\n",
      "Reward buffer length =  7100\n",
      "Num timesteps: 7200\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0049\n",
      "Last reward =  [-0.04772079]\n",
      "Reward buffer length =  7200\n",
      "Num timesteps: 7300\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0001\n",
      "Last reward =  [-0.04734723]\n",
      "Reward buffer length =  7300\n",
      "Num timesteps: 7400\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0014\n",
      "Last reward =  [0.06708743]\n",
      "Reward buffer length =  7400\n",
      "Num timesteps: 7500\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0025\n",
      "Last reward =  [-0.01913512]\n",
      "Reward buffer length =  7500\n",
      "Num timesteps: 7600\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0031\n",
      "Last reward =  [0.01910972]\n",
      "Reward buffer length =  7600\n",
      "Num timesteps: 7700\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0052\n",
      "Last reward =  [-0.01787269]\n",
      "Reward buffer length =  7700\n",
      "Num timesteps: 7800\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0057\n",
      "Last reward =  [-0.00856068]\n",
      "Reward buffer length =  7800\n",
      "Num timesteps: 7900\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0003\n",
      "Last reward =  [-0.02376194]\n",
      "Reward buffer length =  7900\n",
      "Num timesteps: 8000\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0016\n",
      "Last reward =  [0.03854495]\n",
      "Reward buffer length =  8000\n",
      "Num timesteps: 8100\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0002\n",
      "Last reward =  [0.05148729]\n",
      "Reward buffer length =  8100\n",
      "Num timesteps: 8200\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0003\n",
      "Last reward =  [-0.04128465]\n",
      "Reward buffer length =  8200\n",
      "Num timesteps: 8300\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0022\n",
      "Last reward =  [0.03607657]\n",
      "Reward buffer length =  8300\n",
      "Num timesteps: 8400\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0021\n",
      "Last reward =  [0.01741724]\n",
      "Reward buffer length =  8400\n",
      "Num timesteps: 8500\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0018\n",
      "Last reward =  [-0.01286918]\n",
      "Reward buffer length =  8500\n",
      "Num timesteps: 8600\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0042\n",
      "Last reward =  [0.03356848]\n",
      "Reward buffer length =  8600\n",
      "Num timesteps: 8700\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0015\n",
      "Last reward =  [0.01842768]\n",
      "Reward buffer length =  8700\n",
      "Num timesteps: 8800\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0006\n",
      "Last reward =  [0.00335177]\n",
      "Reward buffer length =  8800\n",
      "Num timesteps: 8900\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: -0.0010\n",
      "Last reward =  [-0.05400853]\n",
      "Reward buffer length =  8900\n",
      "Num timesteps: 9000\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0067\n",
      "Last reward =  [-0.00151641]\n",
      "Reward buffer length =  9000\n",
      "Num timesteps: 9100\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0088\n",
      "Last reward =  [-0.00326692]\n",
      "Reward buffer length =  9100\n",
      "Num timesteps: 9200\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0033\n",
      "Last reward =  [0.01079731]\n",
      "Reward buffer length =  9200\n",
      "Num timesteps: 9300\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0058\n",
      "Last reward =  [0.01250673]\n",
      "Reward buffer length =  9300\n",
      "Num timesteps: 9400\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0076\n",
      "Last reward =  [-0.00828002]\n",
      "Reward buffer length =  9400\n",
      "Num timesteps: 9500\n",
      "Best mean reward: 0.0119, Best mean reward step: 3200 Last mean reward per episode: 0.0143\n",
      "Last reward =  [0.04229119]\n",
      "Reward buffer length =  9500\n",
      "Num timesteps: 9600\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0029\n",
      "Last reward =  [0.00889753]\n",
      "Reward buffer length =  9600\n",
      "Num timesteps: 9700\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0041\n",
      "Last reward =  [-0.00223721]\n",
      "Reward buffer length =  9700\n",
      "Num timesteps: 9800\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0089\n",
      "Last reward =  [0.0257233]\n",
      "Reward buffer length =  9800\n",
      "Num timesteps: 9900\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0022\n",
      "Last reward =  [-0.00756787]\n",
      "Reward buffer length =  9900\n",
      "Num timesteps: 10000\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0023\n",
      "Last reward =  [0.02405971]\n",
      "Reward buffer length =  10000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 10100\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0033\n",
      "Last reward =  [-0.00647625]\n",
      "Reward buffer length =  10100\n",
      "Num timesteps: 10200\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0079\n",
      "Last reward =  [-0.01347819]\n",
      "Reward buffer length =  10200\n",
      "Num timesteps: 10300\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0060\n",
      "Last reward =  [-0.02254831]\n",
      "Reward buffer length =  10300\n",
      "Num timesteps: 10400\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0001\n",
      "Last reward =  [-0.02244843]\n",
      "Reward buffer length =  10400\n",
      "Num timesteps: 10500\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0059\n",
      "Last reward =  [0.00043964]\n",
      "Reward buffer length =  10500\n",
      "Num timesteps: 10600\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0065\n",
      "Last reward =  [-0.02111649]\n",
      "Reward buffer length =  10600\n",
      "Num timesteps: 10700\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0068\n",
      "Last reward =  [0.00779952]\n",
      "Reward buffer length =  10700\n",
      "Num timesteps: 10800\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0012\n",
      "Last reward =  [0.00926723]\n",
      "Reward buffer length =  10800\n",
      "Num timesteps: 10900\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0060\n",
      "Last reward =  [-0.00612257]\n",
      "Reward buffer length =  10900\n",
      "Num timesteps: 11000\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0058\n",
      "Last reward =  [-0.01990774]\n",
      "Reward buffer length =  11000\n",
      "Num timesteps: 11100\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0011\n",
      "Last reward =  [-0.02102741]\n",
      "Reward buffer length =  11100\n",
      "Num timesteps: 11200\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0013\n",
      "Last reward =  [-0.02423019]\n",
      "Reward buffer length =  11200\n",
      "Num timesteps: 11300\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0056\n",
      "Last reward =  [-0.01129565]\n",
      "Reward buffer length =  11300\n",
      "Num timesteps: 11400\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0002\n",
      "Last reward =  [0.00318764]\n",
      "Reward buffer length =  11400\n",
      "Num timesteps: 11500\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0063\n",
      "Last reward =  [0.03980802]\n",
      "Reward buffer length =  11500\n",
      "Num timesteps: 11600\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0140\n",
      "Last reward =  [0.04166874]\n",
      "Reward buffer length =  11600\n",
      "Num timesteps: 11700\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0006\n",
      "Last reward =  [-0.05958033]\n",
      "Reward buffer length =  11700\n",
      "Num timesteps: 11800\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0007\n",
      "Last reward =  [-0.01199667]\n",
      "Reward buffer length =  11800\n",
      "Num timesteps: 11900\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0058\n",
      "Last reward =  [0.016222]\n",
      "Reward buffer length =  11900\n",
      "Num timesteps: 12000\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0015\n",
      "Last reward =  [-0.04278166]\n",
      "Reward buffer length =  12000\n",
      "Num timesteps: 12100\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0106\n",
      "Last reward =  [-0.00768884]\n",
      "Reward buffer length =  12100\n",
      "Num timesteps: 12200\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0003\n",
      "Last reward =  [-0.02792213]\n",
      "Reward buffer length =  12200\n",
      "Num timesteps: 12300\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0009\n",
      "Last reward =  [0.01215314]\n",
      "Reward buffer length =  12300\n",
      "Num timesteps: 12400\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0041\n",
      "Last reward =  [0.04636501]\n",
      "Reward buffer length =  12400\n",
      "Num timesteps: 12500\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0009\n",
      "Last reward =  [-0.0145528]\n",
      "Reward buffer length =  12500\n",
      "Num timesteps: 12600\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0028\n",
      "Last reward =  [0.00081423]\n",
      "Reward buffer length =  12600\n",
      "Num timesteps: 12700\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0036\n",
      "Last reward =  [0.018716]\n",
      "Reward buffer length =  12700\n",
      "Num timesteps: 12800\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0008\n",
      "Last reward =  [0.01808206]\n",
      "Reward buffer length =  12800\n",
      "Num timesteps: 12900\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0066\n",
      "Last reward =  [0.02340503]\n",
      "Reward buffer length =  12900\n",
      "Num timesteps: 13000\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0122\n",
      "Last reward =  [-0.05104143]\n",
      "Reward buffer length =  13000\n",
      "Num timesteps: 13100\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0027\n",
      "Last reward =  [0.04713714]\n",
      "Reward buffer length =  13100\n",
      "Num timesteps: 13200\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0013\n",
      "Last reward =  [0.01842077]\n",
      "Reward buffer length =  13200\n",
      "Num timesteps: 13300\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0039\n",
      "Last reward =  [-0.00076365]\n",
      "Reward buffer length =  13300\n",
      "Num timesteps: 13400\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0004\n",
      "Last reward =  [-0.00852748]\n",
      "Reward buffer length =  13400\n",
      "Num timesteps: 13500\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0045\n",
      "Last reward =  [0.01476787]\n",
      "Reward buffer length =  13500\n",
      "Num timesteps: 13600\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0111\n",
      "Last reward =  [0.04014801]\n",
      "Reward buffer length =  13600\n",
      "Num timesteps: 13700\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0006\n",
      "Last reward =  [-0.01187308]\n",
      "Reward buffer length =  13700\n",
      "Num timesteps: 13800\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0003\n",
      "Last reward =  [-0.02861167]\n",
      "Reward buffer length =  13800\n",
      "Num timesteps: 13900\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0035\n",
      "Last reward =  [-0.01824598]\n",
      "Reward buffer length =  13900\n",
      "Num timesteps: 14000\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0035\n",
      "Last reward =  [-0.00136783]\n",
      "Reward buffer length =  14000\n",
      "Num timesteps: 14100\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0100\n",
      "Last reward =  [0.02631672]\n",
      "Reward buffer length =  14100\n",
      "Num timesteps: 14200\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0033\n",
      "Last reward =  [-0.00545161]\n",
      "Reward buffer length =  14200\n",
      "Num timesteps: 14300\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0009\n",
      "Last reward =  [-0.05949589]\n",
      "Reward buffer length =  14300\n",
      "Num timesteps: 14400\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0029\n",
      "Last reward =  [-0.02844764]\n",
      "Reward buffer length =  14400\n",
      "Num timesteps: 14500\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0033\n",
      "Last reward =  [0.03018448]\n",
      "Reward buffer length =  14500\n",
      "Num timesteps: 14600\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0020\n",
      "Last reward =  [-0.03013831]\n",
      "Reward buffer length =  14600\n",
      "Num timesteps: 14700\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0010\n",
      "Last reward =  [0.03023401]\n",
      "Reward buffer length =  14700\n",
      "Num timesteps: 14800\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0031\n",
      "Last reward =  [0.06765757]\n",
      "Reward buffer length =  14800\n",
      "Num timesteps: 14900\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0086\n",
      "Last reward =  [-0.03020036]\n",
      "Reward buffer length =  14900\n",
      "Num timesteps: 15000\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0046\n",
      "Last reward =  [0.01469381]\n",
      "Reward buffer length =  15000\n",
      "Num timesteps: 15100\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0029\n",
      "Last reward =  [-0.03460032]\n",
      "Reward buffer length =  15100\n",
      "Num timesteps: 15200\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0017\n",
      "Last reward =  [-0.02143892]\n",
      "Reward buffer length =  15200\n",
      "Num timesteps: 15300\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0047\n",
      "Last reward =  [-0.0332067]\n",
      "Reward buffer length =  15300\n",
      "Num timesteps: 15400\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0003\n",
      "Last reward =  [0.04276067]\n",
      "Reward buffer length =  15400\n",
      "Num timesteps: 15500\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0017\n",
      "Last reward =  [0.01404695]\n",
      "Reward buffer length =  15500\n",
      "Num timesteps: 15600\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0017\n",
      "Last reward =  [0.02403189]\n",
      "Reward buffer length =  15600\n",
      "Num timesteps: 15700\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0031\n",
      "Last reward =  [0.01162842]\n",
      "Reward buffer length =  15700\n",
      "Num timesteps: 15800\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0050\n",
      "Last reward =  [-0.03900711]\n",
      "Reward buffer length =  15800\n",
      "Num timesteps: 15900\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0035\n",
      "Last reward =  [0.02486339]\n",
      "Reward buffer length =  15900\n",
      "Num timesteps: 16000\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0044\n",
      "Last reward =  [-0.04808028]\n",
      "Reward buffer length =  16000\n",
      "Num timesteps: 16100\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0008\n",
      "Last reward =  [-0.03587137]\n",
      "Reward buffer length =  16100\n",
      "Num timesteps: 16200\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0023\n",
      "Last reward =  [-0.00532917]\n",
      "Reward buffer length =  16200\n",
      "Num timesteps: 16300\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0003\n",
      "Last reward =  [-0.01009116]\n",
      "Reward buffer length =  16300\n",
      "Num timesteps: 16400\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0046\n",
      "Last reward =  [0.00155939]\n",
      "Reward buffer length =  16400\n",
      "Num timesteps: 16500\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0001\n",
      "Last reward =  [0.01396219]\n",
      "Reward buffer length =  16500\n",
      "Num timesteps: 16600\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0029\n",
      "Last reward =  [0.02238352]\n",
      "Reward buffer length =  16600\n",
      "Num timesteps: 16700\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0109\n",
      "Last reward =  [-0.05702313]\n",
      "Reward buffer length =  16700\n",
      "Num timesteps: 16800\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0044\n",
      "Last reward =  [-0.03386321]\n",
      "Reward buffer length =  16800\n",
      "Num timesteps: 16900\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0025\n",
      "Last reward =  [-0.06728153]\n",
      "Reward buffer length =  16900\n",
      "Num timesteps: 17000\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0033\n",
      "Last reward =  [-0.02248578]\n",
      "Reward buffer length =  17000\n",
      "Num timesteps: 17100\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0023\n",
      "Last reward =  [0.04782618]\n",
      "Reward buffer length =  17100\n",
      "Num timesteps: 17200\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0038\n",
      "Last reward =  [-0.00404914]\n",
      "Reward buffer length =  17200\n",
      "Num timesteps: 17300\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: -0.0027\n",
      "Last reward =  [0.00508488]\n",
      "Reward buffer length =  17300\n",
      "Num timesteps: 17400\n",
      "Best mean reward: 0.0143, Best mean reward step: 9500 Last mean reward per episode: 0.0145\n",
      "Last reward =  [-0.05050066]\n",
      "Reward buffer length =  17400\n",
      "Num timesteps: 17500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0036\n",
      "Last reward =  [-0.03986972]\n",
      "Reward buffer length =  17500\n",
      "Num timesteps: 17600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0051\n",
      "Last reward =  [0.02746631]\n",
      "Reward buffer length =  17600\n",
      "Num timesteps: 17700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0014\n",
      "Last reward =  [-0.01401084]\n",
      "Reward buffer length =  17700\n",
      "Num timesteps: 17800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0043\n",
      "Last reward =  [-0.02601968]\n",
      "Reward buffer length =  17800\n",
      "Num timesteps: 17900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0001\n",
      "Last reward =  [-0.01187224]\n",
      "Reward buffer length =  17900\n",
      "Num timesteps: 18000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0013\n",
      "Last reward =  [0.07653211]\n",
      "Reward buffer length =  18000\n",
      "Num timesteps: 18100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0050\n",
      "Last reward =  [-0.01120852]\n",
      "Reward buffer length =  18100\n",
      "Num timesteps: 18200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0002\n",
      "Last reward =  [-0.03225333]\n",
      "Reward buffer length =  18200\n",
      "Num timesteps: 18300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0054\n",
      "Last reward =  [0.02632059]\n",
      "Reward buffer length =  18300\n",
      "Num timesteps: 18400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0079\n",
      "Last reward =  [0.02771568]\n",
      "Reward buffer length =  18400\n",
      "Num timesteps: 18500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0073\n",
      "Last reward =  [-0.07233315]\n",
      "Reward buffer length =  18500\n",
      "Num timesteps: 18600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0086\n",
      "Last reward =  [0.02496628]\n",
      "Reward buffer length =  18600\n",
      "Num timesteps: 18700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0088\n",
      "Last reward =  [0.01326782]\n",
      "Reward buffer length =  18700\n",
      "Num timesteps: 18800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0079\n",
      "Last reward =  [0.03057118]\n",
      "Reward buffer length =  18800\n",
      "Num timesteps: 18900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0015\n",
      "Last reward =  [0.01343489]\n",
      "Reward buffer length =  18900\n",
      "Num timesteps: 19000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0050\n",
      "Last reward =  [0.06751183]\n",
      "Reward buffer length =  19000\n",
      "Num timesteps: 19100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0121\n",
      "Last reward =  [-0.00219794]\n",
      "Reward buffer length =  19100\n",
      "Num timesteps: 19200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0100\n",
      "Last reward =  [0.02272799]\n",
      "Reward buffer length =  19200\n",
      "Num timesteps: 19300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0031\n",
      "Last reward =  [-0.04616731]\n",
      "Reward buffer length =  19300\n",
      "Num timesteps: 19400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0009\n",
      "Last reward =  [0.01306395]\n",
      "Reward buffer length =  19400\n",
      "Num timesteps: 19500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0099\n",
      "Last reward =  [-0.02581916]\n",
      "Reward buffer length =  19500\n",
      "Num timesteps: 19600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0051\n",
      "Last reward =  [-0.04096277]\n",
      "Reward buffer length =  19600\n",
      "Num timesteps: 19700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0078\n",
      "Last reward =  [-0.0108079]\n",
      "Reward buffer length =  19700\n",
      "Num timesteps: 19800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0094\n",
      "Last reward =  [0.02090781]\n",
      "Reward buffer length =  19800\n",
      "Num timesteps: 19900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0107\n",
      "Last reward =  [-0.04351594]\n",
      "Reward buffer length =  19900\n",
      "Num timesteps: 20000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0078\n",
      "Last reward =  [-0.00868026]\n",
      "Reward buffer length =  20000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 20100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0013\n",
      "Last reward =  [0.03838618]\n",
      "Reward buffer length =  20100\n",
      "Num timesteps: 20200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0064\n",
      "Last reward =  [0.01350539]\n",
      "Reward buffer length =  20200\n",
      "Num timesteps: 20300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0083\n",
      "Last reward =  [-0.0319664]\n",
      "Reward buffer length =  20300\n",
      "Num timesteps: 20400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0110\n",
      "Last reward =  [-0.04472037]\n",
      "Reward buffer length =  20400\n",
      "Num timesteps: 20500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0116\n",
      "Last reward =  [-0.00315174]\n",
      "Reward buffer length =  20500\n",
      "Num timesteps: 20600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0093\n",
      "Last reward =  [0.0308458]\n",
      "Reward buffer length =  20600\n",
      "Num timesteps: 20700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0143\n",
      "Last reward =  [-0.05783199]\n",
      "Reward buffer length =  20700\n",
      "Num timesteps: 20800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0141\n",
      "Last reward =  [0.01351146]\n",
      "Reward buffer length =  20800\n",
      "Num timesteps: 20900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0046\n",
      "Last reward =  [0.13641721]\n",
      "Reward buffer length =  20900\n",
      "Num timesteps: 21000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0034\n",
      "Last reward =  [0.01048826]\n",
      "Reward buffer length =  21000\n",
      "Num timesteps: 21100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0129\n",
      "Last reward =  [-0.04137756]\n",
      "Reward buffer length =  21100\n",
      "Num timesteps: 21200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0116\n",
      "Last reward =  [-0.0069472]\n",
      "Reward buffer length =  21200\n",
      "Num timesteps: 21300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0127\n",
      "Last reward =  [0.02390924]\n",
      "Reward buffer length =  21300\n",
      "Num timesteps: 21400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0069\n",
      "Last reward =  [-0.02849468]\n",
      "Reward buffer length =  21400\n",
      "Num timesteps: 21500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0140\n",
      "Last reward =  [-0.0417315]\n",
      "Reward buffer length =  21500\n",
      "Num timesteps: 21600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0130\n",
      "Last reward =  [-0.03137252]\n",
      "Reward buffer length =  21600\n",
      "Num timesteps: 21700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0164\n",
      "Last reward =  [-0.01987069]\n",
      "Reward buffer length =  21700\n",
      "Num timesteps: 21800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0187\n",
      "Last reward =  [0.04486419]\n",
      "Reward buffer length =  21800\n",
      "Num timesteps: 21900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0182\n",
      "Last reward =  [0.01310916]\n",
      "Reward buffer length =  21900\n",
      "Num timesteps: 22000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0187\n",
      "Last reward =  [-0.00380254]\n",
      "Reward buffer length =  22000\n",
      "Num timesteps: 22100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0186\n",
      "Last reward =  [-0.04109962]\n",
      "Reward buffer length =  22100\n",
      "Num timesteps: 22200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0171\n",
      "Last reward =  [-0.0394339]\n",
      "Reward buffer length =  22200\n",
      "Num timesteps: 22300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0226\n",
      "Last reward =  [-0.0430607]\n",
      "Reward buffer length =  22300\n",
      "Num timesteps: 22400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0203\n",
      "Last reward =  [0.001262]\n",
      "Reward buffer length =  22400\n",
      "Num timesteps: 22500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0057\n",
      "Last reward =  [-0.08202238]\n",
      "Reward buffer length =  22500\n",
      "Num timesteps: 22600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0062\n",
      "Last reward =  [0.02267185]\n",
      "Reward buffer length =  22600\n",
      "Num timesteps: 22700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0018\n",
      "Last reward =  [0.0049126]\n",
      "Reward buffer length =  22700\n",
      "Num timesteps: 22800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0057\n",
      "Last reward =  [0.02747573]\n",
      "Reward buffer length =  22800\n",
      "Num timesteps: 22900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0078\n",
      "Last reward =  [-0.03015936]\n",
      "Reward buffer length =  22900\n",
      "Num timesteps: 23000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0152\n",
      "Last reward =  [-0.01761661]\n",
      "Reward buffer length =  23000\n",
      "Num timesteps: 23100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0216\n",
      "Last reward =  [-0.04466873]\n",
      "Reward buffer length =  23100\n",
      "Num timesteps: 23200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0245\n",
      "Last reward =  [-0.02781048]\n",
      "Reward buffer length =  23200\n",
      "Num timesteps: 23300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0225\n",
      "Last reward =  [-0.0279525]\n",
      "Reward buffer length =  23300\n",
      "Num timesteps: 23400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0245\n",
      "Last reward =  [-0.01713677]\n",
      "Reward buffer length =  23400\n",
      "Num timesteps: 23500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0245\n",
      "Last reward =  [0.05591815]\n",
      "Reward buffer length =  23500\n",
      "Num timesteps: 23600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0203\n",
      "Last reward =  [-0.03216448]\n",
      "Reward buffer length =  23600\n",
      "Num timesteps: 23700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0224\n",
      "Last reward =  [-0.06342275]\n",
      "Reward buffer length =  23700\n",
      "Num timesteps: 23800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0089\n",
      "Last reward =  [0.00304452]\n",
      "Reward buffer length =  23800\n",
      "Num timesteps: 23900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0008\n",
      "Last reward =  [-0.00678695]\n",
      "Reward buffer length =  23900\n",
      "Num timesteps: 24000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0082\n",
      "Last reward =  [-0.00456502]\n",
      "Reward buffer length =  24000\n",
      "Num timesteps: 24100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0075\n",
      "Last reward =  [0.05023639]\n",
      "Reward buffer length =  24100\n",
      "Num timesteps: 24200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0167\n",
      "Last reward =  [-0.00878946]\n",
      "Reward buffer length =  24200\n",
      "Num timesteps: 24300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0241\n",
      "Last reward =  [-0.02650902]\n",
      "Reward buffer length =  24300\n",
      "Num timesteps: 24400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0259\n",
      "Last reward =  [-0.03359838]\n",
      "Reward buffer length =  24400\n",
      "Num timesteps: 24500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0042\n",
      "Last reward =  [-0.01828603]\n",
      "Reward buffer length =  24500\n",
      "Num timesteps: 24600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0022\n",
      "Last reward =  [0.0079725]\n",
      "Reward buffer length =  24600\n",
      "Num timesteps: 24700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0020\n",
      "Last reward =  [-0.01209556]\n",
      "Reward buffer length =  24700\n",
      "Num timesteps: 24800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0059\n",
      "Last reward =  [-0.10252574]\n",
      "Reward buffer length =  24800\n",
      "Num timesteps: 24900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0091\n",
      "Last reward =  [-0.02747003]\n",
      "Reward buffer length =  24900\n",
      "Num timesteps: 25000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0148\n",
      "Last reward =  [0.00472075]\n",
      "Reward buffer length =  25000\n",
      "Num timesteps: 25100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0241\n",
      "Last reward =  [0.04757974]\n",
      "Reward buffer length =  25100\n",
      "Num timesteps: 25200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0267\n",
      "Last reward =  [-0.00136592]\n",
      "Reward buffer length =  25200\n",
      "Num timesteps: 25300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0012\n",
      "Last reward =  [-0.03678233]\n",
      "Reward buffer length =  25300\n",
      "Num timesteps: 25400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0050\n",
      "Last reward =  [-0.05946361]\n",
      "Reward buffer length =  25400\n",
      "Num timesteps: 25500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0003\n",
      "Last reward =  [-0.03178174]\n",
      "Reward buffer length =  25500\n",
      "Num timesteps: 25600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0195\n",
      "Last reward =  [0.00679419]\n",
      "Reward buffer length =  25600\n",
      "Num timesteps: 25700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0247\n",
      "Last reward =  [0.00254711]\n",
      "Reward buffer length =  25700\n",
      "Num timesteps: 25800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0287\n",
      "Last reward =  [-0.1093329]\n",
      "Reward buffer length =  25800\n",
      "Num timesteps: 25900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0051\n",
      "Last reward =  [0.05076194]\n",
      "Reward buffer length =  25900\n",
      "Num timesteps: 26000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0087\n",
      "Last reward =  [-0.03547623]\n",
      "Reward buffer length =  26000\n",
      "Num timesteps: 26100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0034\n",
      "Last reward =  [-0.02233255]\n",
      "Reward buffer length =  26100\n",
      "Num timesteps: 26200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0189\n",
      "Last reward =  [-0.04694536]\n",
      "Reward buffer length =  26200\n",
      "Num timesteps: 26300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0257\n",
      "Last reward =  [-0.03953051]\n",
      "Reward buffer length =  26300\n",
      "Num timesteps: 26400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0266\n",
      "Last reward =  [-0.03549438]\n",
      "Reward buffer length =  26400\n",
      "Num timesteps: 26500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0173\n",
      "Last reward =  [-0.0641681]\n",
      "Reward buffer length =  26500\n",
      "Num timesteps: 26600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0007\n",
      "Last reward =  [-0.03877057]\n",
      "Reward buffer length =  26600\n",
      "Num timesteps: 26700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0039\n",
      "Last reward =  [-0.00634283]\n",
      "Reward buffer length =  26700\n",
      "Num timesteps: 26800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0043\n",
      "Last reward =  [0.02570685]\n",
      "Reward buffer length =  26800\n",
      "Num timesteps: 26900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0120\n",
      "Last reward =  [0.00442468]\n",
      "Reward buffer length =  26900\n",
      "Num timesteps: 27000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0186\n",
      "Last reward =  [-0.00701859]\n",
      "Reward buffer length =  27000\n",
      "Num timesteps: 27100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0294\n",
      "Last reward =  [-0.06562889]\n",
      "Reward buffer length =  27100\n",
      "Num timesteps: 27200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0265\n",
      "Last reward =  [-0.04959919]\n",
      "Reward buffer length =  27200\n",
      "Num timesteps: 27300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0018\n",
      "Last reward =  [-0.04329102]\n",
      "Reward buffer length =  27300\n",
      "Num timesteps: 27400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0039\n",
      "Last reward =  [0.01752009]\n",
      "Reward buffer length =  27400\n",
      "Num timesteps: 27500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0046\n",
      "Last reward =  [-0.07065249]\n",
      "Reward buffer length =  27500\n",
      "Num timesteps: 27600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0096\n",
      "Last reward =  [-0.00334655]\n",
      "Reward buffer length =  27600\n",
      "Num timesteps: 27700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0005\n",
      "Last reward =  [0.02343279]\n",
      "Reward buffer length =  27700\n",
      "Num timesteps: 27800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0184\n",
      "Last reward =  [-0.05560925]\n",
      "Reward buffer length =  27800\n",
      "Num timesteps: 27900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0258\n",
      "Last reward =  [-0.00516104]\n",
      "Reward buffer length =  27900\n",
      "Num timesteps: 28000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0309\n",
      "Last reward =  [-0.02693567]\n",
      "Reward buffer length =  28000\n",
      "Num timesteps: 28100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0182\n",
      "Last reward =  [-0.00460665]\n",
      "Reward buffer length =  28100\n",
      "Num timesteps: 28200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0090\n",
      "Last reward =  [-0.02403665]\n",
      "Reward buffer length =  28200\n",
      "Num timesteps: 28300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0052\n",
      "Last reward =  [-0.02758119]\n",
      "Reward buffer length =  28300\n",
      "Num timesteps: 28400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0155\n",
      "Last reward =  [-0.0414697]\n",
      "Reward buffer length =  28400\n",
      "Num timesteps: 28500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0270\n",
      "Last reward =  [0.01419203]\n",
      "Reward buffer length =  28500\n",
      "Num timesteps: 28600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0292\n",
      "Last reward =  [-0.03403374]\n",
      "Reward buffer length =  28600\n",
      "Num timesteps: 28700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0268\n",
      "Last reward =  [-0.08715517]\n",
      "Reward buffer length =  28700\n",
      "Num timesteps: 28800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0061\n",
      "Last reward =  [-0.00918358]\n",
      "Reward buffer length =  28800\n",
      "Num timesteps: 28900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0143\n",
      "Last reward =  [0.11279303]\n",
      "Reward buffer length =  28900\n",
      "Num timesteps: 29000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0057\n",
      "Last reward =  [0.00866228]\n",
      "Reward buffer length =  29000\n",
      "Num timesteps: 29100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0231\n",
      "Last reward =  [-0.04479034]\n",
      "Reward buffer length =  29100\n",
      "Num timesteps: 29200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0294\n",
      "Last reward =  [-0.06132513]\n",
      "Reward buffer length =  29200\n",
      "Num timesteps: 29300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0332\n",
      "Last reward =  [-0.02016442]\n",
      "Reward buffer length =  29300\n",
      "Num timesteps: 29400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0177\n",
      "Last reward =  [-0.05085216]\n",
      "Reward buffer length =  29400\n",
      "Num timesteps: 29500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0069\n",
      "Last reward =  [0.09345675]\n",
      "Reward buffer length =  29500\n",
      "Num timesteps: 29600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0188\n",
      "Last reward =  [-0.02297962]\n",
      "Reward buffer length =  29600\n",
      "Num timesteps: 29700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0282\n",
      "Last reward =  [-0.04072486]\n",
      "Reward buffer length =  29700\n",
      "Num timesteps: 29800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0288\n",
      "Last reward =  [-0.03121401]\n",
      "Reward buffer length =  29800\n",
      "Num timesteps: 29900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0178\n",
      "Last reward =  [-0.07328966]\n",
      "Reward buffer length =  29900\n",
      "Num timesteps: 30000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0187\n",
      "Last reward =  [-0.0563608]\n",
      "Reward buffer length =  30000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 30100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.07604628]\n",
      "Reward buffer length =  30100\n",
      "Num timesteps: 30200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0331\n",
      "Last reward =  [-0.05200021]\n",
      "Reward buffer length =  30200\n",
      "Num timesteps: 30300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0336\n",
      "Last reward =  [-0.02286181]\n",
      "Reward buffer length =  30300\n",
      "Num timesteps: 30400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0045\n",
      "Last reward =  [-0.02552866]\n",
      "Reward buffer length =  30400\n",
      "Num timesteps: 30500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0125\n",
      "Last reward =  [-0.03406162]\n",
      "Reward buffer length =  30500\n",
      "Num timesteps: 30600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0051\n",
      "Last reward =  [0.00991732]\n",
      "Reward buffer length =  30600\n",
      "Num timesteps: 30700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0194\n",
      "Last reward =  [-0.05019448]\n",
      "Reward buffer length =  30700\n",
      "Num timesteps: 30800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0234\n",
      "Last reward =  [-0.04507987]\n",
      "Reward buffer length =  30800\n",
      "Num timesteps: 30900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0316\n",
      "Last reward =  [-0.06076495]\n",
      "Reward buffer length =  30900\n",
      "Num timesteps: 31000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0355\n",
      "Last reward =  [-0.04520583]\n",
      "Reward buffer length =  31000\n",
      "Num timesteps: 31100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0173\n",
      "Last reward =  [-0.03499481]\n",
      "Reward buffer length =  31100\n",
      "Num timesteps: 31200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0039\n",
      "Last reward =  [-0.03476338]\n",
      "Reward buffer length =  31200\n",
      "Num timesteps: 31300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.05750079]\n",
      "Reward buffer length =  31300\n",
      "Num timesteps: 31400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0244\n",
      "Last reward =  [-0.05493183]\n",
      "Reward buffer length =  31400\n",
      "Num timesteps: 31500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0308\n",
      "Last reward =  [-0.0476827]\n",
      "Reward buffer length =  31500\n",
      "Num timesteps: 31600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0196\n",
      "Last reward =  [0.01987424]\n",
      "Reward buffer length =  31600\n",
      "Num timesteps: 31700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0232\n",
      "Last reward =  [-0.0224349]\n",
      "Reward buffer length =  31700\n",
      "Num timesteps: 31800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0283\n",
      "Last reward =  [0.01208954]\n",
      "Reward buffer length =  31800\n",
      "Num timesteps: 31900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0339\n",
      "Last reward =  [-0.04821974]\n",
      "Reward buffer length =  31900\n",
      "Num timesteps: 32000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0386\n",
      "Last reward =  [-0.01645083]\n",
      "Reward buffer length =  32000\n",
      "Num timesteps: 32100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0387\n",
      "Last reward =  [-0.03898356]\n",
      "Reward buffer length =  32100\n",
      "Num timesteps: 32200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0227\n",
      "Last reward =  [0.01078922]\n",
      "Reward buffer length =  32200\n",
      "Num timesteps: 32300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0101\n",
      "Last reward =  [-0.07887799]\n",
      "Reward buffer length =  32300\n",
      "Num timesteps: 32400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0178\n",
      "Last reward =  [0.00882286]\n",
      "Reward buffer length =  32400\n",
      "Num timesteps: 32500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0102\n",
      "Last reward =  [0.01291649]\n",
      "Reward buffer length =  32500\n",
      "Num timesteps: 32600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0304\n",
      "Last reward =  [-0.06924295]\n",
      "Reward buffer length =  32600\n",
      "Num timesteps: 32700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0297\n",
      "Last reward =  [-0.01866897]\n",
      "Reward buffer length =  32700\n",
      "Num timesteps: 32800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0387\n",
      "Last reward =  [-0.03465133]\n",
      "Reward buffer length =  32800\n",
      "Num timesteps: 32900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0321\n",
      "Last reward =  [-0.01258247]\n",
      "Reward buffer length =  32900\n",
      "Num timesteps: 33000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0106\n",
      "Last reward =  [-0.0524797]\n",
      "Reward buffer length =  33000\n",
      "Num timesteps: 33100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0298\n",
      "Last reward =  [-0.05483012]\n",
      "Reward buffer length =  33100\n",
      "Num timesteps: 33200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0298\n",
      "Last reward =  [-0.05111957]\n",
      "Reward buffer length =  33200\n",
      "Num timesteps: 33300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0404\n",
      "Last reward =  [-0.02292683]\n",
      "Reward buffer length =  33300\n",
      "Num timesteps: 33400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0308\n",
      "Last reward =  [-0.04082656]\n",
      "Reward buffer length =  33400\n",
      "Num timesteps: 33500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0048\n",
      "Last reward =  [-0.02566891]\n",
      "Reward buffer length =  33500\n",
      "Num timesteps: 33600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0072\n",
      "Last reward =  [-0.01425306]\n",
      "Reward buffer length =  33600\n",
      "Num timesteps: 33700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0134\n",
      "Last reward =  [-0.04086619]\n",
      "Reward buffer length =  33700\n",
      "Num timesteps: 33800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0209\n",
      "Last reward =  [-0.01982968]\n",
      "Reward buffer length =  33800\n",
      "Num timesteps: 33900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0146\n",
      "Last reward =  [-0.02979949]\n",
      "Reward buffer length =  33900\n",
      "Num timesteps: 34000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0310\n",
      "Last reward =  [0.00835346]\n",
      "Reward buffer length =  34000\n",
      "Num timesteps: 34100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0335\n",
      "Last reward =  [-0.01527004]\n",
      "Reward buffer length =  34100\n",
      "Num timesteps: 34200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0459\n",
      "Last reward =  [-0.06208632]\n",
      "Reward buffer length =  34200\n",
      "Num timesteps: 34300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0402\n",
      "Last reward =  [-0.06021871]\n",
      "Reward buffer length =  34300\n",
      "Num timesteps: 34400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0338\n",
      "Last reward =  [-0.07416065]\n",
      "Reward buffer length =  34400\n",
      "Num timesteps: 34500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0428\n",
      "Last reward =  [-0.02825742]\n",
      "Reward buffer length =  34500\n",
      "Num timesteps: 34600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0211\n",
      "Last reward =  [-0.01413083]\n",
      "Reward buffer length =  34600\n",
      "Num timesteps: 34700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0148\n",
      "Last reward =  [-0.01996785]\n",
      "Reward buffer length =  34700\n",
      "Num timesteps: 34800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0161\n",
      "Last reward =  [-0.02016506]\n",
      "Reward buffer length =  34800\n",
      "Num timesteps: 34900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0244\n",
      "Last reward =  [-0.05944547]\n",
      "Reward buffer length =  34900\n",
      "Num timesteps: 35000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0377\n",
      "Last reward =  [-0.00277798]\n",
      "Reward buffer length =  35000\n",
      "Num timesteps: 35100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0393\n",
      "Last reward =  [-0.0843813]\n",
      "Reward buffer length =  35100\n",
      "Num timesteps: 35200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0487\n",
      "Last reward =  [-0.08133385]\n",
      "Reward buffer length =  35200\n",
      "Num timesteps: 35300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0361\n",
      "Last reward =  [0.06785306]\n",
      "Reward buffer length =  35300\n",
      "Num timesteps: 35400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0442\n",
      "Last reward =  [-0.07679665]\n",
      "Reward buffer length =  35400\n",
      "Num timesteps: 35500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0478\n",
      "Last reward =  [-0.06913956]\n",
      "Reward buffer length =  35500\n",
      "Num timesteps: 35600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0403\n",
      "Last reward =  [-0.03912026]\n",
      "Reward buffer length =  35600\n",
      "Num timesteps: 35700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0436\n",
      "Last reward =  [-0.08154728]\n",
      "Reward buffer length =  35700\n",
      "Num timesteps: 35800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0514\n",
      "Last reward =  [-0.05864799]\n",
      "Reward buffer length =  35800\n",
      "Num timesteps: 35900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0383\n",
      "Last reward =  [0.11714115]\n",
      "Reward buffer length =  35900\n",
      "Num timesteps: 36000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0191\n",
      "Last reward =  [-0.0225]\n",
      "Reward buffer length =  36000\n",
      "Num timesteps: 36100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0374\n",
      "Last reward =  [-0.07147124]\n",
      "Reward buffer length =  36100\n",
      "Num timesteps: 36200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0435\n",
      "Last reward =  [-0.09588186]\n",
      "Reward buffer length =  36200\n",
      "Num timesteps: 36300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0522\n",
      "Last reward =  [-0.05160747]\n",
      "Reward buffer length =  36300\n",
      "Num timesteps: 36400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0333\n",
      "Last reward =  [-0.05220674]\n",
      "Reward buffer length =  36400\n",
      "Num timesteps: 36500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0181\n",
      "Last reward =  [-0.02880421]\n",
      "Reward buffer length =  36500\n",
      "Num timesteps: 36600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0352\n",
      "Last reward =  [-0.02687764]\n",
      "Reward buffer length =  36600\n",
      "Num timesteps: 36700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0422\n",
      "Last reward =  [-0.02740129]\n",
      "Reward buffer length =  36700\n",
      "Num timesteps: 36800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0497\n",
      "Last reward =  [-0.03069159]\n",
      "Reward buffer length =  36800\n",
      "Num timesteps: 36900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0254\n",
      "Last reward =  [-0.01045644]\n",
      "Reward buffer length =  36900\n",
      "Num timesteps: 37000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0193\n",
      "Last reward =  [-0.00305026]\n",
      "Reward buffer length =  37000\n",
      "Num timesteps: 37100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0209\n",
      "Last reward =  [-0.10413205]\n",
      "Reward buffer length =  37100\n",
      "Num timesteps: 37200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0305\n",
      "Last reward =  [-0.0763156]\n",
      "Reward buffer length =  37200\n",
      "Num timesteps: 37300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0417\n",
      "Last reward =  [-0.08190309]\n",
      "Reward buffer length =  37300\n",
      "Num timesteps: 37400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0476\n",
      "Last reward =  [-0.02969838]\n",
      "Reward buffer length =  37400\n",
      "Num timesteps: 37500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0594\n",
      "Last reward =  [-0.06280578]\n",
      "Reward buffer length =  37500\n",
      "Num timesteps: 37600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0257\n",
      "Last reward =  [-0.01865439]\n",
      "Reward buffer length =  37600\n",
      "Num timesteps: 37700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0321\n",
      "Last reward =  [-0.0476322]\n",
      "Reward buffer length =  37700\n",
      "Num timesteps: 37800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0403\n",
      "Last reward =  [-0.05329172]\n",
      "Reward buffer length =  37800\n",
      "Num timesteps: 37900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0457\n",
      "Last reward =  [-0.06958064]\n",
      "Reward buffer length =  37900\n",
      "Num timesteps: 38000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0562\n",
      "Last reward =  [-0.04068355]\n",
      "Reward buffer length =  38000\n",
      "Num timesteps: 38100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0477\n",
      "Last reward =  [-0.07968954]\n",
      "Reward buffer length =  38100\n",
      "Num timesteps: 38200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0576\n",
      "Last reward =  [-0.03039032]\n",
      "Reward buffer length =  38200\n",
      "Num timesteps: 38300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0143\n",
      "Last reward =  [-0.01033809]\n",
      "Reward buffer length =  38300\n",
      "Num timesteps: 38400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0271\n",
      "Last reward =  [-0.04581569]\n",
      "Reward buffer length =  38400\n",
      "Num timesteps: 38500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0180\n",
      "Last reward =  [-0.05422549]\n",
      "Reward buffer length =  38500\n",
      "Num timesteps: 38600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0381\n",
      "Last reward =  [-0.02152965]\n",
      "Reward buffer length =  38600\n",
      "Num timesteps: 38700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0416\n",
      "Last reward =  [-0.01842046]\n",
      "Reward buffer length =  38700\n",
      "Num timesteps: 38800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0508\n",
      "Last reward =  [0.01205454]\n",
      "Reward buffer length =  38800\n",
      "Num timesteps: 38900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0355\n",
      "Last reward =  [-0.05376134]\n",
      "Reward buffer length =  38900\n",
      "Num timesteps: 39000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0157\n",
      "Last reward =  [-0.02056256]\n",
      "Reward buffer length =  39000\n",
      "Num timesteps: 39100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0266\n",
      "Last reward =  [-0.03617435]\n",
      "Reward buffer length =  39100\n",
      "Num timesteps: 39200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0193\n",
      "Last reward =  [-0.00839006]\n",
      "Reward buffer length =  39200\n",
      "Num timesteps: 39300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0398\n",
      "Last reward =  [-0.07911924]\n",
      "Reward buffer length =  39300\n",
      "Num timesteps: 39400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0424\n",
      "Last reward =  [-0.01683142]\n",
      "Reward buffer length =  39400\n",
      "Num timesteps: 39500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0560\n",
      "Last reward =  [-0.05092411]\n",
      "Reward buffer length =  39500\n",
      "Num timesteps: 39600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0423\n",
      "Last reward =  [-0.05395224]\n",
      "Reward buffer length =  39600\n",
      "Num timesteps: 39700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0235\n",
      "Last reward =  [0.11326521]\n",
      "Reward buffer length =  39700\n",
      "Num timesteps: 39800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0320\n",
      "Last reward =  [-0.03662812]\n",
      "Reward buffer length =  39800\n",
      "Num timesteps: 39900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0437\n",
      "Last reward =  [-0.01215418]\n",
      "Reward buffer length =  39900\n",
      "Num timesteps: 40000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0486\n",
      "Last reward =  [-0.06359363]\n",
      "Reward buffer length =  40000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 40100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0646\n",
      "Last reward =  [-0.11314176]\n",
      "Reward buffer length =  40100\n",
      "Num timesteps: 40200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0392\n",
      "Last reward =  [-0.03940107]\n",
      "Reward buffer length =  40200\n",
      "Num timesteps: 40300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0462\n",
      "Last reward =  [-0.01517435]\n",
      "Reward buffer length =  40300\n",
      "Num timesteps: 40400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0522\n",
      "Last reward =  [-0.1013803]\n",
      "Reward buffer length =  40400\n",
      "Num timesteps: 40500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0636\n",
      "Last reward =  [-0.10920689]\n",
      "Reward buffer length =  40500\n",
      "Num timesteps: 40600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0032\n",
      "Last reward =  [0.03076401]\n",
      "Reward buffer length =  40600\n",
      "Num timesteps: 40700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0077\n",
      "Last reward =  [-0.02508542]\n",
      "Reward buffer length =  40700\n",
      "Num timesteps: 40800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0112\n",
      "Last reward =  [0.00094233]\n",
      "Reward buffer length =  40800\n",
      "Num timesteps: 40900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.05202964]\n",
      "Reward buffer length =  40900\n",
      "Num timesteps: 41000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0249\n",
      "Last reward =  [-0.10524649]\n",
      "Reward buffer length =  41000\n",
      "Num timesteps: 41100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0422\n",
      "Last reward =  [-0.02932701]\n",
      "Reward buffer length =  41100\n",
      "Num timesteps: 41200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0492\n",
      "Last reward =  [-0.00739128]\n",
      "Reward buffer length =  41200\n",
      "Num timesteps: 41300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0566\n",
      "Last reward =  [-0.03546633]\n",
      "Reward buffer length =  41300\n",
      "Num timesteps: 41400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0612\n",
      "Last reward =  [0.0363903]\n",
      "Reward buffer length =  41400\n",
      "Num timesteps: 41500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0081\n",
      "Last reward =  [-0.03022261]\n",
      "Reward buffer length =  41500\n",
      "Num timesteps: 41600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0184\n",
      "Last reward =  [0.05503029]\n",
      "Reward buffer length =  41600\n",
      "Num timesteps: 41700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0333\n",
      "Last reward =  [-0.10472737]\n",
      "Reward buffer length =  41700\n",
      "Num timesteps: 41800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0238\n",
      "Last reward =  [0.01714187]\n",
      "Reward buffer length =  41800\n",
      "Num timesteps: 41900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0436\n",
      "Last reward =  [-0.07363713]\n",
      "Reward buffer length =  41900\n",
      "Num timesteps: 42000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0513\n",
      "Last reward =  [-0.0484777]\n",
      "Reward buffer length =  42000\n",
      "Num timesteps: 42100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0571\n",
      "Last reward =  [-0.10803127]\n",
      "Reward buffer length =  42100\n",
      "Num timesteps: 42200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0356\n",
      "Last reward =  [-0.04008539]\n",
      "Reward buffer length =  42200\n",
      "Num timesteps: 42300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0399\n",
      "Last reward =  [-0.04355077]\n",
      "Reward buffer length =  42300\n",
      "Num timesteps: 42400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0535\n",
      "Last reward =  [-0.04976397]\n",
      "Reward buffer length =  42400\n",
      "Num timesteps: 42500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0577\n",
      "Last reward =  [-0.05136693]\n",
      "Reward buffer length =  42500\n",
      "Num timesteps: 42600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0658\n",
      "Last reward =  [0.00744226]\n",
      "Reward buffer length =  42600\n",
      "Num timesteps: 42700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0032\n",
      "Last reward =  [-0.06745447]\n",
      "Reward buffer length =  42700\n",
      "Num timesteps: 42800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0098\n",
      "Last reward =  [-0.00690601]\n",
      "Reward buffer length =  42800\n",
      "Num timesteps: 42900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0200\n",
      "Last reward =  [-0.03876255]\n",
      "Reward buffer length =  42900\n",
      "Num timesteps: 43000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0327\n",
      "Last reward =  [-0.0272103]\n",
      "Reward buffer length =  43000\n",
      "Num timesteps: 43100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0281\n",
      "Last reward =  [-0.08118451]\n",
      "Reward buffer length =  43100\n",
      "Num timesteps: 43200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0495\n",
      "Last reward =  [-0.02141033]\n",
      "Reward buffer length =  43200\n",
      "Num timesteps: 43300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0528\n",
      "Last reward =  [-0.05930062]\n",
      "Reward buffer length =  43300\n",
      "Num timesteps: 43400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0634\n",
      "Last reward =  [-0.057739]\n",
      "Reward buffer length =  43400\n",
      "Num timesteps: 43500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0603\n",
      "Last reward =  [-0.03734127]\n",
      "Reward buffer length =  43500\n",
      "Num timesteps: 43600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0521\n",
      "Last reward =  [-0.0509724]\n",
      "Reward buffer length =  43600\n",
      "Num timesteps: 43700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0630\n",
      "Last reward =  [-0.03877353]\n",
      "Reward buffer length =  43700\n",
      "Num timesteps: 43800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0763\n",
      "Last reward =  [-0.05596286]\n",
      "Reward buffer length =  43800\n",
      "Num timesteps: 43900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0415\n",
      "Last reward =  [-0.06469482]\n",
      "Reward buffer length =  43900\n",
      "Num timesteps: 44000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0327\n",
      "Last reward =  [-0.05052463]\n",
      "Reward buffer length =  44000\n",
      "Num timesteps: 44100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0335\n",
      "Last reward =  [-0.04546014]\n",
      "Reward buffer length =  44100\n",
      "Num timesteps: 44200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0514\n",
      "Last reward =  [-0.05034584]\n",
      "Reward buffer length =  44200\n",
      "Num timesteps: 44300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0581\n",
      "Last reward =  [-0.06907187]\n",
      "Reward buffer length =  44300\n",
      "Num timesteps: 44400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0705\n",
      "Last reward =  [-0.09153628]\n",
      "Reward buffer length =  44400\n",
      "Num timesteps: 44500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0729\n",
      "Last reward =  [-0.07360094]\n",
      "Reward buffer length =  44500\n",
      "Num timesteps: 44600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0529\n",
      "Last reward =  [-0.00221087]\n",
      "Reward buffer length =  44600\n",
      "Num timesteps: 44700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0358\n",
      "Last reward =  [-0.14504418]\n",
      "Reward buffer length =  44700\n",
      "Num timesteps: 44800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0336\n",
      "Last reward =  [-0.10585582]\n",
      "Reward buffer length =  44800\n",
      "Num timesteps: 44900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0520\n",
      "Last reward =  [0.02346378]\n",
      "Reward buffer length =  44900\n",
      "Num timesteps: 45000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0589\n",
      "Last reward =  [-0.08824593]\n",
      "Reward buffer length =  45000\n",
      "Num timesteps: 45100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0710\n",
      "Last reward =  [-0.06911941]\n",
      "Reward buffer length =  45100\n",
      "Num timesteps: 45200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0436\n",
      "Last reward =  [-0.02937947]\n",
      "Reward buffer length =  45200\n",
      "Num timesteps: 45300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0392\n",
      "Last reward =  [-0.00393914]\n",
      "Reward buffer length =  45300\n",
      "Num timesteps: 45400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0306\n",
      "Last reward =  [-0.01537987]\n",
      "Reward buffer length =  45400\n",
      "Num timesteps: 45500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0512\n",
      "Last reward =  [-0.02894449]\n",
      "Reward buffer length =  45500\n",
      "Num timesteps: 45600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0557\n",
      "Last reward =  [-0.086999]\n",
      "Reward buffer length =  45600\n",
      "Num timesteps: 45700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0683\n",
      "Last reward =  [-0.12343051]\n",
      "Reward buffer length =  45700\n",
      "Num timesteps: 45800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0456\n",
      "Last reward =  [-0.00750735]\n",
      "Reward buffer length =  45800\n",
      "Num timesteps: 45900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0134\n",
      "Last reward =  [-0.02609029]\n",
      "Reward buffer length =  45900\n",
      "Num timesteps: 46000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0244\n",
      "Last reward =  [-0.02049108]\n",
      "Reward buffer length =  46000\n",
      "Num timesteps: 46100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0394\n",
      "Last reward =  [-0.1057274]\n",
      "Reward buffer length =  46100\n",
      "Num timesteps: 46200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0383\n",
      "Last reward =  [-0.06942894]\n",
      "Reward buffer length =  46200\n",
      "Num timesteps: 46300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0606\n",
      "Last reward =  [-0.03311494]\n",
      "Reward buffer length =  46300\n",
      "Num timesteps: 46400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0653\n",
      "Last reward =  [-0.0561505]\n",
      "Reward buffer length =  46400\n",
      "Num timesteps: 46500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0778\n",
      "Last reward =  [-0.19349675]\n",
      "Reward buffer length =  46500\n",
      "Num timesteps: 46600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0484\n",
      "Last reward =  [-0.02079725]\n",
      "Reward buffer length =  46600\n",
      "Num timesteps: 46700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0573\n",
      "Last reward =  [-0.05782568]\n",
      "Reward buffer length =  46700\n",
      "Num timesteps: 46800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0611\n",
      "Last reward =  [-0.03790583]\n",
      "Reward buffer length =  46800\n",
      "Num timesteps: 46900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0719\n",
      "Last reward =  [-0.10874889]\n",
      "Reward buffer length =  46900\n",
      "Num timesteps: 47000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0447\n",
      "Last reward =  [-0.07431313]\n",
      "Reward buffer length =  47000\n",
      "Num timesteps: 47100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0313\n",
      "Last reward =  [-0.20109376]\n",
      "Reward buffer length =  47100\n",
      "Num timesteps: 47200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0497\n",
      "Last reward =  [-0.01235841]\n",
      "Reward buffer length =  47200\n",
      "Num timesteps: 47300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0621\n",
      "Last reward =  [-0.06924309]\n",
      "Reward buffer length =  47300\n",
      "Num timesteps: 47400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0672\n",
      "Last reward =  [-0.03406746]\n",
      "Reward buffer length =  47400\n",
      "Num timesteps: 47500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0765\n",
      "Last reward =  [-0.11364584]\n",
      "Reward buffer length =  47500\n",
      "Num timesteps: 47600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0712\n",
      "Last reward =  [0.02396707]\n",
      "Reward buffer length =  47600\n",
      "Num timesteps: 47700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0440\n",
      "Last reward =  [-0.02328388]\n",
      "Reward buffer length =  47700\n",
      "Num timesteps: 47800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0137\n",
      "Last reward =  [-0.02798779]\n",
      "Reward buffer length =  47800\n",
      "Num timesteps: 47900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0304\n",
      "Last reward =  [-0.04922945]\n",
      "Reward buffer length =  47900\n",
      "Num timesteps: 48000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0361\n",
      "Last reward =  [-0.00842611]\n",
      "Reward buffer length =  48000\n",
      "Num timesteps: 48100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0469\n",
      "Last reward =  [-0.07336982]\n",
      "Reward buffer length =  48100\n",
      "Num timesteps: 48200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0641\n",
      "Last reward =  [-0.06846902]\n",
      "Reward buffer length =  48200\n",
      "Num timesteps: 48300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0681\n",
      "Last reward =  [-0.10219938]\n",
      "Reward buffer length =  48300\n",
      "Num timesteps: 48400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0792\n",
      "Last reward =  [-0.05593473]\n",
      "Reward buffer length =  48400\n",
      "Num timesteps: 48500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0735\n",
      "Last reward =  [-0.05853773]\n",
      "Reward buffer length =  48500\n",
      "Num timesteps: 48600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0322\n",
      "Last reward =  [0.00560999]\n",
      "Reward buffer length =  48600\n",
      "Num timesteps: 48700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0543\n",
      "Last reward =  [-0.08935656]\n",
      "Reward buffer length =  48700\n",
      "Num timesteps: 48800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0647\n",
      "Last reward =  [-0.03583619]\n",
      "Reward buffer length =  48800\n",
      "Num timesteps: 48900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0662\n",
      "Last reward =  [-0.06712303]\n",
      "Reward buffer length =  48900\n",
      "Num timesteps: 49000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0780\n",
      "Last reward =  [-0.05748596]\n",
      "Reward buffer length =  49000\n",
      "Num timesteps: 49100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0353\n",
      "Last reward =  [-0.12454678]\n",
      "Reward buffer length =  49100\n",
      "Num timesteps: 49200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0571\n",
      "Last reward =  [-0.03473539]\n",
      "Reward buffer length =  49200\n",
      "Num timesteps: 49300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0651\n",
      "Last reward =  [-0.02682544]\n",
      "Reward buffer length =  49300\n",
      "Num timesteps: 49400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0671\n",
      "Last reward =  [-0.06636455]\n",
      "Reward buffer length =  49400\n",
      "Num timesteps: 49500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0803\n",
      "Last reward =  [-0.09059855]\n",
      "Reward buffer length =  49500\n",
      "Num timesteps: 49600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0797\n",
      "Last reward =  [-0.04924638]\n",
      "Reward buffer length =  49600\n",
      "Num timesteps: 49700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0737\n",
      "Last reward =  [-0.00879532]\n",
      "Reward buffer length =  49700\n",
      "Num timesteps: 49800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0665\n",
      "Last reward =  [-0.06352273]\n",
      "Reward buffer length =  49800\n",
      "Num timesteps: 49900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0645\n",
      "Last reward =  [-0.08787649]\n",
      "Reward buffer length =  49900\n",
      "Num timesteps: 50000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0812\n",
      "Last reward =  [-0.05778089]\n",
      "Reward buffer length =  50000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 50100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0279\n",
      "Last reward =  [-0.03516677]\n",
      "Reward buffer length =  50100\n",
      "Num timesteps: 50200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0417\n",
      "Last reward =  [0.01636215]\n",
      "Reward buffer length =  50200\n",
      "Num timesteps: 50300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0403\n",
      "Last reward =  [-0.07416808]\n",
      "Reward buffer length =  50300\n",
      "Num timesteps: 50400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0622\n",
      "Last reward =  [-0.04624745]\n",
      "Reward buffer length =  50400\n",
      "Num timesteps: 50500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0588\n",
      "Last reward =  [-0.06645879]\n",
      "Reward buffer length =  50500\n",
      "Num timesteps: 50600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0828\n",
      "Last reward =  [-0.119685]\n",
      "Reward buffer length =  50600\n",
      "Num timesteps: 50700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0346\n",
      "Last reward =  [-0.03197152]\n",
      "Reward buffer length =  50700\n",
      "Num timesteps: 50800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0254\n",
      "Last reward =  [-0.06179958]\n",
      "Reward buffer length =  50800\n",
      "Num timesteps: 50900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0420\n",
      "Last reward =  [-0.03729231]\n",
      "Reward buffer length =  50900\n",
      "Num timesteps: 51000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0390\n",
      "Last reward =  [-0.11731078]\n",
      "Reward buffer length =  51000\n",
      "Num timesteps: 51100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0631\n",
      "Last reward =  [-0.04563838]\n",
      "Reward buffer length =  51100\n",
      "Num timesteps: 51200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0666\n",
      "Last reward =  [-0.06749954]\n",
      "Reward buffer length =  51200\n",
      "Num timesteps: 51300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0770\n",
      "Last reward =  [-0.00305196]\n",
      "Reward buffer length =  51300\n",
      "Num timesteps: 51400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0797\n",
      "Last reward =  [-0.06831439]\n",
      "Reward buffer length =  51400\n",
      "Num timesteps: 51500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0749\n",
      "Last reward =  [-0.05943314]\n",
      "Reward buffer length =  51500\n",
      "Num timesteps: 51600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0749\n",
      "Last reward =  [-0.07958153]\n",
      "Reward buffer length =  51600\n",
      "Num timesteps: 51700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0693\n",
      "Last reward =  [-0.10465464]\n",
      "Reward buffer length =  51700\n",
      "Num timesteps: 51800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0732\n",
      "Last reward =  [-0.09804203]\n",
      "Reward buffer length =  51800\n",
      "Num timesteps: 51900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0810\n",
      "Last reward =  [-0.00044963]\n",
      "Reward buffer length =  51900\n",
      "Num timesteps: 52000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0382\n",
      "Last reward =  [0.04413113]\n",
      "Reward buffer length =  52000\n",
      "Num timesteps: 52100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0632\n",
      "Last reward =  [-0.07186138]\n",
      "Reward buffer length =  52100\n",
      "Num timesteps: 52200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0720\n",
      "Last reward =  [-0.10786481]\n",
      "Reward buffer length =  52200\n",
      "Num timesteps: 52300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0794\n",
      "Last reward =  [-0.12251396]\n",
      "Reward buffer length =  52300\n",
      "Num timesteps: 52400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0442\n",
      "Last reward =  [0.01611044]\n",
      "Reward buffer length =  52400\n",
      "Num timesteps: 52500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0075\n",
      "Last reward =  [-0.04409061]\n",
      "Reward buffer length =  52500\n",
      "Num timesteps: 52600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0177\n",
      "Last reward =  [-0.00067717]\n",
      "Reward buffer length =  52600\n",
      "Num timesteps: 52700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0349\n",
      "Last reward =  [-0.00820107]\n",
      "Reward buffer length =  52700\n",
      "Num timesteps: 52800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0410\n",
      "Last reward =  [-0.04407394]\n",
      "Reward buffer length =  52800\n",
      "Num timesteps: 52900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0557\n",
      "Last reward =  [-0.03913628]\n",
      "Reward buffer length =  52900\n",
      "Num timesteps: 53000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0716\n",
      "Last reward =  [-0.16521367]\n",
      "Reward buffer length =  53000\n",
      "Num timesteps: 53100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0714\n",
      "Last reward =  [-0.04180753]\n",
      "Reward buffer length =  53100\n",
      "Num timesteps: 53200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0877\n",
      "Last reward =  [-0.06977463]\n",
      "Reward buffer length =  53200\n",
      "Num timesteps: 53300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0722\n",
      "Last reward =  [-0.07808349]\n",
      "Reward buffer length =  53300\n",
      "Num timesteps: 53400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0895\n",
      "Last reward =  [-0.0428518]\n",
      "Reward buffer length =  53400\n",
      "Num timesteps: 53500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0711\n",
      "Last reward =  [-0.09258253]\n",
      "Reward buffer length =  53500\n",
      "Num timesteps: 53600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0929\n",
      "Last reward =  [-0.08036134]\n",
      "Reward buffer length =  53600\n",
      "Num timesteps: 53700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0056\n",
      "Last reward =  [-0.00636571]\n",
      "Reward buffer length =  53700\n",
      "Num timesteps: 53800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0084\n",
      "Last reward =  [-0.08424113]\n",
      "Reward buffer length =  53800\n",
      "Num timesteps: 53900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0170\n",
      "Last reward =  [-0.05208039]\n",
      "Reward buffer length =  53900\n",
      "Num timesteps: 54000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0347\n",
      "Last reward =  [-0.03172661]\n",
      "Reward buffer length =  54000\n",
      "Num timesteps: 54100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0405\n",
      "Last reward =  [-0.0153701]\n",
      "Reward buffer length =  54100\n",
      "Num timesteps: 54200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0633\n",
      "Last reward =  [-0.0613079]\n",
      "Reward buffer length =  54200\n",
      "Num timesteps: 54300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0727\n",
      "Last reward =  [-0.08325002]\n",
      "Reward buffer length =  54300\n",
      "Num timesteps: 54400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0749\n",
      "Last reward =  [-0.07703916]\n",
      "Reward buffer length =  54400\n",
      "Num timesteps: 54500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0922\n",
      "Last reward =  [-0.05830808]\n",
      "Reward buffer length =  54500\n",
      "Num timesteps: 54600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0888\n",
      "Last reward =  [-0.08538699]\n",
      "Reward buffer length =  54600\n",
      "Num timesteps: 54700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0659\n",
      "Last reward =  [-0.10777652]\n",
      "Reward buffer length =  54700\n",
      "Num timesteps: 54800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0719\n",
      "Last reward =  [-0.04742114]\n",
      "Reward buffer length =  54800\n",
      "Num timesteps: 54900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0824\n",
      "Last reward =  [-0.0846441]\n",
      "Reward buffer length =  54900\n",
      "Num timesteps: 55000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0762\n",
      "Last reward =  [-0.129446]\n",
      "Reward buffer length =  55000\n",
      "Num timesteps: 55100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0729\n",
      "Last reward =  [-0.02678955]\n",
      "Reward buffer length =  55100\n",
      "Num timesteps: 55200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0772\n",
      "Last reward =  [-0.17067716]\n",
      "Reward buffer length =  55200\n",
      "Num timesteps: 55300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0953\n",
      "Last reward =  [-0.13018876]\n",
      "Reward buffer length =  55300\n",
      "Num timesteps: 55400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0515\n",
      "Last reward =  [-0.06385029]\n",
      "Reward buffer length =  55400\n",
      "Num timesteps: 55500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0508\n",
      "Last reward =  [-0.06722387]\n",
      "Reward buffer length =  55500\n",
      "Num timesteps: 55600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0412\n",
      "Last reward =  [-0.02125426]\n",
      "Reward buffer length =  55600\n",
      "Num timesteps: 55700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0728\n",
      "Last reward =  [-0.07638437]\n",
      "Reward buffer length =  55700\n",
      "Num timesteps: 55800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0761\n",
      "Last reward =  [-0.06589045]\n",
      "Reward buffer length =  55800\n",
      "Num timesteps: 55900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0972\n",
      "Last reward =  [-0.15862283]\n",
      "Reward buffer length =  55900\n",
      "Num timesteps: 56000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0325\n",
      "Last reward =  [-0.03946055]\n",
      "Reward buffer length =  56000\n",
      "Num timesteps: 56100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.01832668]\n",
      "Reward buffer length =  56100\n",
      "Num timesteps: 56200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0474\n",
      "Last reward =  [-0.08289588]\n",
      "Reward buffer length =  56200\n",
      "Num timesteps: 56300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0395\n",
      "Last reward =  [-0.06827965]\n",
      "Reward buffer length =  56300\n",
      "Num timesteps: 56400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0694\n",
      "Last reward =  [0.03356668]\n",
      "Reward buffer length =  56400\n",
      "Num timesteps: 56500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0733\n",
      "Last reward =  [-0.08341284]\n",
      "Reward buffer length =  56500\n",
      "Num timesteps: 56600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0835\n",
      "Last reward =  [-0.13792124]\n",
      "Reward buffer length =  56600\n",
      "Num timesteps: 56700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0943\n",
      "Last reward =  [-0.06639443]\n",
      "Reward buffer length =  56700\n",
      "Num timesteps: 56800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0724\n",
      "Last reward =  [-0.09646347]\n",
      "Reward buffer length =  56800\n",
      "Num timesteps: 56900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0742\n",
      "Last reward =  [-0.0645763]\n",
      "Reward buffer length =  56900\n",
      "Num timesteps: 57000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0741\n",
      "Last reward =  [-0.0715417]\n",
      "Reward buffer length =  57000\n",
      "Num timesteps: 57100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0886\n",
      "Last reward =  [-0.01409245]\n",
      "Reward buffer length =  57100\n",
      "Num timesteps: 57200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0879\n",
      "Last reward =  [-0.00445307]\n",
      "Reward buffer length =  57200\n",
      "Num timesteps: 57300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0802\n",
      "Last reward =  [-0.07184143]\n",
      "Reward buffer length =  57300\n",
      "Num timesteps: 57400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1009\n",
      "Last reward =  [-0.1046516]\n",
      "Reward buffer length =  57400\n",
      "Num timesteps: 57500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0827\n",
      "Last reward =  [-0.00633666]\n",
      "Reward buffer length =  57500\n",
      "Num timesteps: 57600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0118\n",
      "Last reward =  [-0.02445851]\n",
      "Reward buffer length =  57600\n",
      "Num timesteps: 57700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0211\n",
      "Last reward =  [-0.03777135]\n",
      "Reward buffer length =  57700\n",
      "Num timesteps: 57800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0393\n",
      "Last reward =  [-0.0630073]\n",
      "Reward buffer length =  57800\n",
      "Num timesteps: 57900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0435\n",
      "Last reward =  [0.01685533]\n",
      "Reward buffer length =  57900\n",
      "Num timesteps: 58000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0642\n",
      "Last reward =  [-0.09634717]\n",
      "Reward buffer length =  58000\n",
      "Num timesteps: 58100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0822\n",
      "Last reward =  [-0.03402643]\n",
      "Reward buffer length =  58100\n",
      "Num timesteps: 58200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0840\n",
      "Last reward =  [-0.12276648]\n",
      "Reward buffer length =  58200\n",
      "Num timesteps: 58300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0987\n",
      "Last reward =  [-0.08945518]\n",
      "Reward buffer length =  58300\n",
      "Num timesteps: 58400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0949\n",
      "Last reward =  [-0.08709504]\n",
      "Reward buffer length =  58400\n",
      "Num timesteps: 58500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0667\n",
      "Last reward =  [-0.00564612]\n",
      "Reward buffer length =  58500\n",
      "Num timesteps: 58600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0495\n",
      "Last reward =  [-0.06917364]\n",
      "Reward buffer length =  58600\n",
      "Num timesteps: 58700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0448\n",
      "Last reward =  [-0.09995676]\n",
      "Reward buffer length =  58700\n",
      "Num timesteps: 58800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0788\n",
      "Last reward =  [-0.13913414]\n",
      "Reward buffer length =  58800\n",
      "Num timesteps: 58900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0826\n",
      "Last reward =  [-0.06358187]\n",
      "Reward buffer length =  58900\n",
      "Num timesteps: 59000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0976\n",
      "Last reward =  [-0.08486523]\n",
      "Reward buffer length =  59000\n",
      "Num timesteps: 59100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0728\n",
      "Last reward =  [-0.11395886]\n",
      "Reward buffer length =  59100\n",
      "Num timesteps: 59200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0751\n",
      "Last reward =  [-0.11732759]\n",
      "Reward buffer length =  59200\n",
      "Num timesteps: 59300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0773\n",
      "Last reward =  [-0.12969771]\n",
      "Reward buffer length =  59300\n",
      "Num timesteps: 59400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0900\n",
      "Last reward =  [-0.11184238]\n",
      "Reward buffer length =  59400\n",
      "Num timesteps: 59500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0878\n",
      "Last reward =  [-0.0316365]\n",
      "Reward buffer length =  59500\n",
      "Num timesteps: 59600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0783\n",
      "Last reward =  [-0.09190708]\n",
      "Reward buffer length =  59600\n",
      "Num timesteps: 59700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0803\n",
      "Last reward =  [-0.04879047]\n",
      "Reward buffer length =  59700\n",
      "Num timesteps: 59800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0953\n",
      "Last reward =  [-0.1212956]\n",
      "Reward buffer length =  59800\n",
      "Num timesteps: 59900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0707\n",
      "Last reward =  [0.00231306]\n",
      "Reward buffer length =  59900\n",
      "Num timesteps: 60000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0174\n",
      "Last reward =  [-0.02234817]\n",
      "Reward buffer length =  60000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 60100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0329\n",
      "Last reward =  [-0.07134517]\n",
      "Reward buffer length =  60100\n",
      "Num timesteps: 60200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0513\n",
      "Last reward =  [-0.04961219]\n",
      "Reward buffer length =  60200\n",
      "Num timesteps: 60300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0478\n",
      "Last reward =  [-0.13534984]\n",
      "Reward buffer length =  60300\n",
      "Num timesteps: 60400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0807\n",
      "Last reward =  [-0.07995305]\n",
      "Reward buffer length =  60400\n",
      "Num timesteps: 60500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0831\n",
      "Last reward =  [-0.09431646]\n",
      "Reward buffer length =  60500\n",
      "Num timesteps: 60600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1009\n",
      "Last reward =  [-0.0207921]\n",
      "Reward buffer length =  60600\n",
      "Num timesteps: 60700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0744\n",
      "Last reward =  [-0.1213965]\n",
      "Reward buffer length =  60700\n",
      "Num timesteps: 60800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0721\n",
      "Last reward =  [-0.130287]\n",
      "Reward buffer length =  60800\n",
      "Num timesteps: 60900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0849\n",
      "Last reward =  [-0.0743112]\n",
      "Reward buffer length =  60900\n",
      "Num timesteps: 61000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0872\n",
      "Last reward =  [-0.09369116]\n",
      "Reward buffer length =  61000\n",
      "Num timesteps: 61100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1046\n",
      "Last reward =  [-0.03031201]\n",
      "Reward buffer length =  61100\n",
      "Num timesteps: 61200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1026\n",
      "Last reward =  [-0.09432184]\n",
      "Reward buffer length =  61200\n",
      "Num timesteps: 61300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1023\n",
      "Last reward =  [-0.07217839]\n",
      "Reward buffer length =  61300\n",
      "Num timesteps: 61400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0842\n",
      "Last reward =  [0.02320122]\n",
      "Reward buffer length =  61400\n",
      "Num timesteps: 61500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1132\n",
      "Last reward =  [-0.16486894]\n",
      "Reward buffer length =  61500\n",
      "Num timesteps: 61600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0825\n",
      "Last reward =  [-0.09156647]\n",
      "Reward buffer length =  61600\n",
      "Num timesteps: 61700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0461\n",
      "Last reward =  [-0.06669701]\n",
      "Reward buffer length =  61700\n",
      "Num timesteps: 61800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0802\n",
      "Last reward =  [0.01934877]\n",
      "Reward buffer length =  61800\n",
      "Num timesteps: 61900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0848\n",
      "Last reward =  [-0.07994808]\n",
      "Reward buffer length =  61900\n",
      "Num timesteps: 62000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0919\n",
      "Last reward =  [-0.15276462]\n",
      "Reward buffer length =  62000\n",
      "Num timesteps: 62100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0866\n",
      "Last reward =  [-0.05046792]\n",
      "Reward buffer length =  62100\n",
      "Num timesteps: 62200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0787\n",
      "Last reward =  [-0.04908837]\n",
      "Reward buffer length =  62200\n",
      "Num timesteps: 62300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0863\n",
      "Last reward =  [-0.07107414]\n",
      "Reward buffer length =  62300\n",
      "Num timesteps: 62400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0968\n",
      "Last reward =  [-0.17912465]\n",
      "Reward buffer length =  62400\n",
      "Num timesteps: 62500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1160\n",
      "Last reward =  [-0.11549726]\n",
      "Reward buffer length =  62500\n",
      "Num timesteps: 62600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1123\n",
      "Last reward =  [0.01614558]\n",
      "Reward buffer length =  62600\n",
      "Num timesteps: 62700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0116\n",
      "Last reward =  [-0.03369865]\n",
      "Reward buffer length =  62700\n",
      "Num timesteps: 62800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0203\n",
      "Last reward =  [-0.03833348]\n",
      "Reward buffer length =  62800\n",
      "Num timesteps: 62900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0393\n",
      "Last reward =  [-0.0621732]\n",
      "Reward buffer length =  62900\n",
      "Num timesteps: 63000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0480\n",
      "Last reward =  [-0.01625705]\n",
      "Reward buffer length =  63000\n",
      "Num timesteps: 63100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0636\n",
      "Last reward =  [-0.07381535]\n",
      "Reward buffer length =  63100\n",
      "Num timesteps: 63200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0834\n",
      "Last reward =  [-0.08753502]\n",
      "Reward buffer length =  63200\n",
      "Num timesteps: 63300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0864\n",
      "Last reward =  [-0.07880362]\n",
      "Reward buffer length =  63300\n",
      "Num timesteps: 63400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1151\n",
      "Last reward =  [-0.12234177]\n",
      "Reward buffer length =  63400\n",
      "Num timesteps: 63500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0467\n",
      "Last reward =  [-0.04265644]\n",
      "Reward buffer length =  63500\n",
      "Num timesteps: 63600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0503\n",
      "Last reward =  [-0.05017665]\n",
      "Reward buffer length =  63600\n",
      "Num timesteps: 63700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0740\n",
      "Last reward =  [-0.12375142]\n",
      "Reward buffer length =  63700\n",
      "Num timesteps: 63800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0865\n",
      "Last reward =  [-0.09576521]\n",
      "Reward buffer length =  63800\n",
      "Num timesteps: 63900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0794\n",
      "Last reward =  [-0.14856611]\n",
      "Reward buffer length =  63900\n",
      "Num timesteps: 64000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0928\n",
      "Last reward =  [-0.04334733]\n",
      "Reward buffer length =  64000\n",
      "Num timesteps: 64100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0727\n",
      "Last reward =  [-0.15730011]\n",
      "Reward buffer length =  64100\n",
      "Num timesteps: 64200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0878\n",
      "Last reward =  [-0.05047324]\n",
      "Reward buffer length =  64200\n",
      "Num timesteps: 64300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0813\n",
      "Last reward =  [-0.10145454]\n",
      "Reward buffer length =  64300\n",
      "Num timesteps: 64400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1126\n",
      "Last reward =  [-0.01857276]\n",
      "Reward buffer length =  64400\n",
      "Num timesteps: 64500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: 0.0002\n",
      "Last reward =  [-0.02576496]\n",
      "Reward buffer length =  64500\n",
      "Num timesteps: 64600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0173\n",
      "Last reward =  [-0.00790627]\n",
      "Reward buffer length =  64600\n",
      "Num timesteps: 64700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0263\n",
      "Last reward =  [-0.0215814]\n",
      "Reward buffer length =  64700\n",
      "Num timesteps: 64800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0500\n",
      "Last reward =  [-0.05918358]\n",
      "Reward buffer length =  64800\n",
      "Num timesteps: 64900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0537\n",
      "Last reward =  [0.04059405]\n",
      "Reward buffer length =  64900\n",
      "Num timesteps: 65000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0823\n",
      "Last reward =  [-0.06363177]\n",
      "Reward buffer length =  65000\n",
      "Num timesteps: 65100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0879\n",
      "Last reward =  [-0.02195111]\n",
      "Reward buffer length =  65100\n",
      "Num timesteps: 65200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0915\n",
      "Last reward =  [-0.06919353]\n",
      "Reward buffer length =  65200\n",
      "Num timesteps: 65300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0942\n",
      "Last reward =  [-0.03145489]\n",
      "Reward buffer length =  65300\n",
      "Num timesteps: 65400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0378\n",
      "Last reward =  [-0.06758798]\n",
      "Reward buffer length =  65400\n",
      "Num timesteps: 65500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0553\n",
      "Last reward =  [0.0686995]\n",
      "Reward buffer length =  65500\n",
      "Num timesteps: 65600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0658\n",
      "Last reward =  [-0.0118488]\n",
      "Reward buffer length =  65600\n",
      "Num timesteps: 65700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0881\n",
      "Last reward =  [-0.11562409]\n",
      "Reward buffer length =  65700\n",
      "Num timesteps: 65800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0927\n",
      "Last reward =  [-0.19613236]\n",
      "Reward buffer length =  65800\n",
      "Num timesteps: 65900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1122\n",
      "Last reward =  [-0.10461025]\n",
      "Reward buffer length =  65900\n",
      "Num timesteps: 66000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0350\n",
      "Last reward =  [-0.02446837]\n",
      "Reward buffer length =  66000\n",
      "Num timesteps: 66100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0261\n",
      "Last reward =  [-0.0032935]\n",
      "Reward buffer length =  66100\n",
      "Num timesteps: 66200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0497\n",
      "Last reward =  [-0.03848096]\n",
      "Reward buffer length =  66200\n",
      "Num timesteps: 66300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0532\n",
      "Last reward =  [-0.16526319]\n",
      "Reward buffer length =  66300\n",
      "Num timesteps: 66400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0839\n",
      "Last reward =  [-0.05795118]\n",
      "Reward buffer length =  66400\n",
      "Num timesteps: 66500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0928\n",
      "Last reward =  [-0.01291959]\n",
      "Reward buffer length =  66500\n",
      "Num timesteps: 66600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0886\n",
      "Last reward =  [-0.08703685]\n",
      "Reward buffer length =  66600\n",
      "Num timesteps: 66700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1142\n",
      "Last reward =  [-0.07048636]\n",
      "Reward buffer length =  66700\n",
      "Num timesteps: 66800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0959\n",
      "Last reward =  [-0.07696142]\n",
      "Reward buffer length =  66800\n",
      "Num timesteps: 66900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0873\n",
      "Last reward =  [-0.11944098]\n",
      "Reward buffer length =  66900\n",
      "Num timesteps: 67000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1123\n",
      "Last reward =  [-0.04875541]\n",
      "Reward buffer length =  67000\n",
      "Num timesteps: 67100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0921\n",
      "Last reward =  [-0.20937239]\n",
      "Reward buffer length =  67100\n",
      "Num timesteps: 67200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0882\n",
      "Last reward =  [-0.1066094]\n",
      "Reward buffer length =  67200\n",
      "Num timesteps: 67300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1047\n",
      "Last reward =  [-0.08503613]\n",
      "Reward buffer length =  67300\n",
      "Num timesteps: 67400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0922\n",
      "Last reward =  [-0.11488165]\n",
      "Reward buffer length =  67400\n",
      "Num timesteps: 67500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1085\n",
      "Last reward =  [-0.10160974]\n",
      "Reward buffer length =  67500\n",
      "Num timesteps: 67600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0360\n",
      "Last reward =  [-0.03546518]\n",
      "Reward buffer length =  67600\n",
      "Num timesteps: 67700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0440\n",
      "Last reward =  [-0.04869045]\n",
      "Reward buffer length =  67700\n",
      "Num timesteps: 67800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0516\n",
      "Last reward =  [-0.07674526]\n",
      "Reward buffer length =  67800\n",
      "Num timesteps: 67900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0723\n",
      "Last reward =  [-0.0973857]\n",
      "Reward buffer length =  67900\n",
      "Num timesteps: 68000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0877\n",
      "Last reward =  [-0.04224747]\n",
      "Reward buffer length =  68000\n",
      "Num timesteps: 68100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0918\n",
      "Last reward =  [-0.0015539]\n",
      "Reward buffer length =  68100\n",
      "Num timesteps: 68200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1131\n",
      "Last reward =  [-0.13045506]\n",
      "Reward buffer length =  68200\n",
      "Num timesteps: 68300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0923\n",
      "Last reward =  [-0.15660737]\n",
      "Reward buffer length =  68300\n",
      "Num timesteps: 68400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1120\n",
      "Last reward =  [-0.1085071]\n",
      "Reward buffer length =  68400\n",
      "Num timesteps: 68500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0964\n",
      "Last reward =  [-0.09312811]\n",
      "Reward buffer length =  68500\n",
      "Num timesteps: 68600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0895\n",
      "Last reward =  [-0.05818927]\n",
      "Reward buffer length =  68600\n",
      "Num timesteps: 68700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1153\n",
      "Last reward =  [-0.1814428]\n",
      "Reward buffer length =  68700\n",
      "Num timesteps: 68800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0578\n",
      "Last reward =  [-0.03376875]\n",
      "Reward buffer length =  68800\n",
      "Num timesteps: 68900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0245\n",
      "Last reward =  [-0.00070956]\n",
      "Reward buffer length =  68900\n",
      "Num timesteps: 69000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0479\n",
      "Last reward =  [-0.03521805]\n",
      "Reward buffer length =  69000\n",
      "Num timesteps: 69100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0520\n",
      "Last reward =  [0.00060778]\n",
      "Reward buffer length =  69100\n",
      "Num timesteps: 69200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0762\n",
      "Last reward =  [-0.08178082]\n",
      "Reward buffer length =  69200\n",
      "Num timesteps: 69300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0942\n",
      "Last reward =  [-0.06364039]\n",
      "Reward buffer length =  69300\n",
      "Num timesteps: 69400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0930\n",
      "Last reward =  [-0.05715708]\n",
      "Reward buffer length =  69400\n",
      "Num timesteps: 69500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1170\n",
      "Last reward =  [-0.1896126]\n",
      "Reward buffer length =  69500\n",
      "Num timesteps: 69600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0915\n",
      "Last reward =  [-0.13048376]\n",
      "Reward buffer length =  69600\n",
      "Num timesteps: 69700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1095\n",
      "Last reward =  [-0.09923375]\n",
      "Reward buffer length =  69700\n",
      "Num timesteps: 69800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1136\n",
      "Last reward =  [-0.21823283]\n",
      "Reward buffer length =  69800\n",
      "Num timesteps: 69900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0939\n",
      "Last reward =  [-0.07457791]\n",
      "Reward buffer length =  69900\n",
      "Num timesteps: 70000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0927\n",
      "Last reward =  [-0.1945737]\n",
      "Reward buffer length =  70000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 70100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0798\n",
      "Last reward =  [-0.0457982]\n",
      "Reward buffer length =  70100\n",
      "Num timesteps: 70200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0280\n",
      "Last reward =  [-0.04542518]\n",
      "Reward buffer length =  70200\n",
      "Num timesteps: 70300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0397\n",
      "Last reward =  [-0.08841748]\n",
      "Reward buffer length =  70300\n",
      "Num timesteps: 70400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0600\n",
      "Last reward =  [-0.07388071]\n",
      "Reward buffer length =  70400\n",
      "Num timesteps: 70500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0624\n",
      "Last reward =  [-0.09252875]\n",
      "Reward buffer length =  70500\n",
      "Num timesteps: 70600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0877\n",
      "Last reward =  [-0.03091624]\n",
      "Reward buffer length =  70600\n",
      "Num timesteps: 70700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0906\n",
      "Last reward =  [-0.06195558]\n",
      "Reward buffer length =  70700\n",
      "Num timesteps: 70800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1102\n",
      "Last reward =  [-0.22411242]\n",
      "Reward buffer length =  70800\n",
      "Num timesteps: 70900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1134\n",
      "Last reward =  [-0.07109798]\n",
      "Reward buffer length =  70900\n",
      "Num timesteps: 71000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0875\n",
      "Last reward =  [-0.17615618]\n",
      "Reward buffer length =  71000\n",
      "Num timesteps: 71100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1226\n",
      "Last reward =  [-0.05733876]\n",
      "Reward buffer length =  71100\n",
      "Num timesteps: 71200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0551\n",
      "Last reward =  [-0.05655214]\n",
      "Reward buffer length =  71200\n",
      "Num timesteps: 71300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0552\n",
      "Last reward =  [-0.13774134]\n",
      "Reward buffer length =  71300\n",
      "Num timesteps: 71400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0768\n",
      "Last reward =  [-0.14012125]\n",
      "Reward buffer length =  71400\n",
      "Num timesteps: 71500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0931\n",
      "Last reward =  [0.04547101]\n",
      "Reward buffer length =  71500\n",
      "Num timesteps: 71600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0861\n",
      "Last reward =  [-0.08037264]\n",
      "Reward buffer length =  71600\n",
      "Num timesteps: 71700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0909\n",
      "Last reward =  [-0.00323005]\n",
      "Reward buffer length =  71700\n",
      "Num timesteps: 71800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0318\n",
      "Last reward =  [-0.03342094]\n",
      "Reward buffer length =  71800\n",
      "Num timesteps: 71900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0561\n",
      "Last reward =  [-0.07740819]\n",
      "Reward buffer length =  71900\n",
      "Num timesteps: 72000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0576\n",
      "Last reward =  [0.03421732]\n",
      "Reward buffer length =  72000\n",
      "Num timesteps: 72100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0790\n",
      "Last reward =  [-0.04791113]\n",
      "Reward buffer length =  72100\n",
      "Num timesteps: 72200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0968\n",
      "Last reward =  [-0.02324328]\n",
      "Reward buffer length =  72200\n",
      "Num timesteps: 72300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0917\n",
      "Last reward =  [-0.08234396]\n",
      "Reward buffer length =  72300\n",
      "Num timesteps: 72400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0950\n",
      "Last reward =  [-0.0695754]\n",
      "Reward buffer length =  72400\n",
      "Num timesteps: 72500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0512\n",
      "Last reward =  [-0.09630904]\n",
      "Reward buffer length =  72500\n",
      "Num timesteps: 72600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0566\n",
      "Last reward =  [-0.01814626]\n",
      "Reward buffer length =  72600\n",
      "Num timesteps: 72700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0777\n",
      "Last reward =  [-0.09606538]\n",
      "Reward buffer length =  72700\n",
      "Num timesteps: 72800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0870\n",
      "Last reward =  [-0.14071406]\n",
      "Reward buffer length =  72800\n",
      "Num timesteps: 72900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0895\n",
      "Last reward =  [-0.09136178]\n",
      "Reward buffer length =  72900\n",
      "Num timesteps: 73000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1218\n",
      "Last reward =  [-0.20716915]\n",
      "Reward buffer length =  73000\n",
      "Num timesteps: 73100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0292\n",
      "Last reward =  [-0.04054055]\n",
      "Reward buffer length =  73100\n",
      "Num timesteps: 73200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0445\n",
      "Last reward =  [-0.09012331]\n",
      "Reward buffer length =  73200\n",
      "Num timesteps: 73300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0628\n",
      "Last reward =  [0.02085426]\n",
      "Reward buffer length =  73300\n",
      "Num timesteps: 73400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0671\n",
      "Last reward =  [-0.08357634]\n",
      "Reward buffer length =  73400\n",
      "Num timesteps: 73500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0824\n",
      "Last reward =  [-0.06310027]\n",
      "Reward buffer length =  73500\n",
      "Num timesteps: 73600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0939\n",
      "Last reward =  [-0.04017383]\n",
      "Reward buffer length =  73600\n",
      "Num timesteps: 73700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1149\n",
      "Last reward =  [-0.14756162]\n",
      "Reward buffer length =  73700\n",
      "Num timesteps: 73800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1031\n",
      "Last reward =  [-0.07708206]\n",
      "Reward buffer length =  73800\n",
      "Num timesteps: 73900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0879\n",
      "Last reward =  [-0.15184739]\n",
      "Reward buffer length =  73900\n",
      "Num timesteps: 74000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1228\n",
      "Last reward =  [-0.06167778]\n",
      "Reward buffer length =  74000\n",
      "Num timesteps: 74100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0830\n",
      "Last reward =  [-0.06662989]\n",
      "Reward buffer length =  74100\n",
      "Num timesteps: 74200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0975\n",
      "Last reward =  [-0.2319792]\n",
      "Reward buffer length =  74200\n",
      "Num timesteps: 74300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0947\n",
      "Last reward =  [-0.14227585]\n",
      "Reward buffer length =  74300\n",
      "Num timesteps: 74400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1021\n",
      "Last reward =  [-0.1265508]\n",
      "Reward buffer length =  74400\n",
      "Num timesteps: 74500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0813\n",
      "Last reward =  [0.0287647]\n",
      "Reward buffer length =  74500\n",
      "Num timesteps: 74600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1041\n",
      "Last reward =  [-0.0796644]\n",
      "Reward buffer length =  74600\n",
      "Num timesteps: 74700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0929\n",
      "Last reward =  [-0.10690347]\n",
      "Reward buffer length =  74700\n",
      "Num timesteps: 74800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0995\n",
      "Last reward =  [-0.04189468]\n",
      "Reward buffer length =  74800\n",
      "Num timesteps: 74900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0457\n",
      "Last reward =  [-0.06826332]\n",
      "Reward buffer length =  74900\n",
      "Num timesteps: 75000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0633\n",
      "Last reward =  [0.02182898]\n",
      "Reward buffer length =  75000\n",
      "Num timesteps: 75100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0707\n",
      "Last reward =  [-0.09056382]\n",
      "Reward buffer length =  75100\n",
      "Num timesteps: 75200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0882\n",
      "Last reward =  [-0.07339136]\n",
      "Reward buffer length =  75200\n",
      "Num timesteps: 75300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0931\n",
      "Last reward =  [-0.05489647]\n",
      "Reward buffer length =  75300\n",
      "Num timesteps: 75400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1131\n",
      "Last reward =  [-0.15246375]\n",
      "Reward buffer length =  75400\n",
      "Num timesteps: 75500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0712\n",
      "Last reward =  [-0.04370153]\n",
      "Reward buffer length =  75500\n",
      "Num timesteps: 75600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0854\n",
      "Last reward =  [-0.0711242]\n",
      "Reward buffer length =  75600\n",
      "Num timesteps: 75700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1032\n",
      "Last reward =  [0.00541994]\n",
      "Reward buffer length =  75700\n",
      "Num timesteps: 75800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0969\n",
      "Last reward =  [-0.20414908]\n",
      "Reward buffer length =  75800\n",
      "Num timesteps: 75900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0880\n",
      "Last reward =  [-0.02144684]\n",
      "Reward buffer length =  75900\n",
      "Num timesteps: 76000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0800\n",
      "Last reward =  [-0.02048226]\n",
      "Reward buffer length =  76000\n",
      "Num timesteps: 76100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0943\n",
      "Last reward =  [-0.11740626]\n",
      "Reward buffer length =  76100\n",
      "Num timesteps: 76200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0897\n",
      "Last reward =  [0.01335801]\n",
      "Reward buffer length =  76200\n",
      "Num timesteps: 76300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1193\n",
      "Last reward =  [-0.07409852]\n",
      "Reward buffer length =  76300\n",
      "Num timesteps: 76400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0620\n",
      "Last reward =  [0.06273304]\n",
      "Reward buffer length =  76400\n",
      "Num timesteps: 76500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0835\n",
      "Last reward =  [-0.08078661]\n",
      "Reward buffer length =  76500\n",
      "Num timesteps: 76600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0942\n",
      "Last reward =  [-0.02823568]\n",
      "Reward buffer length =  76600\n",
      "Num timesteps: 76700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0988\n",
      "Last reward =  [-0.08725355]\n",
      "Reward buffer length =  76700\n",
      "Num timesteps: 76800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1267\n",
      "Last reward =  [-0.01547554]\n",
      "Reward buffer length =  76800\n",
      "Num timesteps: 76900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0102\n",
      "Last reward =  [0.02040042]\n",
      "Reward buffer length =  76900\n",
      "Num timesteps: 77000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0221\n",
      "Last reward =  [-0.01360214]\n",
      "Reward buffer length =  77000\n",
      "Num timesteps: 77100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0368\n",
      "Last reward =  [-0.0954087]\n",
      "Reward buffer length =  77100\n",
      "Num timesteps: 77200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0599\n",
      "Last reward =  [-0.12294076]\n",
      "Reward buffer length =  77200\n",
      "Num timesteps: 77300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0647\n",
      "Last reward =  [0.01392486]\n",
      "Reward buffer length =  77300\n",
      "Num timesteps: 77400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0928\n",
      "Last reward =  [-0.04065802]\n",
      "Reward buffer length =  77400\n",
      "Num timesteps: 77500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0974\n",
      "Last reward =  [-0.178707]\n",
      "Reward buffer length =  77500\n",
      "Num timesteps: 77600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1019\n",
      "Last reward =  [-0.04241167]\n",
      "Reward buffer length =  77600\n",
      "Num timesteps: 77700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0991\n",
      "Last reward =  [-0.04003607]\n",
      "Reward buffer length =  77700\n",
      "Num timesteps: 77800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0462\n",
      "Last reward =  [-0.04312663]\n",
      "Reward buffer length =  77800\n",
      "Num timesteps: 77900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0660\n",
      "Last reward =  [-0.0169772]\n",
      "Reward buffer length =  77900\n",
      "Num timesteps: 78000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0757\n",
      "Last reward =  [0.0224211]\n",
      "Reward buffer length =  78000\n",
      "Num timesteps: 78100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0852\n",
      "Last reward =  [-0.05656331]\n",
      "Reward buffer length =  78100\n",
      "Num timesteps: 78200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0996\n",
      "Last reward =  [-0.1699418]\n",
      "Reward buffer length =  78200\n",
      "Num timesteps: 78300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1177\n",
      "Last reward =  [-0.18939704]\n",
      "Reward buffer length =  78300\n",
      "Num timesteps: 78400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1024\n",
      "Last reward =  [-0.1651688]\n",
      "Reward buffer length =  78400\n",
      "Num timesteps: 78500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0993\n",
      "Last reward =  [-0.05926536]\n",
      "Reward buffer length =  78500\n",
      "Num timesteps: 78600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1070\n",
      "Last reward =  [0.02825673]\n",
      "Reward buffer length =  78600\n",
      "Num timesteps: 78700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1204\n",
      "Last reward =  [-0.12664552]\n",
      "Reward buffer length =  78700\n",
      "Num timesteps: 78800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0968\n",
      "Last reward =  [-0.10325628]\n",
      "Reward buffer length =  78800\n",
      "Num timesteps: 78900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1043\n",
      "Last reward =  [-0.11809807]\n",
      "Reward buffer length =  78900\n",
      "Num timesteps: 79000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1281\n",
      "Last reward =  [0.00217752]\n",
      "Reward buffer length =  79000\n",
      "Num timesteps: 79100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0140\n",
      "Last reward =  [-0.02215463]\n",
      "Reward buffer length =  79100\n",
      "Num timesteps: 79200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0323\n",
      "Last reward =  [-0.0591796]\n",
      "Reward buffer length =  79200\n",
      "Num timesteps: 79300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0534\n",
      "Last reward =  [-0.06700969]\n",
      "Reward buffer length =  79300\n",
      "Num timesteps: 79400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0676\n",
      "Last reward =  [-0.07010256]\n",
      "Reward buffer length =  79400\n",
      "Num timesteps: 79500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0902\n",
      "Last reward =  [-0.1335841]\n",
      "Reward buffer length =  79500\n",
      "Num timesteps: 79600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0997\n",
      "Last reward =  [-0.13046947]\n",
      "Reward buffer length =  79600\n",
      "Num timesteps: 79700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1075\n",
      "Last reward =  [-0.13603659]\n",
      "Reward buffer length =  79700\n",
      "Num timesteps: 79800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1371\n",
      "Last reward =  [-0.15472257]\n",
      "Reward buffer length =  79800\n",
      "Num timesteps: 79900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1039\n",
      "Last reward =  [-0.14751126]\n",
      "Reward buffer length =  79900\n",
      "Num timesteps: 80000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1382\n",
      "Last reward =  [-0.09165107]\n",
      "Reward buffer length =  80000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 80100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1074\n",
      "Last reward =  [-0.25852147]\n",
      "Reward buffer length =  80100\n",
      "Num timesteps: 80200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1133\n",
      "Last reward =  [-0.22250193]\n",
      "Reward buffer length =  80200\n",
      "Num timesteps: 80300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1102\n",
      "Last reward =  [-0.05047636]\n",
      "Reward buffer length =  80300\n",
      "Num timesteps: 80400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0715\n",
      "Last reward =  [-0.03700074]\n",
      "Reward buffer length =  80400\n",
      "Num timesteps: 80500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0819\n",
      "Last reward =  [-0.17405602]\n",
      "Reward buffer length =  80500\n",
      "Num timesteps: 80600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1017\n",
      "Last reward =  [-0.09499671]\n",
      "Reward buffer length =  80600\n",
      "Num timesteps: 80700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1145\n",
      "Last reward =  [-0.11625117]\n",
      "Reward buffer length =  80700\n",
      "Num timesteps: 80800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1375\n",
      "Last reward =  [-0.18716627]\n",
      "Reward buffer length =  80800\n",
      "Num timesteps: 80900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0514\n",
      "Last reward =  [-0.04144285]\n",
      "Reward buffer length =  80900\n",
      "Num timesteps: 81000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0501\n",
      "Last reward =  [-0.08722985]\n",
      "Reward buffer length =  81000\n",
      "Num timesteps: 81100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0735\n",
      "Last reward =  [-0.08444794]\n",
      "Reward buffer length =  81100\n",
      "Num timesteps: 81200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0754\n",
      "Last reward =  [-0.1485021]\n",
      "Reward buffer length =  81200\n",
      "Num timesteps: 81300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0959\n",
      "Last reward =  [-0.04681271]\n",
      "Reward buffer length =  81300\n",
      "Num timesteps: 81400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1050\n",
      "Last reward =  [-0.06910791]\n",
      "Reward buffer length =  81400\n",
      "Num timesteps: 81500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1222\n",
      "Last reward =  [-0.12672564]\n",
      "Reward buffer length =  81500\n",
      "Num timesteps: 81600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0766\n",
      "Last reward =  [-0.05216457]\n",
      "Reward buffer length =  81600\n",
      "Num timesteps: 81700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0521\n",
      "Last reward =  [-0.13152786]\n",
      "Reward buffer length =  81700\n",
      "Num timesteps: 81800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0732\n",
      "Last reward =  [-0.04709434]\n",
      "Reward buffer length =  81800\n",
      "Num timesteps: 81900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0784\n",
      "Last reward =  [-0.17656043]\n",
      "Reward buffer length =  81900\n",
      "Num timesteps: 82000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1012\n",
      "Last reward =  [0.02940096]\n",
      "Reward buffer length =  82000\n",
      "Num timesteps: 82100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1135\n",
      "Last reward =  [-0.1746141]\n",
      "Reward buffer length =  82100\n",
      "Num timesteps: 82200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1266\n",
      "Last reward =  [-0.1419974]\n",
      "Reward buffer length =  82200\n",
      "Num timesteps: 82300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1147\n",
      "Last reward =  [-0.07700565]\n",
      "Reward buffer length =  82300\n",
      "Num timesteps: 82400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1157\n",
      "Last reward =  [-0.11251692]\n",
      "Reward buffer length =  82400\n",
      "Num timesteps: 82500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1312\n",
      "Last reward =  [-0.00090623]\n",
      "Reward buffer length =  82500\n",
      "Num timesteps: 82600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0933\n",
      "Last reward =  [-0.02677586]\n",
      "Reward buffer length =  82600\n",
      "Num timesteps: 82700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0993\n",
      "Last reward =  [-0.11938156]\n",
      "Reward buffer length =  82700\n",
      "Num timesteps: 82800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1124\n",
      "Last reward =  [-0.12403671]\n",
      "Reward buffer length =  82800\n",
      "Num timesteps: 82900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1111\n",
      "Last reward =  [-0.09691864]\n",
      "Reward buffer length =  82900\n",
      "Num timesteps: 83000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1468\n",
      "Last reward =  [-0.08782168]\n",
      "Reward buffer length =  83000\n",
      "Num timesteps: 83100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1123\n",
      "Last reward =  [-0.17357263]\n",
      "Reward buffer length =  83100\n",
      "Num timesteps: 83200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1148\n",
      "Last reward =  [-0.20908338]\n",
      "Reward buffer length =  83200\n",
      "Num timesteps: 83300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1162\n",
      "Last reward =  [-0.13021603]\n",
      "Reward buffer length =  83300\n",
      "Num timesteps: 83400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1519\n",
      "Last reward =  [-0.0118627]\n",
      "Reward buffer length =  83400\n",
      "Num timesteps: 83500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1315\n",
      "Last reward =  [-0.05878911]\n",
      "Reward buffer length =  83500\n",
      "Num timesteps: 83600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0473\n",
      "Last reward =  [-0.03344404]\n",
      "Reward buffer length =  83600\n",
      "Num timesteps: 83700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0734\n",
      "Last reward =  [-0.06613746]\n",
      "Reward buffer length =  83700\n",
      "Num timesteps: 83800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0759\n",
      "Last reward =  [-0.06625623]\n",
      "Reward buffer length =  83800\n",
      "Num timesteps: 83900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1126\n",
      "Last reward =  [-0.16319822]\n",
      "Reward buffer length =  83900\n",
      "Num timesteps: 84000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1218\n",
      "Last reward =  [-0.09424736]\n",
      "Reward buffer length =  84000\n",
      "Num timesteps: 84100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1271\n",
      "Last reward =  [-0.17504086]\n",
      "Reward buffer length =  84100\n",
      "Num timesteps: 84200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1314\n",
      "Last reward =  [-0.12130804]\n",
      "Reward buffer length =  84200\n",
      "Num timesteps: 84300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1209\n",
      "Last reward =  [-0.09703608]\n",
      "Reward buffer length =  84300\n",
      "Num timesteps: 84400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1353\n",
      "Last reward =  [-0.21494152]\n",
      "Reward buffer length =  84400\n",
      "Num timesteps: 84500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1310\n",
      "Last reward =  [-0.17636278]\n",
      "Reward buffer length =  84500\n",
      "Num timesteps: 84600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1223\n",
      "Last reward =  [-0.07690267]\n",
      "Reward buffer length =  84600\n",
      "Num timesteps: 84700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1522\n",
      "Last reward =  [-0.19034743]\n",
      "Reward buffer length =  84700\n",
      "Num timesteps: 84800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1072\n",
      "Last reward =  [-0.00826312]\n",
      "Reward buffer length =  84800\n",
      "Num timesteps: 84900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1251\n",
      "Last reward =  [-0.07901738]\n",
      "Reward buffer length =  84900\n",
      "Num timesteps: 85000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1178\n",
      "Last reward =  [-0.14583886]\n",
      "Reward buffer length =  85000\n",
      "Num timesteps: 85100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1260\n",
      "Last reward =  [-0.11020471]\n",
      "Reward buffer length =  85100\n",
      "Num timesteps: 85200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1052\n",
      "Last reward =  [-0.14136128]\n",
      "Reward buffer length =  85200\n",
      "Num timesteps: 85300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1189\n",
      "Last reward =  [-0.22322671]\n",
      "Reward buffer length =  85300\n",
      "Num timesteps: 85400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1223\n",
      "Last reward =  [-0.22531663]\n",
      "Reward buffer length =  85400\n",
      "Num timesteps: 85500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1423\n",
      "Last reward =  [-0.12982303]\n",
      "Reward buffer length =  85500\n",
      "Num timesteps: 85600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1335\n",
      "Last reward =  [-0.13537154]\n",
      "Reward buffer length =  85600\n",
      "Num timesteps: 85700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1487\n",
      "Last reward =  [-0.33490068]\n",
      "Reward buffer length =  85700\n",
      "Num timesteps: 85800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0813\n",
      "Last reward =  [-0.0248326]\n",
      "Reward buffer length =  85800\n",
      "Num timesteps: 85900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0677\n",
      "Last reward =  [-0.07286768]\n",
      "Reward buffer length =  85900\n",
      "Num timesteps: 86000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0695\n",
      "Last reward =  [-0.2431896]\n",
      "Reward buffer length =  86000\n",
      "Num timesteps: 86100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1148\n",
      "Last reward =  [-0.1407235]\n",
      "Reward buffer length =  86100\n",
      "Num timesteps: 86200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1264\n",
      "Last reward =  [-0.08748196]\n",
      "Reward buffer length =  86200\n",
      "Num timesteps: 86300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1280\n",
      "Last reward =  [-0.12884283]\n",
      "Reward buffer length =  86300\n",
      "Num timesteps: 86400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1676\n",
      "Last reward =  [-0.143938]\n",
      "Reward buffer length =  86400\n",
      "Num timesteps: 86500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0754\n",
      "Last reward =  [-0.05091761]\n",
      "Reward buffer length =  86500\n",
      "Num timesteps: 86600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0989\n",
      "Last reward =  [-0.10036399]\n",
      "Reward buffer length =  86600\n",
      "Num timesteps: 86700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1177\n",
      "Last reward =  [-0.17184496]\n",
      "Reward buffer length =  86700\n",
      "Num timesteps: 86800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1366\n",
      "Last reward =  [-0.14537804]\n",
      "Reward buffer length =  86800\n",
      "Num timesteps: 86900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1538\n",
      "Last reward =  [-0.06252827]\n",
      "Reward buffer length =  86900\n",
      "Num timesteps: 87000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1360\n",
      "Last reward =  [-0.10589405]\n",
      "Reward buffer length =  87000\n",
      "Num timesteps: 87100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1301\n",
      "Last reward =  [-0.27706882]\n",
      "Reward buffer length =  87100\n",
      "Num timesteps: 87200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1441\n",
      "Last reward =  [-0.10991862]\n",
      "Reward buffer length =  87200\n",
      "Num timesteps: 87300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1085\n",
      "Last reward =  [-0.13911754]\n",
      "Reward buffer length =  87300\n",
      "Num timesteps: 87400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1386\n",
      "Last reward =  [-0.14486204]\n",
      "Reward buffer length =  87400\n",
      "Num timesteps: 87500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1520\n",
      "Last reward =  [-0.33525687]\n",
      "Reward buffer length =  87500\n",
      "Num timesteps: 87600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0796\n",
      "Last reward =  [-0.03930631]\n",
      "Reward buffer length =  87600\n",
      "Num timesteps: 87700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0578\n",
      "Last reward =  [-0.04989826]\n",
      "Reward buffer length =  87700\n",
      "Num timesteps: 87800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0727\n",
      "Last reward =  [-0.14624692]\n",
      "Reward buffer length =  87800\n",
      "Num timesteps: 87900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0901\n",
      "Last reward =  [-0.13249871]\n",
      "Reward buffer length =  87900\n",
      "Num timesteps: 88000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1070\n",
      "Last reward =  [-0.15253812]\n",
      "Reward buffer length =  88000\n",
      "Num timesteps: 88100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1341\n",
      "Last reward =  [-0.19154948]\n",
      "Reward buffer length =  88100\n",
      "Num timesteps: 88200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1467\n",
      "Last reward =  [-0.00073806]\n",
      "Reward buffer length =  88200\n",
      "Num timesteps: 88300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1291\n",
      "Last reward =  [-0.12118272]\n",
      "Reward buffer length =  88300\n",
      "Num timesteps: 88400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1239\n",
      "Last reward =  [-0.14476812]\n",
      "Reward buffer length =  88400\n",
      "Num timesteps: 88500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1237\n",
      "Last reward =  [-0.16767752]\n",
      "Reward buffer length =  88500\n",
      "Num timesteps: 88600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1323\n",
      "Last reward =  [-0.08507496]\n",
      "Reward buffer length =  88600\n",
      "Num timesteps: 88700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1023\n",
      "Last reward =  [-0.12024015]\n",
      "Reward buffer length =  88700\n",
      "Num timesteps: 88800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1187\n",
      "Last reward =  [-0.17195025]\n",
      "Reward buffer length =  88800\n",
      "Num timesteps: 88900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1311\n",
      "Last reward =  [-0.11124741]\n",
      "Reward buffer length =  88900\n",
      "Num timesteps: 89000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1496\n",
      "Last reward =  [-0.18443494]\n",
      "Reward buffer length =  89000\n",
      "Num timesteps: 89100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1606\n",
      "Last reward =  [-0.24113318]\n",
      "Reward buffer length =  89100\n",
      "Num timesteps: 89200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1356\n",
      "Last reward =  [-0.2856992]\n",
      "Reward buffer length =  89200\n",
      "Num timesteps: 89300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1493\n",
      "Last reward =  [-0.18884021]\n",
      "Reward buffer length =  89300\n",
      "Num timesteps: 89400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1852\n",
      "Last reward =  [-0.21009007]\n",
      "Reward buffer length =  89400\n",
      "Num timesteps: 89500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1342\n",
      "Last reward =  [-0.01328669]\n",
      "Reward buffer length =  89500\n",
      "Num timesteps: 89600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1340\n",
      "Last reward =  [-0.0221054]\n",
      "Reward buffer length =  89600\n",
      "Num timesteps: 89700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1800\n",
      "Last reward =  [-0.23829892]\n",
      "Reward buffer length =  89700\n",
      "Num timesteps: 89800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1627\n",
      "Last reward =  [0.05352164]\n",
      "Reward buffer length =  89800\n",
      "Num timesteps: 89900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1681\n",
      "Last reward =  [-0.07740095]\n",
      "Reward buffer length =  89900\n",
      "Num timesteps: 90000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1175\n",
      "Last reward =  [-0.19765234]\n",
      "Reward buffer length =  90000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 90100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1354\n",
      "Last reward =  [-0.03790089]\n",
      "Reward buffer length =  90100\n",
      "Num timesteps: 90200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1610\n",
      "Last reward =  [-0.2130272]\n",
      "Reward buffer length =  90200\n",
      "Num timesteps: 90300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0769\n",
      "Last reward =  [-0.0756207]\n",
      "Reward buffer length =  90300\n",
      "Num timesteps: 90400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0653\n",
      "Last reward =  [-0.1769182]\n",
      "Reward buffer length =  90400\n",
      "Num timesteps: 90500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0997\n",
      "Last reward =  [-0.18940441]\n",
      "Reward buffer length =  90500\n",
      "Num timesteps: 90600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1145\n",
      "Last reward =  [-0.15555069]\n",
      "Reward buffer length =  90600\n",
      "Num timesteps: 90700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1217\n",
      "Last reward =  [-0.16806014]\n",
      "Reward buffer length =  90700\n",
      "Num timesteps: 90800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1467\n",
      "Last reward =  [-0.10137399]\n",
      "Reward buffer length =  90800\n",
      "Num timesteps: 90900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1123\n",
      "Last reward =  [-0.04885984]\n",
      "Reward buffer length =  90900\n",
      "Num timesteps: 91000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1419\n",
      "Last reward =  [-0.14624216]\n",
      "Reward buffer length =  91000\n",
      "Num timesteps: 91100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1578\n",
      "Last reward =  [-0.11564838]\n",
      "Reward buffer length =  91100\n",
      "Num timesteps: 91200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1247\n",
      "Last reward =  [-0.2371415]\n",
      "Reward buffer length =  91200\n",
      "Num timesteps: 91300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1394\n",
      "Last reward =  [-0.09346301]\n",
      "Reward buffer length =  91300\n",
      "Num timesteps: 91400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1578\n",
      "Last reward =  [-0.15722814]\n",
      "Reward buffer length =  91400\n",
      "Num timesteps: 91500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1201\n",
      "Last reward =  [-0.17776297]\n",
      "Reward buffer length =  91500\n",
      "Num timesteps: 91600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1178\n",
      "Last reward =  [-0.1328106]\n",
      "Reward buffer length =  91600\n",
      "Num timesteps: 91700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1367\n",
      "Last reward =  [-0.10659692]\n",
      "Reward buffer length =  91700\n",
      "Num timesteps: 91800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1586\n",
      "Last reward =  [-0.01890932]\n",
      "Reward buffer length =  91800\n",
      "Num timesteps: 91900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0713\n",
      "Last reward =  [0.06378137]\n",
      "Reward buffer length =  91900\n",
      "Num timesteps: 92000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0866\n",
      "Last reward =  [-0.05398766]\n",
      "Reward buffer length =  92000\n",
      "Num timesteps: 92100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1082\n",
      "Last reward =  [-0.06567832]\n",
      "Reward buffer length =  92100\n",
      "Num timesteps: 92200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1410\n",
      "Last reward =  [-0.15405022]\n",
      "Reward buffer length =  92200\n",
      "Num timesteps: 92300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1519\n",
      "Last reward =  [-0.25503525]\n",
      "Reward buffer length =  92300\n",
      "Num timesteps: 92400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1029\n",
      "Last reward =  [-0.08490562]\n",
      "Reward buffer length =  92400\n",
      "Num timesteps: 92500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1085\n",
      "Last reward =  [-0.01046163]\n",
      "Reward buffer length =  92500\n",
      "Num timesteps: 92600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1382\n",
      "Last reward =  [-0.14354353]\n",
      "Reward buffer length =  92600\n",
      "Num timesteps: 92700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1353\n",
      "Last reward =  [-0.23816669]\n",
      "Reward buffer length =  92700\n",
      "Num timesteps: 92800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1272\n",
      "Last reward =  [-0.01918239]\n",
      "Reward buffer length =  92800\n",
      "Num timesteps: 92900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0278\n",
      "Last reward =  [-0.07388988]\n",
      "Reward buffer length =  92900\n",
      "Num timesteps: 93000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0471\n",
      "Last reward =  [-0.04827347]\n",
      "Reward buffer length =  93000\n",
      "Num timesteps: 93100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0739\n",
      "Last reward =  [-0.12452899]\n",
      "Reward buffer length =  93100\n",
      "Num timesteps: 93200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0743\n",
      "Last reward =  [-0.05132824]\n",
      "Reward buffer length =  93200\n",
      "Num timesteps: 93300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1218\n",
      "Last reward =  [-0.07885762]\n",
      "Reward buffer length =  93300\n",
      "Num timesteps: 93400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1405\n",
      "Last reward =  [-0.11237808]\n",
      "Reward buffer length =  93400\n",
      "Num timesteps: 93500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1416\n",
      "Last reward =  [-0.18738584]\n",
      "Reward buffer length =  93500\n",
      "Num timesteps: 93600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1239\n",
      "Last reward =  [-0.06154153]\n",
      "Reward buffer length =  93600\n",
      "Num timesteps: 93700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0570\n",
      "Last reward =  [-0.11349764]\n",
      "Reward buffer length =  93700\n",
      "Num timesteps: 93800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0775\n",
      "Last reward =  [-0.04053711]\n",
      "Reward buffer length =  93800\n",
      "Num timesteps: 93900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0829\n",
      "Last reward =  [-0.20589115]\n",
      "Reward buffer length =  93900\n",
      "Num timesteps: 94000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1103\n",
      "Last reward =  [-0.01215076]\n",
      "Reward buffer length =  94000\n",
      "Num timesteps: 94100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1391\n",
      "Last reward =  [-0.1124908]\n",
      "Reward buffer length =  94100\n",
      "Num timesteps: 94200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1524\n",
      "Last reward =  [-0.1208434]\n",
      "Reward buffer length =  94200\n",
      "Num timesteps: 94300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1101\n",
      "Last reward =  [-0.12381048]\n",
      "Reward buffer length =  94300\n",
      "Num timesteps: 94400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0737\n",
      "Last reward =  [-0.08375177]\n",
      "Reward buffer length =  94400\n",
      "Num timesteps: 94500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0713\n",
      "Last reward =  [-0.02735372]\n",
      "Reward buffer length =  94500\n",
      "Num timesteps: 94600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1013\n",
      "Last reward =  [-0.03349562]\n",
      "Reward buffer length =  94600\n",
      "Num timesteps: 94700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1348\n",
      "Last reward =  [-0.24940206]\n",
      "Reward buffer length =  94700\n",
      "Num timesteps: 94800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1372\n",
      "Last reward =  [-0.18183024]\n",
      "Reward buffer length =  94800\n",
      "Num timesteps: 94900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1487\n",
      "Last reward =  [-0.08349666]\n",
      "Reward buffer length =  94900\n",
      "Num timesteps: 95000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0727\n",
      "Last reward =  [-0.06271216]\n",
      "Reward buffer length =  95000\n",
      "Num timesteps: 95100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1109\n",
      "Last reward =  [-0.21976008]\n",
      "Reward buffer length =  95100\n",
      "Num timesteps: 95200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1272\n",
      "Last reward =  [-0.16921978]\n",
      "Reward buffer length =  95200\n",
      "Num timesteps: 95300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1361\n",
      "Last reward =  [-0.11714682]\n",
      "Reward buffer length =  95300\n",
      "Num timesteps: 95400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1312\n",
      "Last reward =  [-0.08868269]\n",
      "Reward buffer length =  95400\n",
      "Num timesteps: 95500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0802\n",
      "Last reward =  [-0.04600342]\n",
      "Reward buffer length =  95500\n",
      "Num timesteps: 95600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1057\n",
      "Last reward =  [-0.19718401]\n",
      "Reward buffer length =  95600\n",
      "Num timesteps: 95700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1350\n",
      "Last reward =  [-0.21179962]\n",
      "Reward buffer length =  95700\n",
      "Num timesteps: 95800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1712\n",
      "Last reward =  [-0.34257638]\n",
      "Reward buffer length =  95800\n",
      "Num timesteps: 95900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0723\n",
      "Last reward =  [-0.07916267]\n",
      "Reward buffer length =  95900\n",
      "Num timesteps: 96000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0698\n",
      "Last reward =  [-0.00960189]\n",
      "Reward buffer length =  96000\n",
      "Num timesteps: 96100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0700\n",
      "Last reward =  [-0.00151678]\n",
      "Reward buffer length =  96100\n",
      "Num timesteps: 96200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0980\n",
      "Last reward =  [-0.04063129]\n",
      "Reward buffer length =  96200\n",
      "Num timesteps: 96300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1117\n",
      "Last reward =  [-0.10793485]\n",
      "Reward buffer length =  96300\n",
      "Num timesteps: 96400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1421\n",
      "Last reward =  [-0.19864742]\n",
      "Reward buffer length =  96400\n",
      "Num timesteps: 96500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1719\n",
      "Last reward =  [-0.03333797]\n",
      "Reward buffer length =  96500\n",
      "Num timesteps: 96600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.02385365]\n",
      "Reward buffer length =  96600\n",
      "Num timesteps: 96700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0473\n",
      "Last reward =  [-0.02489616]\n",
      "Reward buffer length =  96700\n",
      "Num timesteps: 96800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0725\n",
      "Last reward =  [-0.00868499]\n",
      "Reward buffer length =  96800\n",
      "Num timesteps: 96900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0701\n",
      "Last reward =  [-0.20274925]\n",
      "Reward buffer length =  96900\n",
      "Num timesteps: 97000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1016\n",
      "Last reward =  [-0.01121179]\n",
      "Reward buffer length =  97000\n",
      "Num timesteps: 97100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1005\n",
      "Last reward =  [-0.2777772]\n",
      "Reward buffer length =  97100\n",
      "Num timesteps: 97200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1284\n",
      "Last reward =  [-0.10741702]\n",
      "Reward buffer length =  97200\n",
      "Num timesteps: 97300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1593\n",
      "Last reward =  [-0.11619899]\n",
      "Reward buffer length =  97300\n",
      "Num timesteps: 97400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0782\n",
      "Last reward =  [-0.10664622]\n",
      "Reward buffer length =  97400\n",
      "Num timesteps: 97500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0800\n",
      "Last reward =  [-0.13946551]\n",
      "Reward buffer length =  97500\n",
      "Num timesteps: 97600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1141\n",
      "Last reward =  [-0.18772598]\n",
      "Reward buffer length =  97600\n",
      "Num timesteps: 97700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1181\n",
      "Last reward =  [-0.06670947]\n",
      "Reward buffer length =  97700\n",
      "Num timesteps: 97800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1450\n",
      "Last reward =  [-0.07547458]\n",
      "Reward buffer length =  97800\n",
      "Num timesteps: 97900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1416\n",
      "Last reward =  [-0.12417464]\n",
      "Reward buffer length =  97900\n",
      "Num timesteps: 98000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0797\n",
      "Last reward =  [0.03594553]\n",
      "Reward buffer length =  98000\n",
      "Num timesteps: 98100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1089\n",
      "Last reward =  [-0.01036016]\n",
      "Reward buffer length =  98100\n",
      "Num timesteps: 98200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1216\n",
      "Last reward =  [-0.03595575]\n",
      "Reward buffer length =  98200\n",
      "Num timesteps: 98300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1531\n",
      "Last reward =  [-0.1798022]\n",
      "Reward buffer length =  98300\n",
      "Num timesteps: 98400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1777\n",
      "Last reward =  [-0.20120737]\n",
      "Reward buffer length =  98400\n",
      "Num timesteps: 98500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1305\n",
      "Last reward =  [-0.09739622]\n",
      "Reward buffer length =  98500\n",
      "Num timesteps: 98600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0827\n",
      "Last reward =  [-0.0391693]\n",
      "Reward buffer length =  98600\n",
      "Num timesteps: 98700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0872\n",
      "Last reward =  [-0.16310525]\n",
      "Reward buffer length =  98700\n",
      "Num timesteps: 98800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1021\n",
      "Last reward =  [-0.03460751]\n",
      "Reward buffer length =  98800\n",
      "Num timesteps: 98900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1255\n",
      "Last reward =  [-0.20603165]\n",
      "Reward buffer length =  98900\n",
      "Num timesteps: 99000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1576\n",
      "Last reward =  [-0.2961816]\n",
      "Reward buffer length =  99000\n",
      "Num timesteps: 99100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.2006\n",
      "Last reward =  [-0.11690434]\n",
      "Reward buffer length =  99100\n",
      "Num timesteps: 99200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1160\n",
      "Last reward =  [-0.18204927]\n",
      "Reward buffer length =  99200\n",
      "Num timesteps: 99300\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1216\n",
      "Last reward =  [-0.11278829]\n",
      "Reward buffer length =  99300\n",
      "Num timesteps: 99400\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1520\n",
      "Last reward =  [-0.15479046]\n",
      "Reward buffer length =  99400\n",
      "Num timesteps: 99500\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1013\n",
      "Last reward =  [0.00430906]\n",
      "Reward buffer length =  99500\n",
      "Num timesteps: 99600\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0241\n",
      "Last reward =  [-0.01927107]\n",
      "Reward buffer length =  99600\n",
      "Num timesteps: 99700\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0494\n",
      "Last reward =  [-0.04391444]\n",
      "Reward buffer length =  99700\n",
      "Num timesteps: 99800\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0760\n",
      "Last reward =  [-0.09633884]\n",
      "Reward buffer length =  99800\n",
      "Num timesteps: 99900\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.0750\n",
      "Last reward =  [-0.18183316]\n",
      "Reward buffer length =  99900\n",
      "Num timesteps: 100000\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1130\n",
      "Last reward =  [0.01833443]\n",
      "Reward buffer length =  100000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-b7903b81\\online\\model.zip\n",
      "Num timesteps: 100100\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1037\n",
      "Last reward =  [-0.0049545]\n",
      "Reward buffer length =  100100\n",
      "Num timesteps: 100200\n",
      "Best mean reward: 0.0145, Best mean reward step: 17400 Last mean reward per episode: -0.1502\n",
      "Last reward =  [-0.17952466]\n",
      "Reward buffer length =  100200\n",
      "End training online model...\n",
      "row_count=4871, start_row=3870, start_date=2017-12-17T22:00:00.000000000, end_row=4870, end_date=2021-10-27T21:00:00.000000000\n",
      "Data shape:(7, 1000, 4)\n",
      "Instruments:['EURUSD', 'USDJPY', 'GBPUSD', 'AUDUSD', 'USDCAD', 'USDCHF', 'NZDUSD'], lookack:30, random_episode_start:True, cash:1000.0, max_slippage_percent:0.01, lot_size:Micro, leverage:20, pip_size:[0.0001, 0.01, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001], pip_spread:[2, 2, 2, 2, 2, 2, 2], compute_position:long_and_short, compute_indicators:all, compute_reward:['log_returns'], verbose:False\n",
      "Model name:fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\n",
      "Using cuda device\n",
      "Start training model...\n",
      "Logging to E:\\\\alpha-machine\\\\logs\\\\forex\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708_0\n",
      "Num timesteps: 100\n",
      "Best mean reward: -inf, Best mean reward step: 0 Last mean reward per episode: -0.0035\n",
      "Last reward =  [-0.05325885]\n",
      "Reward buffer length =  100\n",
      "Num timesteps: 200\n",
      "Best mean reward: -0.0035, Best mean reward step: 100 Last mean reward per episode: -0.0080\n",
      "Last reward =  [-0.03290277]\n",
      "Reward buffer length =  200\n",
      "Num timesteps: 300\n",
      "Best mean reward: -0.0035, Best mean reward step: 100 Last mean reward per episode: -0.0033\n",
      "Last reward =  [0.01751575]\n",
      "Reward buffer length =  300\n",
      "Num timesteps: 400\n",
      "Best mean reward: -0.0033, Best mean reward step: 300 Last mean reward per episode: 0.0008\n",
      "Last reward =  [0.08026528]\n",
      "Reward buffer length =  400\n",
      "Num timesteps: 500\n",
      "Best mean reward: 0.0008, Best mean reward step: 400 Last mean reward per episode: 0.0018\n",
      "Last reward =  [0.02126384]\n",
      "Reward buffer length =  500\n",
      "Num timesteps: 600\n",
      "Best mean reward: 0.0018, Best mean reward step: 500 Last mean reward per episode: 0.0009\n",
      "Last reward =  [-0.03483235]\n",
      "Reward buffer length =  600\n",
      "Num timesteps: 700\n",
      "Best mean reward: 0.0018, Best mean reward step: 500 Last mean reward per episode: -0.0022\n",
      "Last reward =  [-0.01183995]\n",
      "Reward buffer length =  700\n",
      "Num timesteps: 800\n",
      "Best mean reward: 0.0018, Best mean reward step: 500 Last mean reward per episode: -0.0029\n",
      "Last reward =  [-0.00559888]\n",
      "Reward buffer length =  800\n",
      "Num timesteps: 900\n",
      "Best mean reward: 0.0018, Best mean reward step: 500 Last mean reward per episode: 0.0001\n",
      "Last reward =  [0.0085013]\n",
      "Reward buffer length =  900\n",
      "Num timesteps: 1000\n",
      "Best mean reward: 0.0018, Best mean reward step: 500 Last mean reward per episode: 0.0028\n",
      "Last reward =  [0.00598451]\n",
      "Reward buffer length =  1000\n",
      "Num timesteps: 1100\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0012\n",
      "Last reward =  [-0.01888518]\n",
      "Reward buffer length =  1100\n",
      "Num timesteps: 1200\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: 0.0011\n",
      "Last reward =  [0.0441674]\n",
      "Reward buffer length =  1200\n",
      "Num timesteps: 1300\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0038\n",
      "Last reward =  [-0.00615087]\n",
      "Reward buffer length =  1300\n",
      "Num timesteps: 1400\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0035\n",
      "Last reward =  [-0.04629881]\n",
      "Reward buffer length =  1400\n",
      "Num timesteps: 1500\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0033\n",
      "Last reward =  [-0.03065707]\n",
      "Reward buffer length =  1500\n",
      "Num timesteps: 1600\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: 0.0002\n",
      "Last reward =  [0.00297203]\n",
      "Reward buffer length =  1600\n",
      "Num timesteps: 1700\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0025\n",
      "Last reward =  [-0.01836313]\n",
      "Reward buffer length =  1700\n",
      "Num timesteps: 1800\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0039\n",
      "Last reward =  [-0.01817191]\n",
      "Reward buffer length =  1800\n",
      "Num timesteps: 1900\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0003\n",
      "Last reward =  [0.01254828]\n",
      "Reward buffer length =  1900\n",
      "Num timesteps: 2000\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0044\n",
      "Last reward =  [0.00752558]\n",
      "Reward buffer length =  2000\n",
      "Num timesteps: 2100\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: 0.0002\n",
      "Last reward =  [-0.04094537]\n",
      "Reward buffer length =  2100\n",
      "Num timesteps: 2200\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: 0.0002\n",
      "Last reward =  [0.0014214]\n",
      "Reward buffer length =  2200\n",
      "Num timesteps: 2300\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0015\n",
      "Last reward =  [0.00738517]\n",
      "Reward buffer length =  2300\n",
      "Num timesteps: 2400\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: -0.0022\n",
      "Last reward =  [-0.01723749]\n",
      "Reward buffer length =  2400\n",
      "Num timesteps: 2500\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: 0.0007\n",
      "Last reward =  [-0.00475987]\n",
      "Reward buffer length =  2500\n",
      "Num timesteps: 2600\n",
      "Best mean reward: 0.0028, Best mean reward step: 1000 Last mean reward per episode: 0.0042\n",
      "Last reward =  [0.00828216]\n",
      "Reward buffer length =  2600\n",
      "Num timesteps: 2700\n",
      "Best mean reward: 0.0042, Best mean reward step: 2600 Last mean reward per episode: -0.0048\n",
      "Last reward =  [-0.02075717]\n",
      "Reward buffer length =  2700\n",
      "Num timesteps: 2800\n",
      "Best mean reward: 0.0042, Best mean reward step: 2600 Last mean reward per episode: -0.0031\n",
      "Last reward =  [-0.01679241]\n",
      "Reward buffer length =  2800\n",
      "Num timesteps: 2900\n",
      "Best mean reward: 0.0042, Best mean reward step: 2600 Last mean reward per episode: -0.0018\n",
      "Last reward =  [0.04045787]\n",
      "Reward buffer length =  2900\n",
      "Num timesteps: 3000\n",
      "Best mean reward: 0.0042, Best mean reward step: 2600 Last mean reward per episode: -0.0029\n",
      "Last reward =  [-0.01261513]\n",
      "Reward buffer length =  3000\n",
      "Num timesteps: 3100\n",
      "Best mean reward: 0.0042, Best mean reward step: 2600 Last mean reward per episode: 0.0003\n",
      "Last reward =  [0.00337938]\n",
      "Reward buffer length =  3100\n",
      "Num timesteps: 3200\n",
      "Best mean reward: 0.0042, Best mean reward step: 2600 Last mean reward per episode: 0.0024\n",
      "Last reward =  [0.00459874]\n",
      "Reward buffer length =  3200\n",
      "Num timesteps: 3300\n",
      "Best mean reward: 0.0042, Best mean reward step: 2600 Last mean reward per episode: 0.0130\n",
      "Last reward =  [0.01356589]\n",
      "Reward buffer length =  3300\n",
      "Num timesteps: 3400\n",
      "Best mean reward: 0.0130, Best mean reward step: 3300 Last mean reward per episode: -0.0036\n",
      "Last reward =  [0.00357134]\n",
      "Reward buffer length =  3400\n",
      "Num timesteps: 3500\n",
      "Best mean reward: 0.0130, Best mean reward step: 3300 Last mean reward per episode: -0.0001\n",
      "Last reward =  [-0.02791731]\n",
      "Reward buffer length =  3500\n",
      "Num timesteps: 3600\n",
      "Best mean reward: 0.0130, Best mean reward step: 3300 Last mean reward per episode: -0.0044\n",
      "Last reward =  [0.02359075]\n",
      "Reward buffer length =  3600\n",
      "Num timesteps: 3700\n",
      "Best mean reward: 0.0130, Best mean reward step: 3300 Last mean reward per episode: -0.0025\n",
      "Last reward =  [-0.02920653]\n",
      "Reward buffer length =  3700\n",
      "Num timesteps: 3800\n",
      "Best mean reward: 0.0130, Best mean reward step: 3300 Last mean reward per episode: 0.0021\n",
      "Last reward =  [0.02823687]\n",
      "Reward buffer length =  3800\n",
      "Num timesteps: 3900\n",
      "Best mean reward: 0.0130, Best mean reward step: 3300 Last mean reward per episode: 0.0023\n",
      "Last reward =  [0.00550495]\n",
      "Reward buffer length =  3900\n",
      "Num timesteps: 4000\n",
      "Best mean reward: 0.0130, Best mean reward step: 3300 Last mean reward per episode: 0.0153\n",
      "Last reward =  [-0.02668343]\n",
      "Reward buffer length =  4000\n",
      "Num timesteps: 4100\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0021\n",
      "Last reward =  [0.02533877]\n",
      "Reward buffer length =  4100\n",
      "Num timesteps: 4200\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0006\n",
      "Last reward =  [0.02412505]\n",
      "Reward buffer length =  4200\n",
      "Num timesteps: 4300\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0020\n",
      "Last reward =  [-0.01426497]\n",
      "Reward buffer length =  4300\n",
      "Num timesteps: 4400\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0006\n",
      "Last reward =  [0.00663829]\n",
      "Reward buffer length =  4400\n",
      "Num timesteps: 4500\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0006\n",
      "Last reward =  [-0.01300791]\n",
      "Reward buffer length =  4500\n",
      "Num timesteps: 4600\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0005\n",
      "Last reward =  [0.01656356]\n",
      "Reward buffer length =  4600\n",
      "Num timesteps: 4700\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0006\n",
      "Last reward =  [-0.00072732]\n",
      "Reward buffer length =  4700\n",
      "Num timesteps: 4800\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0021\n",
      "Last reward =  [0.01436198]\n",
      "Reward buffer length =  4800\n",
      "Num timesteps: 4900\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0003\n",
      "Last reward =  [0.04042432]\n",
      "Reward buffer length =  4900\n",
      "Num timesteps: 5000\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0029\n",
      "Last reward =  [-0.0225634]\n",
      "Reward buffer length =  5000\n",
      "Num timesteps: 5100\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0004\n",
      "Last reward =  [0.00339914]\n",
      "Reward buffer length =  5100\n",
      "Num timesteps: 5200\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0016\n",
      "Last reward =  [-0.04109122]\n",
      "Reward buffer length =  5200\n",
      "Num timesteps: 5300\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0013\n",
      "Last reward =  [-0.05425418]\n",
      "Reward buffer length =  5300\n",
      "Num timesteps: 5400\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0148\n",
      "Last reward =  [-0.02918371]\n",
      "Reward buffer length =  5400\n",
      "Num timesteps: 5500\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0011\n",
      "Last reward =  [0.00930233]\n",
      "Reward buffer length =  5500\n",
      "Num timesteps: 5600\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0002\n",
      "Last reward =  [-0.02456106]\n",
      "Reward buffer length =  5600\n",
      "Num timesteps: 5700\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0026\n",
      "Last reward =  [-0.03343266]\n",
      "Reward buffer length =  5700\n",
      "Num timesteps: 5800\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0009\n",
      "Last reward =  [-0.00610506]\n",
      "Reward buffer length =  5800\n",
      "Num timesteps: 5900\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: -0.0004\n",
      "Last reward =  [0.00539017]\n",
      "Reward buffer length =  5900\n",
      "Num timesteps: 6000\n",
      "Best mean reward: 0.0153, Best mean reward step: 4000 Last mean reward per episode: 0.0175\n",
      "Last reward =  [-0.03892264]\n",
      "Reward buffer length =  6000\n",
      "Num timesteps: 6100\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0077\n",
      "Last reward =  [0.01359326]\n",
      "Reward buffer length =  6100\n",
      "Num timesteps: 6200\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0044\n",
      "Last reward =  [0.01270952]\n",
      "Reward buffer length =  6200\n",
      "Num timesteps: 6300\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0009\n",
      "Last reward =  [0.00975664]\n",
      "Reward buffer length =  6300\n",
      "Num timesteps: 6400\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0013\n",
      "Last reward =  [0.00227222]\n",
      "Reward buffer length =  6400\n",
      "Num timesteps: 6500\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: -0.0003\n",
      "Last reward =  [-0.00603086]\n",
      "Reward buffer length =  6500\n",
      "Num timesteps: 6600\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0040\n",
      "Last reward =  [-0.00145643]\n",
      "Reward buffer length =  6600\n",
      "Num timesteps: 6700\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0032\n",
      "Last reward =  [0.01627627]\n",
      "Reward buffer length =  6700\n",
      "Num timesteps: 6800\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0167\n",
      "Last reward =  [0.01441344]\n",
      "Reward buffer length =  6800\n",
      "Num timesteps: 6900\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0063\n",
      "Last reward =  [-0.0203157]\n",
      "Reward buffer length =  6900\n",
      "Num timesteps: 7000\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0063\n",
      "Last reward =  [-0.01880893]\n",
      "Reward buffer length =  7000\n",
      "Num timesteps: 7100\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0058\n",
      "Last reward =  [0.04928919]\n",
      "Reward buffer length =  7100\n",
      "Num timesteps: 7200\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: -0.0014\n",
      "Last reward =  [0.01518738]\n",
      "Reward buffer length =  7200\n",
      "Num timesteps: 7300\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0038\n",
      "Last reward =  [0.01893212]\n",
      "Reward buffer length =  7300\n",
      "Num timesteps: 7400\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0014\n",
      "Last reward =  [-0.00235524]\n",
      "Reward buffer length =  7400\n",
      "Num timesteps: 7500\n",
      "Best mean reward: 0.0175, Best mean reward step: 6000 Last mean reward per episode: 0.0196\n",
      "Last reward =  [0.02465004]\n",
      "Reward buffer length =  7500\n",
      "Num timesteps: 7600\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0069\n",
      "Last reward =  [-0.01581213]\n",
      "Reward buffer length =  7600\n",
      "Num timesteps: 7700\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0037\n",
      "Last reward =  [-0.02848721]\n",
      "Reward buffer length =  7700\n",
      "Num timesteps: 7800\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0088\n",
      "Last reward =  [-0.0035617]\n",
      "Reward buffer length =  7800\n",
      "Num timesteps: 7900\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: -0.0029\n",
      "Last reward =  [0.03633101]\n",
      "Reward buffer length =  7900\n",
      "Num timesteps: 8000\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0044\n",
      "Last reward =  [-0.03101896]\n",
      "Reward buffer length =  8000\n",
      "Num timesteps: 8100\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0188\n",
      "Last reward =  [-0.04377558]\n",
      "Reward buffer length =  8100\n",
      "Num timesteps: 8200\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0072\n",
      "Last reward =  [-0.02940092]\n",
      "Reward buffer length =  8200\n",
      "Num timesteps: 8300\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0060\n",
      "Last reward =  [-0.00313221]\n",
      "Reward buffer length =  8300\n",
      "Num timesteps: 8400\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0084\n",
      "Last reward =  [0.04370074]\n",
      "Reward buffer length =  8400\n",
      "Num timesteps: 8500\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0104\n",
      "Last reward =  [0.01863548]\n",
      "Reward buffer length =  8500\n",
      "Num timesteps: 8600\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0065\n",
      "Last reward =  [0.00503454]\n",
      "Reward buffer length =  8600\n",
      "Num timesteps: 8700\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0081\n",
      "Last reward =  [0.0895501]\n",
      "Reward buffer length =  8700\n",
      "Num timesteps: 8800\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0062\n",
      "Last reward =  [0.14028184]\n",
      "Reward buffer length =  8800\n",
      "Num timesteps: 8900\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: -0.0000\n",
      "Last reward =  [-0.00148139]\n",
      "Reward buffer length =  8900\n",
      "Num timesteps: 9000\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0021\n",
      "Last reward =  [-0.01112079]\n",
      "Reward buffer length =  9000\n",
      "Num timesteps: 9100\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0022\n",
      "Last reward =  [0.0023626]\n",
      "Reward buffer length =  9100\n",
      "Num timesteps: 9200\n",
      "Best mean reward: 0.0196, Best mean reward step: 7500 Last mean reward per episode: 0.0206\n",
      "Last reward =  [0.1597077]\n",
      "Reward buffer length =  9200\n",
      "Num timesteps: 9300\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0057\n",
      "Last reward =  [0.02648012]\n",
      "Reward buffer length =  9300\n",
      "Num timesteps: 9400\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0019\n",
      "Last reward =  [-0.05474001]\n",
      "Reward buffer length =  9400\n",
      "Num timesteps: 9500\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0076\n",
      "Last reward =  [0.01174975]\n",
      "Reward buffer length =  9500\n",
      "Num timesteps: 9600\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0003\n",
      "Last reward =  [-0.01867346]\n",
      "Reward buffer length =  9600\n",
      "Num timesteps: 9700\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0028\n",
      "Last reward =  [-0.03217728]\n",
      "Reward buffer length =  9700\n",
      "Num timesteps: 9800\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0095\n",
      "Last reward =  [-0.01320601]\n",
      "Reward buffer length =  9800\n",
      "Num timesteps: 9900\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: -0.0006\n",
      "Last reward =  [0.0286256]\n",
      "Reward buffer length =  9900\n",
      "Num timesteps: 10000\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0041\n",
      "Last reward =  [0.06951062]\n",
      "Reward buffer length =  10000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 10100\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0029\n",
      "Last reward =  [-0.02535552]\n",
      "Reward buffer length =  10100\n",
      "Num timesteps: 10200\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0053\n",
      "Last reward =  [0.01716633]\n",
      "Reward buffer length =  10200\n",
      "Num timesteps: 10300\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: -0.0016\n",
      "Last reward =  [-0.00466417]\n",
      "Reward buffer length =  10300\n",
      "Num timesteps: 10400\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0054\n",
      "Last reward =  [0.03393237]\n",
      "Reward buffer length =  10400\n",
      "Num timesteps: 10500\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: -0.0016\n",
      "Last reward =  [-0.01722356]\n",
      "Reward buffer length =  10500\n",
      "Num timesteps: 10600\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0032\n",
      "Last reward =  [-0.00784268]\n",
      "Reward buffer length =  10600\n",
      "Num timesteps: 10700\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0042\n",
      "Last reward =  [-0.02278062]\n",
      "Reward buffer length =  10700\n",
      "Num timesteps: 10800\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0014\n",
      "Last reward =  [0.02201634]\n",
      "Reward buffer length =  10800\n",
      "Num timesteps: 10900\n",
      "Best mean reward: 0.0206, Best mean reward step: 9200 Last mean reward per episode: 0.0229\n",
      "Last reward =  [0.03530984]\n",
      "Reward buffer length =  10900\n",
      "Num timesteps: 11000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0051\n",
      "Last reward =  [-0.02295684]\n",
      "Reward buffer length =  11000\n",
      "Num timesteps: 11100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0014\n",
      "Last reward =  [0.07059214]\n",
      "Reward buffer length =  11100\n",
      "Num timesteps: 11200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0022\n",
      "Last reward =  [-0.01131987]\n",
      "Reward buffer length =  11200\n",
      "Num timesteps: 11300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0021\n",
      "Last reward =  [-0.02710746]\n",
      "Reward buffer length =  11300\n",
      "Num timesteps: 11400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0016\n",
      "Last reward =  [-0.03779187]\n",
      "Reward buffer length =  11400\n",
      "Num timesteps: 11500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0025\n",
      "Last reward =  [0.03119487]\n",
      "Reward buffer length =  11500\n",
      "Num timesteps: 11600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0029\n",
      "Last reward =  [-0.00495742]\n",
      "Reward buffer length =  11600\n",
      "Num timesteps: 11700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0024\n",
      "Last reward =  [0.00394989]\n",
      "Reward buffer length =  11700\n",
      "Num timesteps: 11800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0226\n",
      "Last reward =  [0.01063508]\n",
      "Reward buffer length =  11800\n",
      "Num timesteps: 11900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0009\n",
      "Last reward =  [-0.01443495]\n",
      "Reward buffer length =  11900\n",
      "Num timesteps: 12000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0014\n",
      "Last reward =  [-0.02314949]\n",
      "Reward buffer length =  12000\n",
      "Num timesteps: 12100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0024\n",
      "Last reward =  [-0.04891029]\n",
      "Reward buffer length =  12100\n",
      "Num timesteps: 12200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0010\n",
      "Last reward =  [0.03471379]\n",
      "Reward buffer length =  12200\n",
      "Num timesteps: 12300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0042\n",
      "Last reward =  [-0.0352802]\n",
      "Reward buffer length =  12300\n",
      "Num timesteps: 12400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0012\n",
      "Last reward =  [-0.10848092]\n",
      "Reward buffer length =  12400\n",
      "Num timesteps: 12500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0031\n",
      "Last reward =  [-0.01848424]\n",
      "Reward buffer length =  12500\n",
      "Num timesteps: 12600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0010\n",
      "Last reward =  [0.00615156]\n",
      "Reward buffer length =  12600\n",
      "Num timesteps: 12700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0164\n",
      "Last reward =  [0.10022861]\n",
      "Reward buffer length =  12700\n",
      "Num timesteps: 12800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0092\n",
      "Last reward =  [-0.02134434]\n",
      "Reward buffer length =  12800\n",
      "Num timesteps: 12900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0028\n",
      "Last reward =  [0.0212454]\n",
      "Reward buffer length =  12900\n",
      "Num timesteps: 13000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0003\n",
      "Last reward =  [-0.02654036]\n",
      "Reward buffer length =  13000\n",
      "Num timesteps: 13100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0013\n",
      "Last reward =  [-0.01787099]\n",
      "Reward buffer length =  13100\n",
      "Num timesteps: 13200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0022\n",
      "Last reward =  [0.0066702]\n",
      "Reward buffer length =  13200\n",
      "Num timesteps: 13300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0199\n",
      "Last reward =  [0.00196532]\n",
      "Reward buffer length =  13300\n",
      "Num timesteps: 13400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0034\n",
      "Last reward =  [0.00477964]\n",
      "Reward buffer length =  13400\n",
      "Num timesteps: 13500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0006\n",
      "Last reward =  [-0.01324668]\n",
      "Reward buffer length =  13500\n",
      "Num timesteps: 13600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0001\n",
      "Last reward =  [0.08840156]\n",
      "Reward buffer length =  13600\n",
      "Num timesteps: 13700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0064\n",
      "Last reward =  [-0.02763154]\n",
      "Reward buffer length =  13700\n",
      "Num timesteps: 13800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0018\n",
      "Last reward =  [0.0330207]\n",
      "Reward buffer length =  13800\n",
      "Num timesteps: 13900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0018\n",
      "Last reward =  [-0.03350469]\n",
      "Reward buffer length =  13900\n",
      "Num timesteps: 14000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0206\n",
      "Last reward =  [-0.07344867]\n",
      "Reward buffer length =  14000\n",
      "Num timesteps: 14100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0018\n",
      "Last reward =  [-0.01403045]\n",
      "Reward buffer length =  14100\n",
      "Num timesteps: 14200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0010\n",
      "Last reward =  [-0.00849249]\n",
      "Reward buffer length =  14200\n",
      "Num timesteps: 14300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0020\n",
      "Last reward =  [0.00930787]\n",
      "Reward buffer length =  14300\n",
      "Num timesteps: 14400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0038\n",
      "Last reward =  [-0.00334596]\n",
      "Reward buffer length =  14400\n",
      "Num timesteps: 14500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0028\n",
      "Last reward =  [0.0076394]\n",
      "Reward buffer length =  14500\n",
      "Num timesteps: 14600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0045\n",
      "Last reward =  [-0.0143872]\n",
      "Reward buffer length =  14600\n",
      "Num timesteps: 14700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0008\n",
      "Last reward =  [0.00521454]\n",
      "Reward buffer length =  14700\n",
      "Num timesteps: 14800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0036\n",
      "Last reward =  [0.00534542]\n",
      "Reward buffer length =  14800\n",
      "Num timesteps: 14900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0007\n",
      "Last reward =  [0.01572305]\n",
      "Reward buffer length =  14900\n",
      "Num timesteps: 15000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0019\n",
      "Last reward =  [0.00832868]\n",
      "Reward buffer length =  15000\n",
      "Num timesteps: 15100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0223\n",
      "Last reward =  [0.06692636]\n",
      "Reward buffer length =  15100\n",
      "Num timesteps: 15200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0004\n",
      "Last reward =  [0.00231482]\n",
      "Reward buffer length =  15200\n",
      "Num timesteps: 15300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0036\n",
      "Last reward =  [-0.00415307]\n",
      "Reward buffer length =  15300\n",
      "Num timesteps: 15400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0023\n",
      "Last reward =  [-0.00480479]\n",
      "Reward buffer length =  15400\n",
      "Num timesteps: 15500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0064\n",
      "Last reward =  [0.09080996]\n",
      "Reward buffer length =  15500\n",
      "Num timesteps: 15600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0004\n",
      "Last reward =  [-0.02567457]\n",
      "Reward buffer length =  15600\n",
      "Num timesteps: 15700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0001\n",
      "Last reward =  [0.02063637]\n",
      "Reward buffer length =  15700\n",
      "Num timesteps: 15800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0178\n",
      "Last reward =  [0.08869921]\n",
      "Reward buffer length =  15800\n",
      "Num timesteps: 15900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0033\n",
      "Last reward =  [0.00647168]\n",
      "Reward buffer length =  15900\n",
      "Num timesteps: 16000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0043\n",
      "Last reward =  [0.00906752]\n",
      "Reward buffer length =  16000\n",
      "Num timesteps: 16100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0044\n",
      "Last reward =  [-0.01877051]\n",
      "Reward buffer length =  16100\n",
      "Num timesteps: 16200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0067\n",
      "Last reward =  [-0.02818128]\n",
      "Reward buffer length =  16200\n",
      "Num timesteps: 16300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0022\n",
      "Last reward =  [0.036572]\n",
      "Reward buffer length =  16300\n",
      "Num timesteps: 16400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0023\n",
      "Last reward =  [-0.01724011]\n",
      "Reward buffer length =  16400\n",
      "Num timesteps: 16500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0021\n",
      "Last reward =  [0.00514281]\n",
      "Reward buffer length =  16500\n",
      "Num timesteps: 16600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0024\n",
      "Last reward =  [0.01540786]\n",
      "Reward buffer length =  16600\n",
      "Num timesteps: 16700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0186\n",
      "Last reward =  [-0.07299581]\n",
      "Reward buffer length =  16700\n",
      "Num timesteps: 16800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0008\n",
      "Last reward =  [0.02414213]\n",
      "Reward buffer length =  16800\n",
      "Num timesteps: 16900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0037\n",
      "Last reward =  [-0.00748572]\n",
      "Reward buffer length =  16900\n",
      "Num timesteps: 17000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0091\n",
      "Last reward =  [0.05359301]\n",
      "Reward buffer length =  17000\n",
      "Num timesteps: 17100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0127\n",
      "Last reward =  [0.02284262]\n",
      "Reward buffer length =  17100\n",
      "Num timesteps: 17200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0064\n",
      "Last reward =  [-0.00930062]\n",
      "Reward buffer length =  17200\n",
      "Num timesteps: 17300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0035\n",
      "Last reward =  [-0.01751172]\n",
      "Reward buffer length =  17300\n",
      "Num timesteps: 17400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0024\n",
      "Last reward =  [-0.02503047]\n",
      "Reward buffer length =  17400\n",
      "Num timesteps: 17500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0112\n",
      "Last reward =  [0.00257405]\n",
      "Reward buffer length =  17500\n",
      "Num timesteps: 17600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0103\n",
      "Last reward =  [0.00741603]\n",
      "Reward buffer length =  17600\n",
      "Num timesteps: 17700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0020\n",
      "Last reward =  [0.0074238]\n",
      "Reward buffer length =  17700\n",
      "Num timesteps: 17800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0164\n",
      "Last reward =  [-0.00444525]\n",
      "Reward buffer length =  17800\n",
      "Num timesteps: 17900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0059\n",
      "Last reward =  [-0.03260216]\n",
      "Reward buffer length =  17900\n",
      "Num timesteps: 18000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0017\n",
      "Last reward =  [-0.04459504]\n",
      "Reward buffer length =  18000\n",
      "Num timesteps: 18100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0095\n",
      "Last reward =  [-0.06254017]\n",
      "Reward buffer length =  18100\n",
      "Num timesteps: 18200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0116\n",
      "Last reward =  [0.00525542]\n",
      "Reward buffer length =  18200\n",
      "Num timesteps: 18300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0089\n",
      "Last reward =  [0.04079737]\n",
      "Reward buffer length =  18300\n",
      "Num timesteps: 18400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0161\n",
      "Last reward =  [-0.04995149]\n",
      "Reward buffer length =  18400\n",
      "Num timesteps: 18500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0143\n",
      "Last reward =  [-0.03417435]\n",
      "Reward buffer length =  18500\n",
      "Num timesteps: 18600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0194\n",
      "Last reward =  [-0.03241906]\n",
      "Reward buffer length =  18600\n",
      "Num timesteps: 18700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0038\n",
      "Last reward =  [0.03837109]\n",
      "Reward buffer length =  18700\n",
      "Num timesteps: 18800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0089\n",
      "Last reward =  [0.04608387]\n",
      "Reward buffer length =  18800\n",
      "Num timesteps: 18900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0099\n",
      "Last reward =  [-0.04373602]\n",
      "Reward buffer length =  18900\n",
      "Num timesteps: 19000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0163\n",
      "Last reward =  [-0.04926991]\n",
      "Reward buffer length =  19000\n",
      "Num timesteps: 19100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0185\n",
      "Last reward =  [-0.0504734]\n",
      "Reward buffer length =  19100\n",
      "Num timesteps: 19200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0203\n",
      "Last reward =  [0.0067015]\n",
      "Reward buffer length =  19200\n",
      "Num timesteps: 19300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0024\n",
      "Last reward =  [0.00484274]\n",
      "Reward buffer length =  19300\n",
      "Num timesteps: 19400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0019\n",
      "Last reward =  [0.04069692]\n",
      "Reward buffer length =  19400\n",
      "Num timesteps: 19500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0118\n",
      "Last reward =  [-0.02142427]\n",
      "Reward buffer length =  19500\n",
      "Num timesteps: 19600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0110\n",
      "Last reward =  [-0.02297974]\n",
      "Reward buffer length =  19600\n",
      "Num timesteps: 19700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0099\n",
      "Last reward =  [-0.07073273]\n",
      "Reward buffer length =  19700\n",
      "Num timesteps: 19800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0195\n",
      "Last reward =  [-0.03231652]\n",
      "Reward buffer length =  19800\n",
      "Num timesteps: 19900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0093\n",
      "Last reward =  [-0.014791]\n",
      "Reward buffer length =  19900\n",
      "Num timesteps: 20000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0112\n",
      "Last reward =  [-0.01664948]\n",
      "Reward buffer length =  20000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 20100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0135\n",
      "Last reward =  [-0.02129871]\n",
      "Reward buffer length =  20100\n",
      "Num timesteps: 20200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0106\n",
      "Last reward =  [-0.0162123]\n",
      "Reward buffer length =  20200\n",
      "Num timesteps: 20300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0205\n",
      "Last reward =  [-0.00852333]\n",
      "Reward buffer length =  20300\n",
      "Num timesteps: 20400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0204\n",
      "Last reward =  [0.00174934]\n",
      "Reward buffer length =  20400\n",
      "Num timesteps: 20500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0020\n",
      "Last reward =  [0.00076896]\n",
      "Reward buffer length =  20500\n",
      "Num timesteps: 20600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0069\n",
      "Last reward =  [-0.00816472]\n",
      "Reward buffer length =  20600\n",
      "Num timesteps: 20700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0145\n",
      "Last reward =  [-0.04076016]\n",
      "Reward buffer length =  20700\n",
      "Num timesteps: 20800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0108\n",
      "Last reward =  [0.03561054]\n",
      "Reward buffer length =  20800\n",
      "Num timesteps: 20900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0117\n",
      "Last reward =  [0.06154317]\n",
      "Reward buffer length =  20900\n",
      "Num timesteps: 21000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0134\n",
      "Last reward =  [0.00646345]\n",
      "Reward buffer length =  21000\n",
      "Num timesteps: 21100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0228\n",
      "Last reward =  [0.02929608]\n",
      "Reward buffer length =  21100\n",
      "Num timesteps: 21200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0018\n",
      "Last reward =  [0.00990972]\n",
      "Reward buffer length =  21200\n",
      "Num timesteps: 21300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0018\n",
      "Last reward =  [0.04329698]\n",
      "Reward buffer length =  21300\n",
      "Num timesteps: 21400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0084\n",
      "Last reward =  [-0.01334452]\n",
      "Reward buffer length =  21400\n",
      "Num timesteps: 21500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0121\n",
      "Last reward =  [-0.02903756]\n",
      "Reward buffer length =  21500\n",
      "Num timesteps: 21600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0113\n",
      "Last reward =  [-0.03394657]\n",
      "Reward buffer length =  21600\n",
      "Num timesteps: 21700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0131\n",
      "Last reward =  [-0.03614157]\n",
      "Reward buffer length =  21700\n",
      "Num timesteps: 21800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0145\n",
      "Last reward =  [-0.01941517]\n",
      "Reward buffer length =  21800\n",
      "Num timesteps: 21900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0276\n",
      "Last reward =  [-0.03966862]\n",
      "Reward buffer length =  21900\n",
      "Num timesteps: 22000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0209\n",
      "Last reward =  [-0.0263061]\n",
      "Reward buffer length =  22000\n",
      "Num timesteps: 22100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0167\n",
      "Last reward =  [0.00247789]\n",
      "Reward buffer length =  22100\n",
      "Num timesteps: 22200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0070\n",
      "Last reward =  [-0.01300035]\n",
      "Reward buffer length =  22200\n",
      "Num timesteps: 22300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0084\n",
      "Last reward =  [0.00991115]\n",
      "Reward buffer length =  22300\n",
      "Num timesteps: 22400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0104\n",
      "Last reward =  [-0.05196081]\n",
      "Reward buffer length =  22400\n",
      "Num timesteps: 22500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0130\n",
      "Last reward =  [-0.00963074]\n",
      "Reward buffer length =  22500\n",
      "Num timesteps: 22600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0158\n",
      "Last reward =  [-0.02496861]\n",
      "Reward buffer length =  22600\n",
      "Num timesteps: 22700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0203\n",
      "Last reward =  [-0.06145784]\n",
      "Reward buffer length =  22700\n",
      "Num timesteps: 22800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0268\n",
      "Last reward =  [-0.03236859]\n",
      "Reward buffer length =  22800\n",
      "Num timesteps: 22900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0086\n",
      "Last reward =  [-0.00588765]\n",
      "Reward buffer length =  22900\n",
      "Num timesteps: 23000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0084\n",
      "Last reward =  [-0.04074914]\n",
      "Reward buffer length =  23000\n",
      "Num timesteps: 23100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0156\n",
      "Last reward =  [-0.00993909]\n",
      "Reward buffer length =  23100\n",
      "Num timesteps: 23200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0176\n",
      "Last reward =  [-0.03720727]\n",
      "Reward buffer length =  23200\n",
      "Num timesteps: 23300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0270\n",
      "Last reward =  [-0.08311924]\n",
      "Reward buffer length =  23300\n",
      "Num timesteps: 23400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0079\n",
      "Last reward =  [-0.02283599]\n",
      "Reward buffer length =  23400\n",
      "Num timesteps: 23500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0095\n",
      "Last reward =  [0.01237429]\n",
      "Reward buffer length =  23500\n",
      "Num timesteps: 23600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0061\n",
      "Last reward =  [-0.02290748]\n",
      "Reward buffer length =  23600\n",
      "Num timesteps: 23700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0200\n",
      "Last reward =  [-0.09244668]\n",
      "Reward buffer length =  23700\n",
      "Num timesteps: 23800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0169\n",
      "Last reward =  [-0.05243609]\n",
      "Reward buffer length =  23800\n",
      "Num timesteps: 23900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0262\n",
      "Last reward =  [-0.107623]\n",
      "Reward buffer length =  23900\n",
      "Num timesteps: 24000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0354\n",
      "Last reward =  [-0.00695764]\n",
      "Reward buffer length =  24000\n",
      "Num timesteps: 24100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0231\n",
      "Last reward =  [-0.0149087]\n",
      "Reward buffer length =  24100\n",
      "Num timesteps: 24200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0067\n",
      "Last reward =  [0.00204635]\n",
      "Reward buffer length =  24200\n",
      "Num timesteps: 24300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0127\n",
      "Last reward =  [-0.02252211]\n",
      "Reward buffer length =  24300\n",
      "Num timesteps: 24400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0088\n",
      "Last reward =  [-0.02650654]\n",
      "Reward buffer length =  24400\n",
      "Num timesteps: 24500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0164\n",
      "Last reward =  [-0.00351219]\n",
      "Reward buffer length =  24500\n",
      "Num timesteps: 24600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0203\n",
      "Last reward =  [-0.04610477]\n",
      "Reward buffer length =  24600\n",
      "Num timesteps: 24700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0205\n",
      "Last reward =  [-0.01214198]\n",
      "Reward buffer length =  24700\n",
      "Num timesteps: 24800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0310\n",
      "Last reward =  [0.0147376]\n",
      "Reward buffer length =  24800\n",
      "Num timesteps: 24900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0076\n",
      "Last reward =  [-0.04491927]\n",
      "Reward buffer length =  24900\n",
      "Num timesteps: 25000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0152\n",
      "Last reward =  [0.0064191]\n",
      "Reward buffer length =  25000\n",
      "Num timesteps: 25100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0186\n",
      "Last reward =  [-0.00680921]\n",
      "Reward buffer length =  25100\n",
      "Num timesteps: 25200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0220\n",
      "Last reward =  [-0.00771]\n",
      "Reward buffer length =  25200\n",
      "Num timesteps: 25300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0289\n",
      "Last reward =  [-0.01147655]\n",
      "Reward buffer length =  25300\n",
      "Num timesteps: 25400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0063\n",
      "Last reward =  [-0.04105537]\n",
      "Reward buffer length =  25400\n",
      "Num timesteps: 25500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0166\n",
      "Last reward =  [-0.03632462]\n",
      "Reward buffer length =  25500\n",
      "Num timesteps: 25600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0226\n",
      "Last reward =  [-0.0433723]\n",
      "Reward buffer length =  25600\n",
      "Num timesteps: 25700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0227\n",
      "Last reward =  [-0.02999681]\n",
      "Reward buffer length =  25700\n",
      "Num timesteps: 25800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0286\n",
      "Last reward =  [0.00788882]\n",
      "Reward buffer length =  25800\n",
      "Num timesteps: 25900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0008\n",
      "Last reward =  [-0.03249081]\n",
      "Reward buffer length =  25900\n",
      "Num timesteps: 26000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0040\n",
      "Last reward =  [-0.01651995]\n",
      "Reward buffer length =  26000\n",
      "Num timesteps: 26100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0094\n",
      "Last reward =  [0.00500663]\n",
      "Reward buffer length =  26100\n",
      "Num timesteps: 26200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0024\n",
      "Last reward =  [0.20418386]\n",
      "Reward buffer length =  26200\n",
      "Num timesteps: 26300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0113\n",
      "Last reward =  [-0.02887714]\n",
      "Reward buffer length =  26300\n",
      "Num timesteps: 26400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.02103404]\n",
      "Reward buffer length =  26400\n",
      "Num timesteps: 26500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0218\n",
      "Last reward =  [-0.05429786]\n",
      "Reward buffer length =  26500\n",
      "Num timesteps: 26600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0244\n",
      "Last reward =  [-0.07679808]\n",
      "Reward buffer length =  26600\n",
      "Num timesteps: 26700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0283\n",
      "Last reward =  [-0.06464463]\n",
      "Reward buffer length =  26700\n",
      "Num timesteps: 26800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0158\n",
      "Last reward =  [-0.01525895]\n",
      "Reward buffer length =  26800\n",
      "Num timesteps: 26900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0037\n",
      "Last reward =  [-0.0346544]\n",
      "Reward buffer length =  26900\n",
      "Num timesteps: 27000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0071\n",
      "Last reward =  [0.00281626]\n",
      "Reward buffer length =  27000\n",
      "Num timesteps: 27100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0150\n",
      "Last reward =  [-0.06386773]\n",
      "Reward buffer length =  27100\n",
      "Num timesteps: 27200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0045\n",
      "Last reward =  [-0.03050151]\n",
      "Reward buffer length =  27200\n",
      "Num timesteps: 27300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0264\n",
      "Last reward =  [-0.01060552]\n",
      "Reward buffer length =  27300\n",
      "Num timesteps: 27400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0210\n",
      "Last reward =  [0.05220505]\n",
      "Reward buffer length =  27400\n",
      "Num timesteps: 27500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0275\n",
      "Last reward =  [-0.0441174]\n",
      "Reward buffer length =  27500\n",
      "Num timesteps: 27600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0240\n",
      "Last reward =  [0.01289424]\n",
      "Reward buffer length =  27600\n",
      "Num timesteps: 27700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0279\n",
      "Last reward =  [-0.03811588]\n",
      "Reward buffer length =  27700\n",
      "Num timesteps: 27800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0345\n",
      "Last reward =  [0.02002544]\n",
      "Reward buffer length =  27800\n",
      "Num timesteps: 27900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0251\n",
      "Last reward =  [-0.04293814]\n",
      "Reward buffer length =  27900\n",
      "Num timesteps: 28000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0174\n",
      "Last reward =  [-0.04739233]\n",
      "Reward buffer length =  28000\n",
      "Num timesteps: 28100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0221\n",
      "Last reward =  [-0.03252091]\n",
      "Reward buffer length =  28100\n",
      "Num timesteps: 28200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0263\n",
      "Last reward =  [-0.01833371]\n",
      "Reward buffer length =  28200\n",
      "Num timesteps: 28300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0333\n",
      "Last reward =  [-0.01550488]\n",
      "Reward buffer length =  28300\n",
      "Num timesteps: 28400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0105\n",
      "Last reward =  [-0.01705794]\n",
      "Reward buffer length =  28400\n",
      "Num timesteps: 28500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0132\n",
      "Last reward =  [-0.02700972]\n",
      "Reward buffer length =  28500\n",
      "Num timesteps: 28600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0031\n",
      "Last reward =  [0.01272089]\n",
      "Reward buffer length =  28600\n",
      "Num timesteps: 28700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0249\n",
      "Last reward =  [-0.04710687]\n",
      "Reward buffer length =  28700\n",
      "Num timesteps: 28800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0220\n",
      "Last reward =  [-0.03961487]\n",
      "Reward buffer length =  28800\n",
      "Num timesteps: 28900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0311\n",
      "Last reward =  [-0.07866671]\n",
      "Reward buffer length =  28900\n",
      "Num timesteps: 29000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0217\n",
      "Last reward =  [-0.04470937]\n",
      "Reward buffer length =  29000\n",
      "Num timesteps: 29100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0129\n",
      "Last reward =  [-0.0265598]\n",
      "Reward buffer length =  29100\n",
      "Num timesteps: 29200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0011\n",
      "Last reward =  [-0.01135094]\n",
      "Reward buffer length =  29200\n",
      "Num timesteps: 29300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0175\n",
      "Last reward =  [0.01476717]\n",
      "Reward buffer length =  29300\n",
      "Num timesteps: 29400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0247\n",
      "Last reward =  [-0.06105153]\n",
      "Reward buffer length =  29400\n",
      "Num timesteps: 29500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0274\n",
      "Last reward =  [-0.02601507]\n",
      "Reward buffer length =  29500\n",
      "Num timesteps: 29600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0346\n",
      "Last reward =  [-0.11512289]\n",
      "Reward buffer length =  29600\n",
      "Num timesteps: 29700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0095\n",
      "Last reward =  [-0.00538008]\n",
      "Reward buffer length =  29700\n",
      "Num timesteps: 29800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0138\n",
      "Last reward =  [0.01706064]\n",
      "Reward buffer length =  29800\n",
      "Num timesteps: 29900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0159\n",
      "Last reward =  [-0.00727111]\n",
      "Reward buffer length =  29900\n",
      "Num timesteps: 30000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0023\n",
      "Last reward =  [-0.01642336]\n",
      "Reward buffer length =  30000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 30100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0231\n",
      "Last reward =  [-0.03149597]\n",
      "Reward buffer length =  30100\n",
      "Num timesteps: 30200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0230\n",
      "Last reward =  [0.04577086]\n",
      "Reward buffer length =  30200\n",
      "Num timesteps: 30300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0350\n",
      "Last reward =  [-0.09009253]\n",
      "Reward buffer length =  30300\n",
      "Num timesteps: 30400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0245\n",
      "Last reward =  [0.04114694]\n",
      "Reward buffer length =  30400\n",
      "Num timesteps: 30500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0005\n",
      "Last reward =  [-0.05145203]\n",
      "Reward buffer length =  30500\n",
      "Num timesteps: 30600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0060\n",
      "Last reward =  [0.01403858]\n",
      "Reward buffer length =  30600\n",
      "Num timesteps: 30700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0151\n",
      "Last reward =  [-0.02723803]\n",
      "Reward buffer length =  30700\n",
      "Num timesteps: 30800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0162\n",
      "Last reward =  [-0.0266575]\n",
      "Reward buffer length =  30800\n",
      "Num timesteps: 30900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0020\n",
      "Last reward =  [-0.02264711]\n",
      "Reward buffer length =  30900\n",
      "Num timesteps: 31000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0263\n",
      "Last reward =  [-0.05532587]\n",
      "Reward buffer length =  31000\n",
      "Num timesteps: 31100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.03245394]\n",
      "Reward buffer length =  31100\n",
      "Num timesteps: 31200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0343\n",
      "Last reward =  [-0.02611526]\n",
      "Reward buffer length =  31200\n",
      "Num timesteps: 31300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0288\n",
      "Last reward =  [0.01421397]\n",
      "Reward buffer length =  31300\n",
      "Num timesteps: 31400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0001\n",
      "Last reward =  [0.06443947]\n",
      "Reward buffer length =  31400\n",
      "Num timesteps: 31500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0278\n",
      "Last reward =  [0.00139594]\n",
      "Reward buffer length =  31500\n",
      "Num timesteps: 31600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0252\n",
      "Last reward =  [-0.06141252]\n",
      "Reward buffer length =  31600\n",
      "Num timesteps: 31700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0396\n",
      "Last reward =  [-0.05513331]\n",
      "Reward buffer length =  31700\n",
      "Num timesteps: 31800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0398\n",
      "Last reward =  [-0.02225618]\n",
      "Reward buffer length =  31800\n",
      "Num timesteps: 31900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0190\n",
      "Last reward =  [-0.04727677]\n",
      "Reward buffer length =  31900\n",
      "Num timesteps: 32000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0013\n",
      "Last reward =  [-0.04939169]\n",
      "Reward buffer length =  32000\n",
      "Num timesteps: 32100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0247\n",
      "Last reward =  [0.01955213]\n",
      "Reward buffer length =  32100\n",
      "Num timesteps: 32200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0279\n",
      "Last reward =  [-0.02807445]\n",
      "Reward buffer length =  32200\n",
      "Num timesteps: 32300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0344\n",
      "Last reward =  [-0.03720491]\n",
      "Reward buffer length =  32300\n",
      "Num timesteps: 32400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0423\n",
      "Last reward =  [-0.09362499]\n",
      "Reward buffer length =  32400\n",
      "Num timesteps: 32500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0390\n",
      "Last reward =  [-0.06350122]\n",
      "Reward buffer length =  32500\n",
      "Num timesteps: 32600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0394\n",
      "Last reward =  [-0.02043278]\n",
      "Reward buffer length =  32600\n",
      "Num timesteps: 32700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0367\n",
      "Last reward =  [-0.00656179]\n",
      "Reward buffer length =  32700\n",
      "Num timesteps: 32800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0376\n",
      "Last reward =  [-0.03468443]\n",
      "Reward buffer length =  32800\n",
      "Num timesteps: 32900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0062\n",
      "Last reward =  [-0.0303978]\n",
      "Reward buffer length =  32900\n",
      "Num timesteps: 33000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0165\n",
      "Last reward =  [-0.08040826]\n",
      "Reward buffer length =  33000\n",
      "Num timesteps: 33100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0184\n",
      "Last reward =  [-0.04900498]\n",
      "Reward buffer length =  33100\n",
      "Num timesteps: 33200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0020\n",
      "Last reward =  [-0.02288593]\n",
      "Reward buffer length =  33200\n",
      "Num timesteps: 33300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0273\n",
      "Last reward =  [0.05999477]\n",
      "Reward buffer length =  33300\n",
      "Num timesteps: 33400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0272\n",
      "Last reward =  [-0.0296309]\n",
      "Reward buffer length =  33400\n",
      "Num timesteps: 33500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0433\n",
      "Last reward =  [-0.04898476]\n",
      "Reward buffer length =  33500\n",
      "Num timesteps: 33600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0408\n",
      "Last reward =  [-0.04814135]\n",
      "Reward buffer length =  33600\n",
      "Num timesteps: 33700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0318\n",
      "Last reward =  [-0.02112692]\n",
      "Reward buffer length =  33700\n",
      "Num timesteps: 33800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0298\n",
      "Last reward =  [0.03011423]\n",
      "Reward buffer length =  33800\n",
      "Num timesteps: 33900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0415\n",
      "Last reward =  [-0.05971983]\n",
      "Reward buffer length =  33900\n",
      "Num timesteps: 34000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0516\n",
      "Last reward =  [-0.00914787]\n",
      "Reward buffer length =  34000\n",
      "Num timesteps: 34100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0223\n",
      "Last reward =  [-0.07521987]\n",
      "Reward buffer length =  34100\n",
      "Num timesteps: 34200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0054\n",
      "Last reward =  [-0.04959384]\n",
      "Reward buffer length =  34200\n",
      "Num timesteps: 34300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0346\n",
      "Last reward =  [-0.02224138]\n",
      "Reward buffer length =  34300\n",
      "Num timesteps: 34400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0328\n",
      "Last reward =  [0.03291018]\n",
      "Reward buffer length =  34400\n",
      "Num timesteps: 34500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0446\n",
      "Last reward =  [-0.06782693]\n",
      "Reward buffer length =  34500\n",
      "Num timesteps: 34600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0136\n",
      "Last reward =  [0.01211832]\n",
      "Reward buffer length =  34600\n",
      "Num timesteps: 34700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0042\n",
      "Last reward =  [-0.00243618]\n",
      "Reward buffer length =  34700\n",
      "Num timesteps: 34800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0111\n",
      "Last reward =  [0.02587233]\n",
      "Reward buffer length =  34800\n",
      "Num timesteps: 34900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0195\n",
      "Last reward =  [-0.0205346]\n",
      "Reward buffer length =  34900\n",
      "Num timesteps: 35000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0047\n",
      "Last reward =  [-0.02381301]\n",
      "Reward buffer length =  35000\n",
      "Num timesteps: 35100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0264\n",
      "Last reward =  [-0.02212156]\n",
      "Reward buffer length =  35100\n",
      "Num timesteps: 35200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0333\n",
      "Last reward =  [-0.01791502]\n",
      "Reward buffer length =  35200\n",
      "Num timesteps: 35300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0403\n",
      "Last reward =  [-0.0573021]\n",
      "Reward buffer length =  35300\n",
      "Num timesteps: 35400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0528\n",
      "Last reward =  [-0.05252449]\n",
      "Reward buffer length =  35400\n",
      "Num timesteps: 35500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0512\n",
      "Last reward =  [0.01378896]\n",
      "Reward buffer length =  35500\n",
      "Num timesteps: 35600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0306\n",
      "Last reward =  [0.01111893]\n",
      "Reward buffer length =  35600\n",
      "Num timesteps: 35700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0345\n",
      "Last reward =  [-0.06194166]\n",
      "Reward buffer length =  35700\n",
      "Num timesteps: 35800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0426\n",
      "Last reward =  [-0.052057]\n",
      "Reward buffer length =  35800\n",
      "Num timesteps: 35900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0579\n",
      "Last reward =  [-0.00994995]\n",
      "Reward buffer length =  35900\n",
      "Num timesteps: 36000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: 0.0015\n",
      "Last reward =  [-0.03552303]\n",
      "Reward buffer length =  36000\n",
      "Num timesteps: 36100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0039\n",
      "Last reward =  [-0.00926508]\n",
      "Reward buffer length =  36100\n",
      "Num timesteps: 36200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0158\n",
      "Last reward =  [-0.00381671]\n",
      "Reward buffer length =  36200\n",
      "Num timesteps: 36300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0230\n",
      "Last reward =  [-0.03015581]\n",
      "Reward buffer length =  36300\n",
      "Num timesteps: 36400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0035\n",
      "Last reward =  [0.0367079]\n",
      "Reward buffer length =  36400\n",
      "Num timesteps: 36500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0358\n",
      "Last reward =  [-0.04073381]\n",
      "Reward buffer length =  36500\n",
      "Num timesteps: 36600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0357\n",
      "Last reward =  [0.00274111]\n",
      "Reward buffer length =  36600\n",
      "Num timesteps: 36700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0453\n",
      "Last reward =  [-0.01570898]\n",
      "Reward buffer length =  36700\n",
      "Num timesteps: 36800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0502\n",
      "Last reward =  [0.00996747]\n",
      "Reward buffer length =  36800\n",
      "Num timesteps: 36900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0114\n",
      "Last reward =  [-0.01887981]\n",
      "Reward buffer length =  36900\n",
      "Num timesteps: 37000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0199\n",
      "Last reward =  [-0.04026751]\n",
      "Reward buffer length =  37000\n",
      "Num timesteps: 37100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0215\n",
      "Last reward =  [0.03992967]\n",
      "Reward buffer length =  37100\n",
      "Num timesteps: 37200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0108\n",
      "Last reward =  [0.01505449]\n",
      "Reward buffer length =  37200\n",
      "Num timesteps: 37300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0352\n",
      "Last reward =  [-0.02131999]\n",
      "Reward buffer length =  37300\n",
      "Num timesteps: 37400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0396\n",
      "Last reward =  [-0.07602787]\n",
      "Reward buffer length =  37400\n",
      "Num timesteps: 37500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0506\n",
      "Last reward =  [0.00426423]\n",
      "Reward buffer length =  37500\n",
      "Num timesteps: 37600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0164\n",
      "Last reward =  [-0.04885819]\n",
      "Reward buffer length =  37600\n",
      "Num timesteps: 37700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0345\n",
      "Last reward =  [-0.07553726]\n",
      "Reward buffer length =  37700\n",
      "Num timesteps: 37800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0377\n",
      "Last reward =  [-0.04178607]\n",
      "Reward buffer length =  37800\n",
      "Num timesteps: 37900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0535\n",
      "Last reward =  [-0.08403067]\n",
      "Reward buffer length =  37900\n",
      "Num timesteps: 38000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0519\n",
      "Last reward =  [-0.00358637]\n",
      "Reward buffer length =  38000\n",
      "Num timesteps: 38100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0505\n",
      "Last reward =  [-0.01492154]\n",
      "Reward buffer length =  38100\n",
      "Num timesteps: 38200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0588\n",
      "Last reward =  [-0.0573691]\n",
      "Reward buffer length =  38200\n",
      "Num timesteps: 38300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0442\n",
      "Last reward =  [-0.08044378]\n",
      "Reward buffer length =  38300\n",
      "Num timesteps: 38400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0566\n",
      "Last reward =  [-0.07841931]\n",
      "Reward buffer length =  38400\n",
      "Num timesteps: 38500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0424\n",
      "Last reward =  [-0.02449497]\n",
      "Reward buffer length =  38500\n",
      "Num timesteps: 38600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0090\n",
      "Last reward =  [-0.05192239]\n",
      "Reward buffer length =  38600\n",
      "Num timesteps: 38700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0369\n",
      "Last reward =  [-0.03083426]\n",
      "Reward buffer length =  38700\n",
      "Num timesteps: 38800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0435\n",
      "Last reward =  [-0.09069367]\n",
      "Reward buffer length =  38800\n",
      "Num timesteps: 38900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0553\n",
      "Last reward =  [-0.09300181]\n",
      "Reward buffer length =  38900\n",
      "Num timesteps: 39000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0391\n",
      "Last reward =  [0.02908333]\n",
      "Reward buffer length =  39000\n",
      "Num timesteps: 39100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0232\n",
      "Last reward =  [-0.04016858]\n",
      "Reward buffer length =  39100\n",
      "Num timesteps: 39200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0110\n",
      "Last reward =  [-0.01651897]\n",
      "Reward buffer length =  39200\n",
      "Num timesteps: 39300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0361\n",
      "Last reward =  [-0.02006115]\n",
      "Reward buffer length =  39300\n",
      "Num timesteps: 39400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0410\n",
      "Last reward =  [-0.06294139]\n",
      "Reward buffer length =  39400\n",
      "Num timesteps: 39500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0517\n",
      "Last reward =  [0.01667902]\n",
      "Reward buffer length =  39500\n",
      "Num timesteps: 39600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0626\n",
      "Last reward =  [-0.11522795]\n",
      "Reward buffer length =  39600\n",
      "Num timesteps: 39700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0603\n",
      "Last reward =  [-0.06355658]\n",
      "Reward buffer length =  39700\n",
      "Num timesteps: 39800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0396\n",
      "Last reward =  [-0.04027486]\n",
      "Reward buffer length =  39800\n",
      "Num timesteps: 39900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0429\n",
      "Last reward =  [-0.01396394]\n",
      "Reward buffer length =  39900\n",
      "Num timesteps: 40000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0553\n",
      "Last reward =  [-0.04311132]\n",
      "Reward buffer length =  40000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 40100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0583\n",
      "Last reward =  [-0.02188774]\n",
      "Reward buffer length =  40100\n",
      "Num timesteps: 40200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0293\n",
      "Last reward =  [-0.0453858]\n",
      "Reward buffer length =  40200\n",
      "Num timesteps: 40300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0154\n",
      "Last reward =  [-0.06572668]\n",
      "Reward buffer length =  40300\n",
      "Num timesteps: 40400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0419\n",
      "Last reward =  [-0.01892707]\n",
      "Reward buffer length =  40400\n",
      "Num timesteps: 40500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0469\n",
      "Last reward =  [-0.0514876]\n",
      "Reward buffer length =  40500\n",
      "Num timesteps: 40600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0615\n",
      "Last reward =  [-0.02531357]\n",
      "Reward buffer length =  40600\n",
      "Num timesteps: 40700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0523\n",
      "Last reward =  [-0.0665197]\n",
      "Reward buffer length =  40700\n",
      "Num timesteps: 40800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0461\n",
      "Last reward =  [-0.08651544]\n",
      "Reward buffer length =  40800\n",
      "Num timesteps: 40900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0603\n",
      "Last reward =  [-0.0645475]\n",
      "Reward buffer length =  40900\n",
      "Num timesteps: 41000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0699\n",
      "Last reward =  [-0.05728378]\n",
      "Reward buffer length =  41000\n",
      "Num timesteps: 41100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0537\n",
      "Last reward =  [-0.08008937]\n",
      "Reward buffer length =  41100\n",
      "Num timesteps: 41200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0643\n",
      "Last reward =  [-0.06696716]\n",
      "Reward buffer length =  41200\n",
      "Num timesteps: 41300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0559\n",
      "Last reward =  [-0.01335462]\n",
      "Reward buffer length =  41300\n",
      "Num timesteps: 41400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0134\n",
      "Last reward =  [0.02124474]\n",
      "Reward buffer length =  41400\n",
      "Num timesteps: 41500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0403\n",
      "Last reward =  [-0.06198519]\n",
      "Reward buffer length =  41500\n",
      "Num timesteps: 41600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0431\n",
      "Last reward =  [-0.06069122]\n",
      "Reward buffer length =  41600\n",
      "Num timesteps: 41700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0583\n",
      "Last reward =  [-0.10028683]\n",
      "Reward buffer length =  41700\n",
      "Num timesteps: 41800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0685\n",
      "Last reward =  [0.02874148]\n",
      "Reward buffer length =  41800\n",
      "Num timesteps: 41900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0483\n",
      "Last reward =  [-0.05494436]\n",
      "Reward buffer length =  41900\n",
      "Num timesteps: 42000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0672\n",
      "Last reward =  [-0.07095778]\n",
      "Reward buffer length =  42000\n",
      "Num timesteps: 42100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0473\n",
      "Last reward =  [-0.0245901]\n",
      "Reward buffer length =  42100\n",
      "Num timesteps: 42200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0046\n",
      "Last reward =  [0.04269016]\n",
      "Reward buffer length =  42200\n",
      "Num timesteps: 42300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0200\n",
      "Last reward =  [0.01189525]\n",
      "Reward buffer length =  42300\n",
      "Num timesteps: 42400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0266\n",
      "Last reward =  [-0.00722818]\n",
      "Reward buffer length =  42400\n",
      "Num timesteps: 42500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0150\n",
      "Last reward =  [-0.08125965]\n",
      "Reward buffer length =  42500\n",
      "Num timesteps: 42600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0388\n",
      "Last reward =  [-0.02614892]\n",
      "Reward buffer length =  42600\n",
      "Num timesteps: 42700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0451\n",
      "Last reward =  [-0.06998275]\n",
      "Reward buffer length =  42700\n",
      "Num timesteps: 42800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0617\n",
      "Last reward =  [-0.03334618]\n",
      "Reward buffer length =  42800\n",
      "Num timesteps: 42900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0638\n",
      "Last reward =  [-0.02598174]\n",
      "Reward buffer length =  42900\n",
      "Num timesteps: 43000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0244\n",
      "Last reward =  [-0.04226881]\n",
      "Reward buffer length =  43000\n",
      "Num timesteps: 43100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0241\n",
      "Last reward =  [-0.02241848]\n",
      "Reward buffer length =  43100\n",
      "Num timesteps: 43200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0315\n",
      "Last reward =  [-0.0261108]\n",
      "Reward buffer length =  43200\n",
      "Num timesteps: 43300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0471\n",
      "Last reward =  [-0.07045794]\n",
      "Reward buffer length =  43300\n",
      "Num timesteps: 43400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0571\n",
      "Last reward =  [-0.03571779]\n",
      "Reward buffer length =  43400\n",
      "Num timesteps: 43500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0691\n",
      "Last reward =  [-0.10099594]\n",
      "Reward buffer length =  43500\n",
      "Num timesteps: 43600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0274\n",
      "Last reward =  [-0.05452394]\n",
      "Reward buffer length =  43600\n",
      "Num timesteps: 43700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0464\n",
      "Last reward =  [-0.06064769]\n",
      "Reward buffer length =  43700\n",
      "Num timesteps: 43800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0518\n",
      "Last reward =  [-0.08243464]\n",
      "Reward buffer length =  43800\n",
      "Num timesteps: 43900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0692\n",
      "Last reward =  [-0.01975301]\n",
      "Reward buffer length =  43900\n",
      "Num timesteps: 44000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0788\n",
      "Last reward =  [-0.0716526]\n",
      "Reward buffer length =  44000\n",
      "Num timesteps: 44100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0737\n",
      "Last reward =  [-0.18228789]\n",
      "Reward buffer length =  44100\n",
      "Num timesteps: 44200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0656\n",
      "Last reward =  [-0.04782488]\n",
      "Reward buffer length =  44200\n",
      "Num timesteps: 44300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0487\n",
      "Last reward =  [-0.08277021]\n",
      "Reward buffer length =  44300\n",
      "Num timesteps: 44400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0606\n",
      "Last reward =  [-0.00011432]\n",
      "Reward buffer length =  44400\n",
      "Num timesteps: 44500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0794\n",
      "Last reward =  [-0.04532946]\n",
      "Reward buffer length =  44500\n",
      "Num timesteps: 44600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0125\n",
      "Last reward =  [-0.03098473]\n",
      "Reward buffer length =  44600\n",
      "Num timesteps: 44700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0245\n",
      "Last reward =  [-0.03960835]\n",
      "Reward buffer length =  44700\n",
      "Num timesteps: 44800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0323\n",
      "Last reward =  [-0.00347711]\n",
      "Reward buffer length =  44800\n",
      "Num timesteps: 44900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0216\n",
      "Last reward =  [-0.04874381]\n",
      "Reward buffer length =  44900\n",
      "Num timesteps: 45000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0487\n",
      "Last reward =  [-0.10093573]\n",
      "Reward buffer length =  45000\n",
      "Num timesteps: 45100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0558\n",
      "Last reward =  [-0.11196862]\n",
      "Reward buffer length =  45100\n",
      "Num timesteps: 45200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0704\n",
      "Last reward =  [-0.06225706]\n",
      "Reward buffer length =  45200\n",
      "Num timesteps: 45300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0907\n",
      "Last reward =  [-0.09629358]\n",
      "Reward buffer length =  45300\n",
      "Num timesteps: 45400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0624\n",
      "Last reward =  [-0.01748045]\n",
      "Reward buffer length =  45400\n",
      "Num timesteps: 45500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0753\n",
      "Last reward =  [-0.10414734]\n",
      "Reward buffer length =  45500\n",
      "Num timesteps: 45600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0689\n",
      "Last reward =  [0.01814861]\n",
      "Reward buffer length =  45600\n",
      "Num timesteps: 45700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0336\n",
      "Last reward =  [-0.06167988]\n",
      "Reward buffer length =  45700\n",
      "Num timesteps: 45800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0235\n",
      "Last reward =  [-0.07375094]\n",
      "Reward buffer length =  45800\n",
      "Num timesteps: 45900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0505\n",
      "Last reward =  [-0.07717458]\n",
      "Reward buffer length =  45900\n",
      "Num timesteps: 46000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0613\n",
      "Last reward =  [-0.07806053]\n",
      "Reward buffer length =  46000\n",
      "Num timesteps: 46100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0742\n",
      "Last reward =  [-0.07661512]\n",
      "Reward buffer length =  46100\n",
      "Num timesteps: 46200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0574\n",
      "Last reward =  [-0.07393772]\n",
      "Reward buffer length =  46200\n",
      "Num timesteps: 46300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0512\n",
      "Last reward =  [-0.00485987]\n",
      "Reward buffer length =  46300\n",
      "Num timesteps: 46400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0601\n",
      "Last reward =  [-0.12813863]\n",
      "Reward buffer length =  46400\n",
      "Num timesteps: 46500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0729\n",
      "Last reward =  [-0.16260694]\n",
      "Reward buffer length =  46500\n",
      "Num timesteps: 46600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0535\n",
      "Last reward =  [-0.08507647]\n",
      "Reward buffer length =  46600\n",
      "Num timesteps: 46700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0238\n",
      "Last reward =  [-0.04867307]\n",
      "Reward buffer length =  46700\n",
      "Num timesteps: 46800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0542\n",
      "Last reward =  [-0.13404234]\n",
      "Reward buffer length =  46800\n",
      "Num timesteps: 46900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0621\n",
      "Last reward =  [0.0377076]\n",
      "Reward buffer length =  46900\n",
      "Num timesteps: 47000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0783\n",
      "Last reward =  [-0.06568827]\n",
      "Reward buffer length =  47000\n",
      "Num timesteps: 47100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0521\n",
      "Last reward =  [-0.06235497]\n",
      "Reward buffer length =  47100\n",
      "Num timesteps: 47200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0258\n",
      "Last reward =  [-0.07955071]\n",
      "Reward buffer length =  47200\n",
      "Num timesteps: 47300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0544\n",
      "Last reward =  [-0.08615616]\n",
      "Reward buffer length =  47300\n",
      "Num timesteps: 47400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0625\n",
      "Last reward =  [-0.08355236]\n",
      "Reward buffer length =  47400\n",
      "Num timesteps: 47500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0751\n",
      "Last reward =  [-0.06643401]\n",
      "Reward buffer length =  47500\n",
      "Num timesteps: 47600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0507\n",
      "Last reward =  [-0.0182604]\n",
      "Reward buffer length =  47600\n",
      "Num timesteps: 47700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0259\n",
      "Last reward =  [0.0471783]\n",
      "Reward buffer length =  47700\n",
      "Num timesteps: 47800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0390\n",
      "Last reward =  [-0.11339863]\n",
      "Reward buffer length =  47800\n",
      "Num timesteps: 47900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0500\n",
      "Last reward =  [0.01107469]\n",
      "Reward buffer length =  47900\n",
      "Num timesteps: 48000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0672\n",
      "Last reward =  [-0.03315654]\n",
      "Reward buffer length =  48000\n",
      "Num timesteps: 48100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0778\n",
      "Last reward =  [-0.11497776]\n",
      "Reward buffer length =  48100\n",
      "Num timesteps: 48200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0284\n",
      "Last reward =  [-0.0451595]\n",
      "Reward buffer length =  48200\n",
      "Num timesteps: 48300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0285\n",
      "Last reward =  [-0.0153486]\n",
      "Reward buffer length =  48300\n",
      "Num timesteps: 48400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0363\n",
      "Last reward =  [-0.07089725]\n",
      "Reward buffer length =  48400\n",
      "Num timesteps: 48500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0299\n",
      "Last reward =  [-0.00532789]\n",
      "Reward buffer length =  48500\n",
      "Num timesteps: 48600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0534\n",
      "Last reward =  [-0.05454083]\n",
      "Reward buffer length =  48600\n",
      "Num timesteps: 48700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0632\n",
      "Last reward =  [-0.01437574]\n",
      "Reward buffer length =  48700\n",
      "Num timesteps: 48800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0758\n",
      "Last reward =  [-0.05431383]\n",
      "Reward buffer length =  48800\n",
      "Num timesteps: 48900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0420\n",
      "Last reward =  [0.02154649]\n",
      "Reward buffer length =  48900\n",
      "Num timesteps: 49000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0315\n",
      "Last reward =  [-0.02988411]\n",
      "Reward buffer length =  49000\n",
      "Num timesteps: 49100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0236\n",
      "Last reward =  [-0.10128719]\n",
      "Reward buffer length =  49100\n",
      "Num timesteps: 49200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0482\n",
      "Last reward =  [-0.10927712]\n",
      "Reward buffer length =  49200\n",
      "Num timesteps: 49300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0563\n",
      "Last reward =  [-0.09763347]\n",
      "Reward buffer length =  49300\n",
      "Num timesteps: 49400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0734\n",
      "Last reward =  [-0.05975533]\n",
      "Reward buffer length =  49400\n",
      "Num timesteps: 49500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0859\n",
      "Last reward =  [0.02053408]\n",
      "Reward buffer length =  49500\n",
      "Num timesteps: 49600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0348\n",
      "Last reward =  [-0.04746686]\n",
      "Reward buffer length =  49600\n",
      "Num timesteps: 49700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0225\n",
      "Last reward =  [-0.03608055]\n",
      "Reward buffer length =  49700\n",
      "Num timesteps: 49800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0507\n",
      "Last reward =  [-0.0454133]\n",
      "Reward buffer length =  49800\n",
      "Num timesteps: 49900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0538\n",
      "Last reward =  [-0.04635455]\n",
      "Reward buffer length =  49900\n",
      "Num timesteps: 50000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0698\n",
      "Last reward =  [-0.013702]\n",
      "Reward buffer length =  50000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 50100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0810\n",
      "Last reward =  [-0.05710677]\n",
      "Reward buffer length =  50100\n",
      "Num timesteps: 50200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0719\n",
      "Last reward =  [-0.04975824]\n",
      "Reward buffer length =  50200\n",
      "Num timesteps: 50300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0877\n",
      "Last reward =  [-0.18960808]\n",
      "Reward buffer length =  50300\n",
      "Num timesteps: 50400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0375\n",
      "Last reward =  [-0.07653371]\n",
      "Reward buffer length =  50400\n",
      "Num timesteps: 50500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0356\n",
      "Last reward =  [0.24849921]\n",
      "Reward buffer length =  50500\n",
      "Num timesteps: 50600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0395\n",
      "Last reward =  [-0.04285507]\n",
      "Reward buffer length =  50600\n",
      "Num timesteps: 50700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0588\n",
      "Last reward =  [-0.01255437]\n",
      "Reward buffer length =  50700\n",
      "Num timesteps: 50800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0652\n",
      "Last reward =  [-0.12312727]\n",
      "Reward buffer length =  50800\n",
      "Num timesteps: 50900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0811\n",
      "Last reward =  [-0.10896502]\n",
      "Reward buffer length =  50900\n",
      "Num timesteps: 51000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0521\n",
      "Last reward =  [-0.02706441]\n",
      "Reward buffer length =  51000\n",
      "Num timesteps: 51100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0612\n",
      "Last reward =  [-0.20039725]\n",
      "Reward buffer length =  51100\n",
      "Num timesteps: 51200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0599\n",
      "Last reward =  [-0.0162147]\n",
      "Reward buffer length =  51200\n",
      "Num timesteps: 51300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0860\n",
      "Last reward =  [-0.10796782]\n",
      "Reward buffer length =  51300\n",
      "Num timesteps: 51400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0675\n",
      "Last reward =  [-0.04201073]\n",
      "Reward buffer length =  51400\n",
      "Num timesteps: 51500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0358\n",
      "Last reward =  [-0.07038141]\n",
      "Reward buffer length =  51500\n",
      "Num timesteps: 51600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0254\n",
      "Last reward =  [-0.03645993]\n",
      "Reward buffer length =  51600\n",
      "Num timesteps: 51700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0567\n",
      "Last reward =  [-0.09261208]\n",
      "Reward buffer length =  51700\n",
      "Num timesteps: 51800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0572\n",
      "Last reward =  [0.00765758]\n",
      "Reward buffer length =  51800\n",
      "Num timesteps: 51900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0778\n",
      "Last reward =  [0.01654482]\n",
      "Reward buffer length =  51900\n",
      "Num timesteps: 52000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0929\n",
      "Last reward =  [-0.06310225]\n",
      "Reward buffer length =  52000\n",
      "Num timesteps: 52100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0638\n",
      "Last reward =  [-0.12928663]\n",
      "Reward buffer length =  52100\n",
      "Num timesteps: 52200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0642\n",
      "Last reward =  [0.0362389]\n",
      "Reward buffer length =  52200\n",
      "Num timesteps: 52300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0856\n",
      "Last reward =  [-0.11409347]\n",
      "Reward buffer length =  52300\n",
      "Num timesteps: 52400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0341\n",
      "Last reward =  [-0.01396672]\n",
      "Reward buffer length =  52400\n",
      "Num timesteps: 52500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0254\n",
      "Last reward =  [-0.00971863]\n",
      "Reward buffer length =  52500\n",
      "Num timesteps: 52600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0361\n",
      "Last reward =  [-0.0441866]\n",
      "Reward buffer length =  52600\n",
      "Num timesteps: 52700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0271\n",
      "Last reward =  [-0.04705025]\n",
      "Reward buffer length =  52700\n",
      "Num timesteps: 52800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0556\n",
      "Last reward =  [-0.10573436]\n",
      "Reward buffer length =  52800\n",
      "Num timesteps: 52900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0583\n",
      "Last reward =  [-0.05885879]\n",
      "Reward buffer length =  52900\n",
      "Num timesteps: 53000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0783\n",
      "Last reward =  [-0.10361232]\n",
      "Reward buffer length =  53000\n",
      "Num timesteps: 53100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0930\n",
      "Last reward =  [-0.12464668]\n",
      "Reward buffer length =  53100\n",
      "Num timesteps: 53200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0073\n",
      "Last reward =  [-0.04737373]\n",
      "Reward buffer length =  53200\n",
      "Num timesteps: 53300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0185\n",
      "Last reward =  [-0.03900478]\n",
      "Reward buffer length =  53300\n",
      "Num timesteps: 53400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0344\n",
      "Last reward =  [-0.09342068]\n",
      "Reward buffer length =  53400\n",
      "Num timesteps: 53500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0477\n",
      "Last reward =  [-0.05793486]\n",
      "Reward buffer length =  53500\n",
      "Num timesteps: 53600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0323\n",
      "Last reward =  [-0.0671967]\n",
      "Reward buffer length =  53600\n",
      "Num timesteps: 53700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0654\n",
      "Last reward =  [-0.01749879]\n",
      "Reward buffer length =  53700\n",
      "Num timesteps: 53800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0670\n",
      "Last reward =  [-0.10184422]\n",
      "Reward buffer length =  53800\n",
      "Num timesteps: 53900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0833\n",
      "Last reward =  [-0.01534887]\n",
      "Reward buffer length =  53900\n",
      "Num timesteps: 54000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0775\n",
      "Last reward =  [-0.11107649]\n",
      "Reward buffer length =  54000\n",
      "Num timesteps: 54100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0784\n",
      "Last reward =  [-0.04725343]\n",
      "Reward buffer length =  54100\n",
      "Num timesteps: 54200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0846\n",
      "Last reward =  [-0.09794147]\n",
      "Reward buffer length =  54200\n",
      "Num timesteps: 54300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0774\n",
      "Last reward =  [-0.07586788]\n",
      "Reward buffer length =  54300\n",
      "Num timesteps: 54400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0754\n",
      "Last reward =  [-0.05617198]\n",
      "Reward buffer length =  54400\n",
      "Num timesteps: 54500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0350\n",
      "Last reward =  [-0.01351278]\n",
      "Reward buffer length =  54500\n",
      "Num timesteps: 54600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0481\n",
      "Last reward =  [-0.10136342]\n",
      "Reward buffer length =  54600\n",
      "Num timesteps: 54700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0312\n",
      "Last reward =  [-0.09044632]\n",
      "Reward buffer length =  54700\n",
      "Num timesteps: 54800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0674\n",
      "Last reward =  [-0.0813169]\n",
      "Reward buffer length =  54800\n",
      "Num timesteps: 54900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0697\n",
      "Last reward =  [0.00538825]\n",
      "Reward buffer length =  54900\n",
      "Num timesteps: 55000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0840\n",
      "Last reward =  [-0.11575321]\n",
      "Reward buffer length =  55000\n",
      "Num timesteps: 55100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0651\n",
      "Last reward =  [-0.04014524]\n",
      "Reward buffer length =  55100\n",
      "Num timesteps: 55200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0339\n",
      "Last reward =  [-0.11564653]\n",
      "Reward buffer length =  55200\n",
      "Num timesteps: 55300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0579\n",
      "Last reward =  [-0.12501438]\n",
      "Reward buffer length =  55300\n",
      "Num timesteps: 55400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0707\n",
      "Last reward =  [-0.11314698]\n",
      "Reward buffer length =  55400\n",
      "Num timesteps: 55500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0837\n",
      "Last reward =  [-0.03618712]\n",
      "Reward buffer length =  55500\n",
      "Num timesteps: 55600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0975\n",
      "Last reward =  [-0.03134783]\n",
      "Reward buffer length =  55600\n",
      "Num timesteps: 55700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0801\n",
      "Last reward =  [-0.06618164]\n",
      "Reward buffer length =  55700\n",
      "Num timesteps: 55800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0971\n",
      "Last reward =  [-0.1349276]\n",
      "Reward buffer length =  55800\n",
      "Num timesteps: 55900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0847\n",
      "Last reward =  [-0.12535313]\n",
      "Reward buffer length =  55900\n",
      "Num timesteps: 56000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0473\n",
      "Last reward =  [-0.04278698]\n",
      "Reward buffer length =  56000\n",
      "Num timesteps: 56100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0488\n",
      "Last reward =  [-0.00900869]\n",
      "Reward buffer length =  56100\n",
      "Num timesteps: 56200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0324\n",
      "Last reward =  [-0.09325486]\n",
      "Reward buffer length =  56200\n",
      "Num timesteps: 56300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0627\n",
      "Last reward =  [-0.00219344]\n",
      "Reward buffer length =  56300\n",
      "Num timesteps: 56400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0738\n",
      "Last reward =  [-0.03894115]\n",
      "Reward buffer length =  56400\n",
      "Num timesteps: 56500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0803\n",
      "Last reward =  [-0.07279953]\n",
      "Reward buffer length =  56500\n",
      "Num timesteps: 56600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0705\n",
      "Last reward =  [-0.08899715]\n",
      "Reward buffer length =  56600\n",
      "Num timesteps: 56700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0594\n",
      "Last reward =  [-0.10108261]\n",
      "Reward buffer length =  56700\n",
      "Num timesteps: 56800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0758\n",
      "Last reward =  [-0.12272502]\n",
      "Reward buffer length =  56800\n",
      "Num timesteps: 56900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0840\n",
      "Last reward =  [-0.08219994]\n",
      "Reward buffer length =  56900\n",
      "Num timesteps: 57000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0940\n",
      "Last reward =  [-0.12520151]\n",
      "Reward buffer length =  57000\n",
      "Num timesteps: 57100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0832\n",
      "Last reward =  [-0.02101382]\n",
      "Reward buffer length =  57100\n",
      "Num timesteps: 57200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0897\n",
      "Last reward =  [-0.07433786]\n",
      "Reward buffer length =  57200\n",
      "Num timesteps: 57300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0359\n",
      "Last reward =  [-0.04793803]\n",
      "Reward buffer length =  57300\n",
      "Num timesteps: 57400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0760\n",
      "Last reward =  [-0.10025907]\n",
      "Reward buffer length =  57400\n",
      "Num timesteps: 57500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0801\n",
      "Last reward =  [-0.13230404]\n",
      "Reward buffer length =  57500\n",
      "Num timesteps: 57600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0901\n",
      "Last reward =  [-0.05539642]\n",
      "Reward buffer length =  57600\n",
      "Num timesteps: 57700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0789\n",
      "Last reward =  [-0.04893788]\n",
      "Reward buffer length =  57700\n",
      "Num timesteps: 57800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0784\n",
      "Last reward =  [-0.01046489]\n",
      "Reward buffer length =  57800\n",
      "Num timesteps: 57900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0815\n",
      "Last reward =  [-0.20927456]\n",
      "Reward buffer length =  57900\n",
      "Num timesteps: 58000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0897\n",
      "Last reward =  [-0.06666679]\n",
      "Reward buffer length =  58000\n",
      "Num timesteps: 58100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0576\n",
      "Last reward =  [0.15888156]\n",
      "Reward buffer length =  58100\n",
      "Num timesteps: 58200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0589\n",
      "Last reward =  [-0.05345801]\n",
      "Reward buffer length =  58200\n",
      "Num timesteps: 58300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0775\n",
      "Last reward =  [-0.11200414]\n",
      "Reward buffer length =  58300\n",
      "Num timesteps: 58400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0867\n",
      "Last reward =  [-0.14321437]\n",
      "Reward buffer length =  58400\n",
      "Num timesteps: 58500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0972\n",
      "Last reward =  [-0.1677036]\n",
      "Reward buffer length =  58500\n",
      "Num timesteps: 58600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0615\n",
      "Last reward =  [0.00562791]\n",
      "Reward buffer length =  58600\n",
      "Num timesteps: 58700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0105\n",
      "Last reward =  [-0.02153748]\n",
      "Reward buffer length =  58700\n",
      "Num timesteps: 58800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0306\n",
      "Last reward =  [-0.04304504]\n",
      "Reward buffer length =  58800\n",
      "Num timesteps: 58900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0456\n",
      "Last reward =  [-0.08128588]\n",
      "Reward buffer length =  58900\n",
      "Num timesteps: 59000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0348\n",
      "Last reward =  [-0.10237827]\n",
      "Reward buffer length =  59000\n",
      "Num timesteps: 59100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0684\n",
      "Last reward =  [-0.03335349]\n",
      "Reward buffer length =  59100\n",
      "Num timesteps: 59200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0764\n",
      "Last reward =  [-0.08201829]\n",
      "Reward buffer length =  59200\n",
      "Num timesteps: 59300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0850\n",
      "Last reward =  [-0.02104502]\n",
      "Reward buffer length =  59300\n",
      "Num timesteps: 59400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1036\n",
      "Last reward =  [-0.08902106]\n",
      "Reward buffer length =  59400\n",
      "Num timesteps: 59500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0903\n",
      "Last reward =  [-0.10673162]\n",
      "Reward buffer length =  59500\n",
      "Num timesteps: 59600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0871\n",
      "Last reward =  [-0.01223068]\n",
      "Reward buffer length =  59600\n",
      "Num timesteps: 59700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0369\n",
      "Last reward =  [-0.06493966]\n",
      "Reward buffer length =  59700\n",
      "Num timesteps: 59800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0494\n",
      "Last reward =  [-0.05105911]\n",
      "Reward buffer length =  59800\n",
      "Num timesteps: 59900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0414\n",
      "Last reward =  [-0.06499106]\n",
      "Reward buffer length =  59900\n",
      "Num timesteps: 60000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0745\n",
      "Last reward =  [-0.11168693]\n",
      "Reward buffer length =  60000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 60100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0779\n",
      "Last reward =  [-0.12538353]\n",
      "Reward buffer length =  60100\n",
      "Num timesteps: 60200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0870\n",
      "Last reward =  [-0.01541376]\n",
      "Reward buffer length =  60200\n",
      "Num timesteps: 60300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0930\n",
      "Last reward =  [-0.11747145]\n",
      "Reward buffer length =  60300\n",
      "Num timesteps: 60400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0868\n",
      "Last reward =  [0.01621546]\n",
      "Reward buffer length =  60400\n",
      "Num timesteps: 60500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1015\n",
      "Last reward =  [-0.01627925]\n",
      "Reward buffer length =  60500\n",
      "Num timesteps: 60600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0094\n",
      "Last reward =  [-0.02938408]\n",
      "Reward buffer length =  60600\n",
      "Num timesteps: 60700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0313\n",
      "Last reward =  [-0.04073698]\n",
      "Reward buffer length =  60700\n",
      "Num timesteps: 60800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0402\n",
      "Last reward =  [-0.02970847]\n",
      "Reward buffer length =  60800\n",
      "Num timesteps: 60900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0374\n",
      "Last reward =  [-0.09647519]\n",
      "Reward buffer length =  60900\n",
      "Num timesteps: 61000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0688\n",
      "Last reward =  [-0.10292163]\n",
      "Reward buffer length =  61000\n",
      "Num timesteps: 61100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0813\n",
      "Last reward =  [-0.13072778]\n",
      "Reward buffer length =  61100\n",
      "Num timesteps: 61200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0918\n",
      "Last reward =  [-0.0928411]\n",
      "Reward buffer length =  61200\n",
      "Num timesteps: 61300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1039\n",
      "Last reward =  [-0.14137954]\n",
      "Reward buffer length =  61300\n",
      "Num timesteps: 61400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0131\n",
      "Last reward =  [-0.01611058]\n",
      "Reward buffer length =  61400\n",
      "Num timesteps: 61500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0361\n",
      "Last reward =  [-0.04712755]\n",
      "Reward buffer length =  61500\n",
      "Num timesteps: 61600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0513\n",
      "Last reward =  [-0.02729126]\n",
      "Reward buffer length =  61600\n",
      "Num timesteps: 61700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0355\n",
      "Last reward =  [0.08931518]\n",
      "Reward buffer length =  61700\n",
      "Num timesteps: 61800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0721\n",
      "Last reward =  [-0.0729101]\n",
      "Reward buffer length =  61800\n",
      "Num timesteps: 61900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0827\n",
      "Last reward =  [0.01020634]\n",
      "Reward buffer length =  61900\n",
      "Num timesteps: 62000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0857\n",
      "Last reward =  [-0.14949504]\n",
      "Reward buffer length =  62000\n",
      "Num timesteps: 62100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0752\n",
      "Last reward =  [-0.0289865]\n",
      "Reward buffer length =  62100\n",
      "Num timesteps: 62200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0115\n",
      "Last reward =  [-0.02578089]\n",
      "Reward buffer length =  62200\n",
      "Num timesteps: 62300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0267\n",
      "Last reward =  [-0.04565364]\n",
      "Reward buffer length =  62300\n",
      "Num timesteps: 62400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0418\n",
      "Last reward =  [-0.10119273]\n",
      "Reward buffer length =  62400\n",
      "Num timesteps: 62500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0569\n",
      "Last reward =  [-0.10466003]\n",
      "Reward buffer length =  62500\n",
      "Num timesteps: 62600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0459\n",
      "Last reward =  [-0.11458014]\n",
      "Reward buffer length =  62600\n",
      "Num timesteps: 62700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0858\n",
      "Last reward =  [-0.06455398]\n",
      "Reward buffer length =  62700\n",
      "Num timesteps: 62800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0841\n",
      "Last reward =  [-0.04602999]\n",
      "Reward buffer length =  62800\n",
      "Num timesteps: 62900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0962\n",
      "Last reward =  [-0.09219364]\n",
      "Reward buffer length =  62900\n",
      "Num timesteps: 63000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0709\n",
      "Last reward =  [-0.07521316]\n",
      "Reward buffer length =  63000\n",
      "Num timesteps: 63100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0408\n",
      "Last reward =  [-0.06894003]\n",
      "Reward buffer length =  63100\n",
      "Num timesteps: 63200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0703\n",
      "Last reward =  [-0.14906214]\n",
      "Reward buffer length =  63200\n",
      "Num timesteps: 63300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0847\n",
      "Last reward =  [-0.08623597]\n",
      "Reward buffer length =  63300\n",
      "Num timesteps: 63400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0946\n",
      "Last reward =  [-0.09788078]\n",
      "Reward buffer length =  63400\n",
      "Num timesteps: 63500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1027\n",
      "Last reward =  [-0.1533729]\n",
      "Reward buffer length =  63500\n",
      "Num timesteps: 63600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0811\n",
      "Last reward =  [-0.02735098]\n",
      "Reward buffer length =  63600\n",
      "Num timesteps: 63700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0874\n",
      "Last reward =  [-0.10279988]\n",
      "Reward buffer length =  63700\n",
      "Num timesteps: 63800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0897\n",
      "Last reward =  [-0.10918193]\n",
      "Reward buffer length =  63800\n",
      "Num timesteps: 63900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1130\n",
      "Last reward =  [-0.1269662]\n",
      "Reward buffer length =  63900\n",
      "Num timesteps: 64000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1004\n",
      "Last reward =  [-0.01764613]\n",
      "Reward buffer length =  64000\n",
      "Num timesteps: 64100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0962\n",
      "Last reward =  [-0.06392661]\n",
      "Reward buffer length =  64100\n",
      "Num timesteps: 64200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0958\n",
      "Last reward =  [-0.094607]\n",
      "Reward buffer length =  64200\n",
      "Num timesteps: 64300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1057\n",
      "Last reward =  [-0.08946241]\n",
      "Reward buffer length =  64300\n",
      "Num timesteps: 64400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1106\n",
      "Last reward =  [-0.04415315]\n",
      "Reward buffer length =  64400\n",
      "Num timesteps: 64500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0430\n",
      "Last reward =  [-0.07583664]\n",
      "Reward buffer length =  64500\n",
      "Num timesteps: 64600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0765\n",
      "Last reward =  [-0.1465914]\n",
      "Reward buffer length =  64600\n",
      "Num timesteps: 64700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0855\n",
      "Last reward =  [-0.07283594]\n",
      "Reward buffer length =  64700\n",
      "Num timesteps: 64800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0992\n",
      "Last reward =  [-0.04827052]\n",
      "Reward buffer length =  64800\n",
      "Num timesteps: 64900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1113\n",
      "Last reward =  [-0.05734145]\n",
      "Reward buffer length =  64900\n",
      "Num timesteps: 65000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0424\n",
      "Last reward =  [-0.0334618]\n",
      "Reward buffer length =  65000\n",
      "Num timesteps: 65100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0570\n",
      "Last reward =  [0.15096436]\n",
      "Reward buffer length =  65100\n",
      "Num timesteps: 65200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0548\n",
      "Last reward =  [-0.04919201]\n",
      "Reward buffer length =  65200\n",
      "Num timesteps: 65300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0897\n",
      "Last reward =  [-0.04959281]\n",
      "Reward buffer length =  65300\n",
      "Num timesteps: 65400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0928\n",
      "Last reward =  [-0.08452331]\n",
      "Reward buffer length =  65400\n",
      "Num timesteps: 65500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1024\n",
      "Last reward =  [-0.22273475]\n",
      "Reward buffer length =  65500\n",
      "Num timesteps: 65600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0677\n",
      "Last reward =  [-0.02195861]\n",
      "Reward buffer length =  65600\n",
      "Num timesteps: 65700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0538\n",
      "Last reward =  [-0.0866814]\n",
      "Reward buffer length =  65700\n",
      "Num timesteps: 65800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0466\n",
      "Last reward =  [-0.09470654]\n",
      "Reward buffer length =  65800\n",
      "Num timesteps: 65900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0810\n",
      "Last reward =  [-0.08931717]\n",
      "Reward buffer length =  65900\n",
      "Num timesteps: 66000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0911\n",
      "Last reward =  [-0.12423985]\n",
      "Reward buffer length =  66000\n",
      "Num timesteps: 66100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0983\n",
      "Last reward =  [-0.14711434]\n",
      "Reward buffer length =  66100\n",
      "Num timesteps: 66200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1075\n",
      "Last reward =  [-0.07027325]\n",
      "Reward buffer length =  66200\n",
      "Num timesteps: 66300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0915\n",
      "Last reward =  [-0.0172207]\n",
      "Reward buffer length =  66300\n",
      "Num timesteps: 66400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0974\n",
      "Last reward =  [-0.15260968]\n",
      "Reward buffer length =  66400\n",
      "Num timesteps: 66500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1141\n",
      "Last reward =  [-0.09071691]\n",
      "Reward buffer length =  66500\n",
      "Num timesteps: 66600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1216\n",
      "Last reward =  [-0.0108404]\n",
      "Reward buffer length =  66600\n",
      "Num timesteps: 66700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0180\n",
      "Last reward =  [-0.04516377]\n",
      "Reward buffer length =  66700\n",
      "Num timesteps: 66800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0428\n",
      "Last reward =  [-0.08233155]\n",
      "Reward buffer length =  66800\n",
      "Num timesteps: 66900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0563\n",
      "Last reward =  [-0.0698129]\n",
      "Reward buffer length =  66900\n",
      "Num timesteps: 67000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0428\n",
      "Last reward =  [0.04906355]\n",
      "Reward buffer length =  67000\n",
      "Num timesteps: 67100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0876\n",
      "Last reward =  [-0.07803924]\n",
      "Reward buffer length =  67100\n",
      "Num timesteps: 67200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0933\n",
      "Last reward =  [-0.14333615]\n",
      "Reward buffer length =  67200\n",
      "Num timesteps: 67300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1006\n",
      "Last reward =  [-0.13800041]\n",
      "Reward buffer length =  67300\n",
      "Num timesteps: 67400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1151\n",
      "Last reward =  [-0.11618591]\n",
      "Reward buffer length =  67400\n",
      "Num timesteps: 67500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0544\n",
      "Last reward =  [-0.12965222]\n",
      "Reward buffer length =  67500\n",
      "Num timesteps: 67600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0961\n",
      "Last reward =  [-0.09021179]\n",
      "Reward buffer length =  67600\n",
      "Num timesteps: 67700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0952\n",
      "Last reward =  [-0.04990059]\n",
      "Reward buffer length =  67700\n",
      "Num timesteps: 67800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1112\n",
      "Last reward =  [-0.12870444]\n",
      "Reward buffer length =  67800\n",
      "Num timesteps: 67900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0986\n",
      "Last reward =  [-0.13071327]\n",
      "Reward buffer length =  67900\n",
      "Num timesteps: 68000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0980\n",
      "Last reward =  [-0.01190595]\n",
      "Reward buffer length =  68000\n",
      "Num timesteps: 68100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0948\n",
      "Last reward =  [-0.18626101]\n",
      "Reward buffer length =  68100\n",
      "Num timesteps: 68200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1056\n",
      "Last reward =  [-0.14321393]\n",
      "Reward buffer length =  68200\n",
      "Num timesteps: 68300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1217\n",
      "Last reward =  [-0.22757016]\n",
      "Reward buffer length =  68300\n",
      "Num timesteps: 68400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1128\n",
      "Last reward =  [-0.11305177]\n",
      "Reward buffer length =  68400\n",
      "Num timesteps: 68500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0981\n",
      "Last reward =  [-0.10350414]\n",
      "Reward buffer length =  68500\n",
      "Num timesteps: 68600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1103\n",
      "Last reward =  [-0.13519514]\n",
      "Reward buffer length =  68600\n",
      "Num timesteps: 68700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0892\n",
      "Last reward =  [-0.02495294]\n",
      "Reward buffer length =  68700\n",
      "Num timesteps: 68800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0500\n",
      "Last reward =  [-0.04725508]\n",
      "Reward buffer length =  68800\n",
      "Num timesteps: 68900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0572\n",
      "Last reward =  [-0.00471899]\n",
      "Reward buffer length =  68900\n",
      "Num timesteps: 69000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0576\n",
      "Last reward =  [-0.07915003]\n",
      "Reward buffer length =  69000\n",
      "Num timesteps: 69100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0961\n",
      "Last reward =  [-0.08225133]\n",
      "Reward buffer length =  69100\n",
      "Num timesteps: 69200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1009\n",
      "Last reward =  [-0.05376324]\n",
      "Reward buffer length =  69200\n",
      "Num timesteps: 69300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1144\n",
      "Last reward =  [-0.12473089]\n",
      "Reward buffer length =  69300\n",
      "Num timesteps: 69400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0962\n",
      "Last reward =  [-0.07444375]\n",
      "Reward buffer length =  69400\n",
      "Num timesteps: 69500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0462\n",
      "Last reward =  [-0.06031318]\n",
      "Reward buffer length =  69500\n",
      "Num timesteps: 69600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0838\n",
      "Last reward =  [-0.08359903]\n",
      "Reward buffer length =  69600\n",
      "Num timesteps: 69700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0991\n",
      "Last reward =  [-0.03546518]\n",
      "Reward buffer length =  69700\n",
      "Num timesteps: 69800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1070\n",
      "Last reward =  [-0.14304186]\n",
      "Reward buffer length =  69800\n",
      "Num timesteps: 69900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1261\n",
      "Last reward =  [-0.18689492]\n",
      "Reward buffer length =  69900\n",
      "Num timesteps: 70000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0538\n",
      "Last reward =  [-0.041039]\n",
      "Reward buffer length =  70000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 70100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0597\n",
      "Last reward =  [0.12442627]\n",
      "Reward buffer length =  70100\n",
      "Num timesteps: 70200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0689\n",
      "Last reward =  [-0.17028861]\n",
      "Reward buffer length =  70200\n",
      "Num timesteps: 70300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1010\n",
      "Last reward =  [-0.04767414]\n",
      "Reward buffer length =  70300\n",
      "Num timesteps: 70400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1086\n",
      "Last reward =  [-0.18466748]\n",
      "Reward buffer length =  70400\n",
      "Num timesteps: 70500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1197\n",
      "Last reward =  [-0.16227148]\n",
      "Reward buffer length =  70500\n",
      "Num timesteps: 70600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0721\n",
      "Last reward =  [-0.01897831]\n",
      "Reward buffer length =  70600\n",
      "Num timesteps: 70700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0890\n",
      "Last reward =  [-0.10079184]\n",
      "Reward buffer length =  70700\n",
      "Num timesteps: 70800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0983\n",
      "Last reward =  [-0.05952714]\n",
      "Reward buffer length =  70800\n",
      "Num timesteps: 70900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1099\n",
      "Last reward =  [-0.03127243]\n",
      "Reward buffer length =  70900\n",
      "Num timesteps: 71000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1296\n",
      "Last reward =  [-0.08419823]\n",
      "Reward buffer length =  71000\n",
      "Num timesteps: 71100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0518\n",
      "Last reward =  [-0.07867739]\n",
      "Reward buffer length =  71100\n",
      "Num timesteps: 71200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0579\n",
      "Last reward =  [-0.06583639]\n",
      "Reward buffer length =  71200\n",
      "Num timesteps: 71300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0774\n",
      "Last reward =  [-0.05530933]\n",
      "Reward buffer length =  71300\n",
      "Num timesteps: 71400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1017\n",
      "Last reward =  [-0.14208981]\n",
      "Reward buffer length =  71400\n",
      "Num timesteps: 71500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1075\n",
      "Last reward =  [-0.05137984]\n",
      "Reward buffer length =  71500\n",
      "Num timesteps: 71600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1246\n",
      "Last reward =  [-0.1433163]\n",
      "Reward buffer length =  71600\n",
      "Num timesteps: 71700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0570\n",
      "Last reward =  [-0.07107955]\n",
      "Reward buffer length =  71700\n",
      "Num timesteps: 71800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0502\n",
      "Last reward =  [-0.02529056]\n",
      "Reward buffer length =  71800\n",
      "Num timesteps: 71900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0624\n",
      "Last reward =  [-0.11141266]\n",
      "Reward buffer length =  71900\n",
      "Num timesteps: 72000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0674\n",
      "Last reward =  [-0.08558779]\n",
      "Reward buffer length =  72000\n",
      "Num timesteps: 72100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0979\n",
      "Last reward =  [-0.13741909]\n",
      "Reward buffer length =  72100\n",
      "Num timesteps: 72200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1016\n",
      "Last reward =  [-0.02077299]\n",
      "Reward buffer length =  72200\n",
      "Num timesteps: 72300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1130\n",
      "Last reward =  [-0.14138418]\n",
      "Reward buffer length =  72300\n",
      "Num timesteps: 72400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0502\n",
      "Last reward =  [-0.0369702]\n",
      "Reward buffer length =  72400\n",
      "Num timesteps: 72500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0507\n",
      "Last reward =  [-0.07274938]\n",
      "Reward buffer length =  72500\n",
      "Num timesteps: 72600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0606\n",
      "Last reward =  [-0.00177716]\n",
      "Reward buffer length =  72600\n",
      "Num timesteps: 72700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0596\n",
      "Last reward =  [-0.14307399]\n",
      "Reward buffer length =  72700\n",
      "Num timesteps: 72800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0978\n",
      "Last reward =  [-0.12007017]\n",
      "Reward buffer length =  72800\n",
      "Num timesteps: 72900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1015\n",
      "Last reward =  [-0.04177887]\n",
      "Reward buffer length =  72900\n",
      "Num timesteps: 73000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1127\n",
      "Last reward =  [-0.22290102]\n",
      "Reward buffer length =  73000\n",
      "Num timesteps: 73100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1024\n",
      "Last reward =  [-0.07201163]\n",
      "Reward buffer length =  73100\n",
      "Num timesteps: 73200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0256\n",
      "Last reward =  [-0.09400578]\n",
      "Reward buffer length =  73200\n",
      "Num timesteps: 73300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0521\n",
      "Last reward =  [-0.04667721]\n",
      "Reward buffer length =  73300\n",
      "Num timesteps: 73400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0636\n",
      "Last reward =  [-0.032435]\n",
      "Reward buffer length =  73400\n",
      "Num timesteps: 73500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0622\n",
      "Last reward =  [-0.08671295]\n",
      "Reward buffer length =  73500\n",
      "Num timesteps: 73600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1030\n",
      "Last reward =  [-0.10839043]\n",
      "Reward buffer length =  73600\n",
      "Num timesteps: 73700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0992\n",
      "Last reward =  [-0.16530788]\n",
      "Reward buffer length =  73700\n",
      "Num timesteps: 73800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1168\n",
      "Last reward =  [-0.11591855]\n",
      "Reward buffer length =  73800\n",
      "Num timesteps: 73900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1114\n",
      "Last reward =  [-0.00939681]\n",
      "Reward buffer length =  73900\n",
      "Num timesteps: 74000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0216\n",
      "Last reward =  [-0.06636859]\n",
      "Reward buffer length =  74000\n",
      "Num timesteps: 74100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0550\n",
      "Last reward =  [-0.05178]\n",
      "Reward buffer length =  74100\n",
      "Num timesteps: 74200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0626\n",
      "Last reward =  [-0.07414772]\n",
      "Reward buffer length =  74200\n",
      "Num timesteps: 74300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0630\n",
      "Last reward =  [-0.08884966]\n",
      "Reward buffer length =  74300\n",
      "Num timesteps: 74400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0994\n",
      "Last reward =  [-0.11098723]\n",
      "Reward buffer length =  74400\n",
      "Num timesteps: 74500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0951\n",
      "Last reward =  [-0.08704957]\n",
      "Reward buffer length =  74500\n",
      "Num timesteps: 74600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1102\n",
      "Last reward =  [-0.15698634]\n",
      "Reward buffer length =  74600\n",
      "Num timesteps: 74700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1449\n",
      "Last reward =  [-0.15863612]\n",
      "Reward buffer length =  74700\n",
      "Num timesteps: 74800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1140\n",
      "Last reward =  [-0.14538229]\n",
      "Reward buffer length =  74800\n",
      "Num timesteps: 74900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1163\n",
      "Last reward =  [-0.05975294]\n",
      "Reward buffer length =  74900\n",
      "Num timesteps: 75000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0910\n",
      "Last reward =  [-0.1427571]\n",
      "Reward buffer length =  75000\n",
      "Num timesteps: 75100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1030\n",
      "Last reward =  [-0.10612349]\n",
      "Reward buffer length =  75100\n",
      "Num timesteps: 75200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1114\n",
      "Last reward =  [-0.12688124]\n",
      "Reward buffer length =  75200\n",
      "Num timesteps: 75300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1289\n",
      "Last reward =  [-0.26517755]\n",
      "Reward buffer length =  75300\n",
      "Num timesteps: 75400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1086\n",
      "Last reward =  [-0.10794497]\n",
      "Reward buffer length =  75400\n",
      "Num timesteps: 75500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1052\n",
      "Last reward =  [-0.20669994]\n",
      "Reward buffer length =  75500\n",
      "Num timesteps: 75600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1075\n",
      "Last reward =  [-0.05322619]\n",
      "Reward buffer length =  75600\n",
      "Num timesteps: 75700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1351\n",
      "Last reward =  [-0.03260734]\n",
      "Reward buffer length =  75700\n",
      "Num timesteps: 75800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1181\n",
      "Last reward =  [-0.15850185]\n",
      "Reward buffer length =  75800\n",
      "Num timesteps: 75900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1274\n",
      "Last reward =  [-0.1090469]\n",
      "Reward buffer length =  75900\n",
      "Num timesteps: 76000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1429\n",
      "Last reward =  [-0.01154225]\n",
      "Reward buffer length =  76000\n",
      "Num timesteps: 76100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1116\n",
      "Last reward =  [-0.17951207]\n",
      "Reward buffer length =  76100\n",
      "Num timesteps: 76200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1285\n",
      "Last reward =  [0.11569735]\n",
      "Reward buffer length =  76200\n",
      "Num timesteps: 76300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0762\n",
      "Last reward =  [-0.18873338]\n",
      "Reward buffer length =  76300\n",
      "Num timesteps: 76400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1026\n",
      "Last reward =  [-0.06392135]\n",
      "Reward buffer length =  76400\n",
      "Num timesteps: 76500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1153\n",
      "Last reward =  [-0.14015718]\n",
      "Reward buffer length =  76500\n",
      "Num timesteps: 76600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1251\n",
      "Last reward =  [-0.19327547]\n",
      "Reward buffer length =  76600\n",
      "Num timesteps: 76700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0531\n",
      "Last reward =  [0.03937548]\n",
      "Reward buffer length =  76700\n",
      "Num timesteps: 76800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0469\n",
      "Last reward =  [-0.07864837]\n",
      "Reward buffer length =  76800\n",
      "Num timesteps: 76900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0643\n",
      "Last reward =  [-0.0048187]\n",
      "Reward buffer length =  76900\n",
      "Num timesteps: 77000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0539\n",
      "Last reward =  [-0.1273284]\n",
      "Reward buffer length =  77000\n",
      "Num timesteps: 77100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0994\n",
      "Last reward =  [-0.04986022]\n",
      "Reward buffer length =  77100\n",
      "Num timesteps: 77200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1028\n",
      "Last reward =  [-0.10462645]\n",
      "Reward buffer length =  77200\n",
      "Num timesteps: 77300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1129\n",
      "Last reward =  [-0.06561397]\n",
      "Reward buffer length =  77300\n",
      "Num timesteps: 77400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1388\n",
      "Last reward =  [-0.05714442]\n",
      "Reward buffer length =  77400\n",
      "Num timesteps: 77500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1149\n",
      "Last reward =  [-0.0585359]\n",
      "Reward buffer length =  77500\n",
      "Num timesteps: 77600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1245\n",
      "Last reward =  [-0.22681585]\n",
      "Reward buffer length =  77600\n",
      "Num timesteps: 77700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0514\n",
      "Last reward =  [-0.0559188]\n",
      "Reward buffer length =  77700\n",
      "Num timesteps: 77800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0562\n",
      "Last reward =  [-0.07027524]\n",
      "Reward buffer length =  77800\n",
      "Num timesteps: 77900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0659\n",
      "Last reward =  [-0.07161076]\n",
      "Reward buffer length =  77900\n",
      "Num timesteps: 78000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0607\n",
      "Last reward =  [-0.0482001]\n",
      "Reward buffer length =  78000\n",
      "Num timesteps: 78100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1024\n",
      "Last reward =  [-0.05497932]\n",
      "Reward buffer length =  78100\n",
      "Num timesteps: 78200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1018\n",
      "Last reward =  [-0.11045431]\n",
      "Reward buffer length =  78200\n",
      "Num timesteps: 78300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1247\n",
      "Last reward =  [-0.18813601]\n",
      "Reward buffer length =  78300\n",
      "Num timesteps: 78400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0763\n",
      "Last reward =  [-0.03015432]\n",
      "Reward buffer length =  78400\n",
      "Num timesteps: 78500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0108\n",
      "Last reward =  [-0.03283719]\n",
      "Reward buffer length =  78500\n",
      "Num timesteps: 78600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0359\n",
      "Last reward =  [-0.06085997]\n",
      "Reward buffer length =  78600\n",
      "Num timesteps: 78700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0582\n",
      "Last reward =  [-0.12466433]\n",
      "Reward buffer length =  78700\n",
      "Num timesteps: 78800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0670\n",
      "Last reward =  [-0.15149902]\n",
      "Reward buffer length =  78800\n",
      "Num timesteps: 78900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0710\n",
      "Last reward =  [-0.16004187]\n",
      "Reward buffer length =  78900\n",
      "Num timesteps: 79000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1046\n",
      "Last reward =  [-0.07544304]\n",
      "Reward buffer length =  79000\n",
      "Num timesteps: 79100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1128\n",
      "Last reward =  [-0.07723503]\n",
      "Reward buffer length =  79100\n",
      "Num timesteps: 79200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1216\n",
      "Last reward =  [-0.18390389]\n",
      "Reward buffer length =  79200\n",
      "Num timesteps: 79300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0669\n",
      "Last reward =  [0.00615144]\n",
      "Reward buffer length =  79300\n",
      "Num timesteps: 79400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0521\n",
      "Last reward =  [-0.04485431]\n",
      "Reward buffer length =  79400\n",
      "Num timesteps: 79500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0682\n",
      "Last reward =  [-0.10338405]\n",
      "Reward buffer length =  79500\n",
      "Num timesteps: 79600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0601\n",
      "Last reward =  [-0.06320414]\n",
      "Reward buffer length =  79600\n",
      "Num timesteps: 79700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1017\n",
      "Last reward =  [-0.02753746]\n",
      "Reward buffer length =  79700\n",
      "Num timesteps: 79800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1025\n",
      "Last reward =  [-0.05929462]\n",
      "Reward buffer length =  79800\n",
      "Num timesteps: 79900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1162\n",
      "Last reward =  [0.01257489]\n",
      "Reward buffer length =  79900\n",
      "Num timesteps: 80000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1264\n",
      "Last reward =  [-0.1378396]\n",
      "Reward buffer length =  80000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 80100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0736\n",
      "Last reward =  [-0.10579836]\n",
      "Reward buffer length =  80100\n",
      "Num timesteps: 80200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0751\n",
      "Last reward =  [-0.1349929]\n",
      "Reward buffer length =  80200\n",
      "Num timesteps: 80300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1053\n",
      "Last reward =  [-0.03438937]\n",
      "Reward buffer length =  80300\n",
      "Num timesteps: 80400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1202\n",
      "Last reward =  [-0.23434658]\n",
      "Reward buffer length =  80400\n",
      "Num timesteps: 80500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1176\n",
      "Last reward =  [-0.06918494]\n",
      "Reward buffer length =  80500\n",
      "Num timesteps: 80600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0918\n",
      "Last reward =  [-0.05146569]\n",
      "Reward buffer length =  80600\n",
      "Num timesteps: 80700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0875\n",
      "Last reward =  [-0.04302435]\n",
      "Reward buffer length =  80700\n",
      "Num timesteps: 80800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1051\n",
      "Last reward =  [-0.17767473]\n",
      "Reward buffer length =  80800\n",
      "Num timesteps: 80900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1229\n",
      "Last reward =  [-0.18829308]\n",
      "Reward buffer length =  80900\n",
      "Num timesteps: 81000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1236\n",
      "Last reward =  [-0.09440203]\n",
      "Reward buffer length =  81000\n",
      "Num timesteps: 81100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1210\n",
      "Last reward =  [-0.16500834]\n",
      "Reward buffer length =  81100\n",
      "Num timesteps: 81200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1297\n",
      "Last reward =  [-0.20362747]\n",
      "Reward buffer length =  81200\n",
      "Num timesteps: 81300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1349\n",
      "Last reward =  [-0.04400464]\n",
      "Reward buffer length =  81300\n",
      "Num timesteps: 81400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1269\n",
      "Last reward =  [-0.24244873]\n",
      "Reward buffer length =  81400\n",
      "Num timesteps: 81500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1361\n",
      "Last reward =  [-0.00583199]\n",
      "Reward buffer length =  81500\n",
      "Num timesteps: 81600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0151\n",
      "Last reward =  [-0.03003671]\n",
      "Reward buffer length =  81600\n",
      "Num timesteps: 81700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0415\n",
      "Last reward =  [-0.06339166]\n",
      "Reward buffer length =  81700\n",
      "Num timesteps: 81800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0630\n",
      "Last reward =  [-0.06452575]\n",
      "Reward buffer length =  81800\n",
      "Num timesteps: 81900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0641\n",
      "Last reward =  [0.1172239]\n",
      "Reward buffer length =  81900\n",
      "Num timesteps: 82000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0951\n",
      "Last reward =  [-0.08137634]\n",
      "Reward buffer length =  82000\n",
      "Num timesteps: 82100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1082\n",
      "Last reward =  [-0.15557685]\n",
      "Reward buffer length =  82100\n",
      "Num timesteps: 82200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1284\n",
      "Last reward =  [-0.1966171]\n",
      "Reward buffer length =  82200\n",
      "Num timesteps: 82300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1288\n",
      "Last reward =  [-0.26898193]\n",
      "Reward buffer length =  82300\n",
      "Num timesteps: 82400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1207\n",
      "Last reward =  [-0.1514946]\n",
      "Reward buffer length =  82400\n",
      "Num timesteps: 82500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1115\n",
      "Last reward =  [-0.14446229]\n",
      "Reward buffer length =  82500\n",
      "Num timesteps: 82600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1315\n",
      "Last reward =  [-0.0408709]\n",
      "Reward buffer length =  82600\n",
      "Num timesteps: 82700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1380\n",
      "Last reward =  [-0.14537275]\n",
      "Reward buffer length =  82700\n",
      "Num timesteps: 82800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1081\n",
      "Last reward =  [-0.16492178]\n",
      "Reward buffer length =  82800\n",
      "Num timesteps: 82900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1121\n",
      "Last reward =  [-0.10085136]\n",
      "Reward buffer length =  82900\n",
      "Num timesteps: 83000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1300\n",
      "Last reward =  [-0.04031699]\n",
      "Reward buffer length =  83000\n",
      "Num timesteps: 83100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1303\n",
      "Last reward =  [0.05241996]\n",
      "Reward buffer length =  83100\n",
      "Num timesteps: 83200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0275\n",
      "Last reward =  [-0.05086288]\n",
      "Reward buffer length =  83200\n",
      "Num timesteps: 83300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0615\n",
      "Last reward =  [-0.04279872]\n",
      "Reward buffer length =  83300\n",
      "Num timesteps: 83400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0705\n",
      "Last reward =  [-0.07919691]\n",
      "Reward buffer length =  83400\n",
      "Num timesteps: 83500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0738\n",
      "Last reward =  [-0.18141139]\n",
      "Reward buffer length =  83500\n",
      "Num timesteps: 83600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1061\n",
      "Last reward =  [-0.10474304]\n",
      "Reward buffer length =  83600\n",
      "Num timesteps: 83700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1242\n",
      "Last reward =  [-0.14820844]\n",
      "Reward buffer length =  83700\n",
      "Num timesteps: 83800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1385\n",
      "Last reward =  [-0.19862504]\n",
      "Reward buffer length =  83800\n",
      "Num timesteps: 83900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1414\n",
      "Last reward =  [-0.11694802]\n",
      "Reward buffer length =  83900\n",
      "Num timesteps: 84000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1319\n",
      "Last reward =  [-0.26600856]\n",
      "Reward buffer length =  84000\n",
      "Num timesteps: 84100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1460\n",
      "Last reward =  [-0.10355978]\n",
      "Reward buffer length =  84100\n",
      "Num timesteps: 84200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1337\n",
      "Last reward =  [-0.066599]\n",
      "Reward buffer length =  84200\n",
      "Num timesteps: 84300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1366\n",
      "Last reward =  [-0.15530424]\n",
      "Reward buffer length =  84300\n",
      "Num timesteps: 84400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1481\n",
      "Last reward =  [-0.17252211]\n",
      "Reward buffer length =  84400\n",
      "Num timesteps: 84500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1281\n",
      "Last reward =  [-0.04686272]\n",
      "Reward buffer length =  84500\n",
      "Num timesteps: 84600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0506\n",
      "Last reward =  [-0.09278386]\n",
      "Reward buffer length =  84600\n",
      "Num timesteps: 84700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0662\n",
      "Last reward =  [-0.09559394]\n",
      "Reward buffer length =  84700\n",
      "Num timesteps: 84800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0654\n",
      "Last reward =  [0.01547345]\n",
      "Reward buffer length =  84800\n",
      "Num timesteps: 84900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1056\n",
      "Last reward =  [-0.09594657]\n",
      "Reward buffer length =  84900\n",
      "Num timesteps: 85000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1202\n",
      "Last reward =  [-0.13812259]\n",
      "Reward buffer length =  85000\n",
      "Num timesteps: 85100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1315\n",
      "Last reward =  [-0.14197145]\n",
      "Reward buffer length =  85100\n",
      "Num timesteps: 85200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1467\n",
      "Last reward =  [-0.03266583]\n",
      "Reward buffer length =  85200\n",
      "Num timesteps: 85300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0138\n",
      "Last reward =  [-0.0434938]\n",
      "Reward buffer length =  85300\n",
      "Num timesteps: 85400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0414\n",
      "Last reward =  [-0.07044696]\n",
      "Reward buffer length =  85400\n",
      "Num timesteps: 85500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0649\n",
      "Last reward =  [-0.13844125]\n",
      "Reward buffer length =  85500\n",
      "Num timesteps: 85600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0786\n",
      "Last reward =  [-0.14582428]\n",
      "Reward buffer length =  85600\n",
      "Num timesteps: 85700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0807\n",
      "Last reward =  [-0.17790702]\n",
      "Reward buffer length =  85700\n",
      "Num timesteps: 85800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1147\n",
      "Last reward =  [-0.06958702]\n",
      "Reward buffer length =  85800\n",
      "Num timesteps: 85900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1286\n",
      "Last reward =  [-0.10833234]\n",
      "Reward buffer length =  85900\n",
      "Num timesteps: 86000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1352\n",
      "Last reward =  [-0.10784192]\n",
      "Reward buffer length =  86000\n",
      "Num timesteps: 86100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1043\n",
      "Last reward =  [-0.10043785]\n",
      "Reward buffer length =  86100\n",
      "Num timesteps: 86200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0667\n",
      "Last reward =  [-0.05713448]\n",
      "Reward buffer length =  86200\n",
      "Num timesteps: 86300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1056\n",
      "Last reward =  [-0.05658936]\n",
      "Reward buffer length =  86300\n",
      "Num timesteps: 86400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1209\n",
      "Last reward =  [-0.06375061]\n",
      "Reward buffer length =  86400\n",
      "Num timesteps: 86500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1337\n",
      "Last reward =  [-0.27062693]\n",
      "Reward buffer length =  86500\n",
      "Num timesteps: 86600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1486\n",
      "Last reward =  [-0.2553161]\n",
      "Reward buffer length =  86600\n",
      "Num timesteps: 86700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1224\n",
      "Last reward =  [-0.1422707]\n",
      "Reward buffer length =  86700\n",
      "Num timesteps: 86800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1341\n",
      "Last reward =  [-0.09234003]\n",
      "Reward buffer length =  86800\n",
      "Num timesteps: 86900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1401\n",
      "Last reward =  [-0.26476532]\n",
      "Reward buffer length =  86900\n",
      "Num timesteps: 87000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1113\n",
      "Last reward =  [-0.1417805]\n",
      "Reward buffer length =  87000\n",
      "Num timesteps: 87100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1196\n",
      "Last reward =  [-0.1923433]\n",
      "Reward buffer length =  87100\n",
      "Num timesteps: 87200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1368\n",
      "Last reward =  [-0.22385375]\n",
      "Reward buffer length =  87200\n",
      "Num timesteps: 87300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1373\n",
      "Last reward =  [-0.13922216]\n",
      "Reward buffer length =  87300\n",
      "Num timesteps: 87400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0913\n",
      "Last reward =  [-0.08938917]\n",
      "Reward buffer length =  87400\n",
      "Num timesteps: 87500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0700\n",
      "Last reward =  [-0.09827235]\n",
      "Reward buffer length =  87500\n",
      "Num timesteps: 87600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1135\n",
      "Last reward =  [-0.16115677]\n",
      "Reward buffer length =  87600\n",
      "Num timesteps: 87700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1206\n",
      "Last reward =  [0.01648441]\n",
      "Reward buffer length =  87700\n",
      "Num timesteps: 87800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1352\n",
      "Last reward =  [-0.08908832]\n",
      "Reward buffer length =  87800\n",
      "Num timesteps: 87900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1364\n",
      "Last reward =  [0.0414118]\n",
      "Reward buffer length =  87900\n",
      "Num timesteps: 88000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0233\n",
      "Last reward =  [0.03148811]\n",
      "Reward buffer length =  88000\n",
      "Num timesteps: 88100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0582\n",
      "Last reward =  [-0.0069774]\n",
      "Reward buffer length =  88100\n",
      "Num timesteps: 88200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0772\n",
      "Last reward =  [-0.0254979]\n",
      "Reward buffer length =  88200\n",
      "Num timesteps: 88300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0723\n",
      "Last reward =  [-0.16061813]\n",
      "Reward buffer length =  88300\n",
      "Num timesteps: 88400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1142\n",
      "Last reward =  [-0.03647203]\n",
      "Reward buffer length =  88400\n",
      "Num timesteps: 88500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1266\n",
      "Last reward =  [-0.05085259]\n",
      "Reward buffer length =  88500\n",
      "Num timesteps: 88600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1403\n",
      "Last reward =  [-0.16914274]\n",
      "Reward buffer length =  88600\n",
      "Num timesteps: 88700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1433\n",
      "Last reward =  [-0.02249241]\n",
      "Reward buffer length =  88700\n",
      "Num timesteps: 88800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0731\n",
      "Last reward =  [-0.15779857]\n",
      "Reward buffer length =  88800\n",
      "Num timesteps: 88900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1112\n",
      "Last reward =  [-0.03613855]\n",
      "Reward buffer length =  88900\n",
      "Num timesteps: 89000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1226\n",
      "Last reward =  [-0.04390506]\n",
      "Reward buffer length =  89000\n",
      "Num timesteps: 89100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1346\n",
      "Last reward =  [-0.15471731]\n",
      "Reward buffer length =  89100\n",
      "Num timesteps: 89200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1325\n",
      "Last reward =  [-0.03160415]\n",
      "Reward buffer length =  89200\n",
      "Num timesteps: 89300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0673\n",
      "Last reward =  [-0.06767632]\n",
      "Reward buffer length =  89300\n",
      "Num timesteps: 89400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0863\n",
      "Last reward =  [-0.0506608]\n",
      "Reward buffer length =  89400\n",
      "Num timesteps: 89500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0865\n",
      "Last reward =  [-0.12292468]\n",
      "Reward buffer length =  89500\n",
      "Num timesteps: 89600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1267\n",
      "Last reward =  [-0.28614992]\n",
      "Reward buffer length =  89600\n",
      "Num timesteps: 89700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1331\n",
      "Last reward =  [-0.25059682]\n",
      "Reward buffer length =  89700\n",
      "Num timesteps: 89800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1526\n",
      "Last reward =  [-0.34436128]\n",
      "Reward buffer length =  89800\n",
      "Num timesteps: 89900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1150\n",
      "Last reward =  [-0.1539834]\n",
      "Reward buffer length =  89900\n",
      "Num timesteps: 90000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1187\n",
      "Last reward =  [-0.1396077]\n",
      "Reward buffer length =  90000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 90100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1317\n",
      "Last reward =  [-0.3060621]\n",
      "Reward buffer length =  90100\n",
      "Num timesteps: 90200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1409\n",
      "Last reward =  [-0.2269144]\n",
      "Reward buffer length =  90200\n",
      "Num timesteps: 90300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1579\n",
      "Last reward =  [-0.16608422]\n",
      "Reward buffer length =  90300\n",
      "Num timesteps: 90400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1643\n",
      "Last reward =  [-0.3401415]\n",
      "Reward buffer length =  90400\n",
      "Num timesteps: 90500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1331\n",
      "Last reward =  [-0.15321271]\n",
      "Reward buffer length =  90500\n",
      "Num timesteps: 90600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1364\n",
      "Last reward =  [0.01156986]\n",
      "Reward buffer length =  90600\n",
      "Num timesteps: 90700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1597\n",
      "Last reward =  [-0.28201684]\n",
      "Reward buffer length =  90700\n",
      "Num timesteps: 90800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0805\n",
      "Last reward =  [-0.04858798]\n",
      "Reward buffer length =  90800\n",
      "Num timesteps: 90900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1158\n",
      "Last reward =  [-0.05997245]\n",
      "Reward buffer length =  90900\n",
      "Num timesteps: 91000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1270\n",
      "Last reward =  [-0.07965804]\n",
      "Reward buffer length =  91000\n",
      "Num timesteps: 91100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1334\n",
      "Last reward =  [-0.29290318]\n",
      "Reward buffer length =  91100\n",
      "Num timesteps: 91200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1593\n",
      "Last reward =  [-0.27839234]\n",
      "Reward buffer length =  91200\n",
      "Num timesteps: 91300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0127\n",
      "Last reward =  [-0.00493577]\n",
      "Reward buffer length =  91300\n",
      "Num timesteps: 91400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0343\n",
      "Last reward =  [-0.04598494]\n",
      "Reward buffer length =  91400\n",
      "Num timesteps: 91500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0676\n",
      "Last reward =  [-0.07702689]\n",
      "Reward buffer length =  91500\n",
      "Num timesteps: 91600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0871\n",
      "Last reward =  [-0.10507848]\n",
      "Reward buffer length =  91600\n",
      "Num timesteps: 91700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0875\n",
      "Last reward =  [-0.08601019]\n",
      "Reward buffer length =  91700\n",
      "Num timesteps: 91800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1233\n",
      "Last reward =  [-0.14812712]\n",
      "Reward buffer length =  91800\n",
      "Num timesteps: 91900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1345\n",
      "Last reward =  [-0.19519092]\n",
      "Reward buffer length =  91900\n",
      "Num timesteps: 92000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1491\n",
      "Last reward =  [-0.15438022]\n",
      "Reward buffer length =  92000\n",
      "Num timesteps: 92100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1269\n",
      "Last reward =  [-0.08794551]\n",
      "Reward buffer length =  92100\n",
      "Num timesteps: 92200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0697\n",
      "Last reward =  [-0.00731181]\n",
      "Reward buffer length =  92200\n",
      "Num timesteps: 92300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0922\n",
      "Last reward =  [-0.15585354]\n",
      "Reward buffer length =  92300\n",
      "Num timesteps: 92400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0971\n",
      "Last reward =  [-0.1831348]\n",
      "Reward buffer length =  92400\n",
      "Num timesteps: 92500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1330\n",
      "Last reward =  [-0.16647685]\n",
      "Reward buffer length =  92500\n",
      "Num timesteps: 92600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1383\n",
      "Last reward =  [-0.14231741]\n",
      "Reward buffer length =  92600\n",
      "Num timesteps: 92700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1536\n",
      "Last reward =  [-0.27327582]\n",
      "Reward buffer length =  92700\n",
      "Num timesteps: 92800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1627\n",
      "Last reward =  [-0.2986959]\n",
      "Reward buffer length =  92800\n",
      "Num timesteps: 92900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1626\n",
      "Last reward =  [-0.07568334]\n",
      "Reward buffer length =  92900\n",
      "Num timesteps: 93000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1260\n",
      "Last reward =  [-0.19599101]\n",
      "Reward buffer length =  93000\n",
      "Num timesteps: 93100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1306\n",
      "Last reward =  [-0.12268797]\n",
      "Reward buffer length =  93100\n",
      "Num timesteps: 93200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1502\n",
      "Last reward =  [-0.10030059]\n",
      "Reward buffer length =  93200\n",
      "Num timesteps: 93300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1596\n",
      "Last reward =  [-0.00452264]\n",
      "Reward buffer length =  93300\n",
      "Num timesteps: 93400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0220\n",
      "Last reward =  [-0.0086387]\n",
      "Reward buffer length =  93400\n",
      "Num timesteps: 93500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0557\n",
      "Last reward =  [-0.10879418]\n",
      "Reward buffer length =  93500\n",
      "Num timesteps: 93600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0750\n",
      "Last reward =  [-0.12798975]\n",
      "Reward buffer length =  93600\n",
      "Num timesteps: 93700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0817\n",
      "Last reward =  [-0.09493987]\n",
      "Reward buffer length =  93700\n",
      "Num timesteps: 93800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1192\n",
      "Last reward =  [-0.17972253]\n",
      "Reward buffer length =  93800\n",
      "Num timesteps: 93900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1259\n",
      "Last reward =  [-0.1591543]\n",
      "Reward buffer length =  93900\n",
      "Num timesteps: 94000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1348\n",
      "Last reward =  [-0.13442148]\n",
      "Reward buffer length =  94000\n",
      "Num timesteps: 94100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1627\n",
      "Last reward =  [-0.3246487]\n",
      "Reward buffer length =  94100\n",
      "Num timesteps: 94200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1618\n",
      "Last reward =  [-0.11418211]\n",
      "Reward buffer length =  94200\n",
      "Num timesteps: 94300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1763\n",
      "Last reward =  [-0.11160864]\n",
      "Reward buffer length =  94300\n",
      "Num timesteps: 94400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1285\n",
      "Last reward =  [-0.01364113]\n",
      "Reward buffer length =  94400\n",
      "Num timesteps: 94500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0891\n",
      "Last reward =  [-0.14413378]\n",
      "Reward buffer length =  94500\n",
      "Num timesteps: 94600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0958\n",
      "Last reward =  [-0.25268105]\n",
      "Reward buffer length =  94600\n",
      "Num timesteps: 94700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1304\n",
      "Last reward =  [-0.26144075]\n",
      "Reward buffer length =  94700\n",
      "Num timesteps: 94800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1389\n",
      "Last reward =  [-0.10276101]\n",
      "Reward buffer length =  94800\n",
      "Num timesteps: 94900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1723\n",
      "Last reward =  [-0.04250446]\n",
      "Reward buffer length =  94900\n",
      "Num timesteps: 95000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1988\n",
      "Last reward =  [-0.16116601]\n",
      "Reward buffer length =  95000\n",
      "Num timesteps: 95100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1285\n",
      "Last reward =  [-0.17848383]\n",
      "Reward buffer length =  95100\n",
      "Num timesteps: 95200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1457\n",
      "Last reward =  [0.06430079]\n",
      "Reward buffer length =  95200\n",
      "Num timesteps: 95300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1639\n",
      "Last reward =  [-0.21530026]\n",
      "Reward buffer length =  95300\n",
      "Num timesteps: 95400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1654\n",
      "Last reward =  [-0.14345777]\n",
      "Reward buffer length =  95400\n",
      "Num timesteps: 95500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1394\n",
      "Last reward =  [-0.20146649]\n",
      "Reward buffer length =  95500\n",
      "Num timesteps: 95600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1547\n",
      "Last reward =  [-0.02376699]\n",
      "Reward buffer length =  95600\n",
      "Num timesteps: 95700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1590\n",
      "Last reward =  [-0.04416654]\n",
      "Reward buffer length =  95700\n",
      "Num timesteps: 95800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0956\n",
      "Last reward =  [-0.16868341]\n",
      "Reward buffer length =  95800\n",
      "Num timesteps: 95900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1112\n",
      "Last reward =  [-0.14220572]\n",
      "Reward buffer length =  95900\n",
      "Num timesteps: 96000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1479\n",
      "Last reward =  [-0.2031245]\n",
      "Reward buffer length =  96000\n",
      "Num timesteps: 96100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1525\n",
      "Last reward =  [-0.07108524]\n",
      "Reward buffer length =  96100\n",
      "Num timesteps: 96200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1819\n",
      "Last reward =  [-0.21007667]\n",
      "Reward buffer length =  96200\n",
      "Num timesteps: 96300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0508\n",
      "Last reward =  [0.01771425]\n",
      "Reward buffer length =  96300\n",
      "Num timesteps: 96400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0280\n",
      "Last reward =  [-0.05439412]\n",
      "Reward buffer length =  96400\n",
      "Num timesteps: 96500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0652\n",
      "Last reward =  [-0.02911968]\n",
      "Reward buffer length =  96500\n",
      "Num timesteps: 96600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0856\n",
      "Last reward =  [-0.06740662]\n",
      "Reward buffer length =  96600\n",
      "Num timesteps: 96700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0871\n",
      "Last reward =  [-0.11103551]\n",
      "Reward buffer length =  96700\n",
      "Num timesteps: 96800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1312\n",
      "Last reward =  [-0.21173006]\n",
      "Reward buffer length =  96800\n",
      "Num timesteps: 96900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1459\n",
      "Last reward =  [-0.12382915]\n",
      "Reward buffer length =  96900\n",
      "Num timesteps: 97000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1580\n",
      "Last reward =  [-0.2080055]\n",
      "Reward buffer length =  97000\n",
      "Num timesteps: 97100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1827\n",
      "Last reward =  [-0.13311715]\n",
      "Reward buffer length =  97100\n",
      "Num timesteps: 97200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1906\n",
      "Last reward =  [-0.05125972]\n",
      "Reward buffer length =  97200\n",
      "Num timesteps: 97300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1476\n",
      "Last reward =  [-0.10886805]\n",
      "Reward buffer length =  97300\n",
      "Num timesteps: 97400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1785\n",
      "Last reward =  [-0.15983222]\n",
      "Reward buffer length =  97400\n",
      "Num timesteps: 97500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1831\n",
      "Last reward =  [-0.32386038]\n",
      "Reward buffer length =  97500\n",
      "Num timesteps: 97600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1699\n",
      "Last reward =  [-0.07447155]\n",
      "Reward buffer length =  97600\n",
      "Num timesteps: 97700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1558\n",
      "Last reward =  [-0.1646135]\n",
      "Reward buffer length =  97700\n",
      "Num timesteps: 97800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1736\n",
      "Last reward =  [-0.27839896]\n",
      "Reward buffer length =  97800\n",
      "Num timesteps: 97900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.2023\n",
      "Last reward =  [-0.21730492]\n",
      "Reward buffer length =  97900\n",
      "Num timesteps: 98000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1950\n",
      "Last reward =  [-0.0771005]\n",
      "Reward buffer length =  98000\n",
      "Num timesteps: 98100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1681\n",
      "Last reward =  [-0.02411893]\n",
      "Reward buffer length =  98100\n",
      "Num timesteps: 98200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0663\n",
      "Last reward =  [-0.0718857]\n",
      "Reward buffer length =  98200\n",
      "Num timesteps: 98300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0856\n",
      "Last reward =  [-0.07601961]\n",
      "Reward buffer length =  98300\n",
      "Num timesteps: 98400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0909\n",
      "Last reward =  [-0.11044358]\n",
      "Reward buffer length =  98400\n",
      "Num timesteps: 98500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1373\n",
      "Last reward =  [-0.09977003]\n",
      "Reward buffer length =  98500\n",
      "Num timesteps: 98600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1541\n",
      "Last reward =  [-0.11510551]\n",
      "Reward buffer length =  98600\n",
      "Num timesteps: 98700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1665\n",
      "Last reward =  [-0.31680346]\n",
      "Reward buffer length =  98700\n",
      "Num timesteps: 98800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1933\n",
      "Last reward =  [-0.05996143]\n",
      "Reward buffer length =  98800\n",
      "Num timesteps: 98900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1369\n",
      "Last reward =  [-0.10807073]\n",
      "Reward buffer length =  98900\n",
      "Num timesteps: 99000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1518\n",
      "Last reward =  [0.01049463]\n",
      "Reward buffer length =  99000\n",
      "Num timesteps: 99100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1852\n",
      "Last reward =  [-0.06254072]\n",
      "Reward buffer length =  99100\n",
      "Num timesteps: 99200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1897\n",
      "Last reward =  [-0.36681423]\n",
      "Reward buffer length =  99200\n",
      "Num timesteps: 99300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1810\n",
      "Last reward =  [-0.13703991]\n",
      "Reward buffer length =  99300\n",
      "Num timesteps: 99400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1889\n",
      "Last reward =  [-0.23116128]\n",
      "Reward buffer length =  99400\n",
      "Num timesteps: 99500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.2025\n",
      "Last reward =  [-0.15037398]\n",
      "Reward buffer length =  99500\n",
      "Num timesteps: 99600\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1364\n",
      "Last reward =  [-0.09347577]\n",
      "Reward buffer length =  99600\n",
      "Num timesteps: 99700\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1441\n",
      "Last reward =  [-0.1421888]\n",
      "Reward buffer length =  99700\n",
      "Num timesteps: 99800\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1560\n",
      "Last reward =  [-0.17384909]\n",
      "Reward buffer length =  99800\n",
      "Num timesteps: 99900\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1794\n",
      "Last reward =  [-0.12202598]\n",
      "Reward buffer length =  99900\n",
      "Num timesteps: 100000\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0818\n",
      "Last reward =  [-0.07261916]\n",
      "Reward buffer length =  100000\n",
      "Saving new best model to E:\\\\alpha-machine\\\\models\\\\forex\\\\oanda\\daily\\prod\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-8db0e708\\online\\model.zip\n",
      "Num timesteps: 100100\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.0822\n",
      "Last reward =  [-0.03786606]\n",
      "Reward buffer length =  100100\n",
      "Num timesteps: 100200\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1309\n",
      "Last reward =  [-0.10877044]\n",
      "Reward buffer length =  100200\n",
      "Num timesteps: 100300\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1473\n",
      "Last reward =  [-0.19737266]\n",
      "Reward buffer length =  100300\n",
      "Num timesteps: 100400\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1630\n",
      "Last reward =  [-0.24831302]\n",
      "Reward buffer length =  100400\n",
      "Num timesteps: 100500\n",
      "Best mean reward: 0.0229, Best mean reward step: 10900 Last mean reward per episode: -0.1979\n",
      "Last reward =  [-0.3103161]\n",
      "Reward buffer length =  100500\n",
      "End training online model...\n",
      "row_count=4871, start_row=3870, start_date=2017-12-17T22:00:00.000000000, end_row=4870, end_date=2021-10-27T21:00:00.000000000\n",
      "Data shape:(7, 1000, 4)\n",
      "Instruments:['EURUSD', 'USDJPY', 'GBPUSD', 'AUDUSD', 'USDCAD', 'USDCHF', 'NZDUSD'], lookack:30, random_episode_start:True, cash:1000.0, max_slippage_percent:0.01, lot_size:Micro, leverage:20, pip_size:[0.0001, 0.01, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001], pip_spread:[2, 2, 2, 2, 2, 2, 2], compute_position:long_and_short, compute_indicators:all, compute_reward:['log_returns'], verbose:False\n",
      "Model name:fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-f5e9cfea\n",
      "Using cuda device\n",
      "Start training model...\n",
      "Logging to E:\\\\alpha-machine\\\\logs\\\\forex\\fx_sb3_leverage_train_with_callback_with_random_episode_start_noise_ou-7-100000-1000-30-2-oanda-daily-on_algo.td3-comp_pos.long_and_short-comp_ind.all-comp_rew.[log_returns]-f5e9cfea_0\n",
      "Num timesteps: 100\n",
      "Best mean reward: -inf, Best mean reward step: 0 Last mean reward per episode: -0.0012\n",
      "Last reward =  [-0.01098468]\n",
      "Reward buffer length =  100\n",
      "Num timesteps: 200\n",
      "Best mean reward: -0.0012, Best mean reward step: 100 Last mean reward per episode: 0.0010\n",
      "Last reward =  [0.04076721]\n",
      "Reward buffer length =  200\n",
      "Num timesteps: 300\n",
      "Best mean reward: 0.0010, Best mean reward step: 200 Last mean reward per episode: -0.0028\n",
      "Last reward =  [0.03039387]\n",
      "Reward buffer length =  300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dcf30f6ad5c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_number_of_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_online_algorithm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_train_look_back_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_total_timesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_config_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-90d9b9e588db>\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(online_algorithm, train_look_back_period, total_timesteps, config_file)\u001b[0m\n\u001b[0;32m    137\u001b[0m                                                           verbose=v_callback_verbose)\n\u001b[0;32m    138\u001b[0m         v_online_model.learn(total_timesteps=total_timesteps, log_interval=1000, reset_num_timesteps=False,\n\u001b[1;32m--> 139\u001b[1;33m                              tb_log_name=v_model_name, callback=callback)\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         v_online_model.learn(total_timesteps=total_timesteps, log_interval=1000, reset_num_timesteps=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;31m# do as many gradients steps as steps performed during the rollout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 \u001b[0mgradient_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_steps\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_steps\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrollout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisode_timesteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_updates\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# Sample replay buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mreplay_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vec_normalize_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\buffers.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, batch_size, env)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mbatch_inds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_inds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_inds\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mVecNormalize\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mReplayBufferSamples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\buffers.py\u001b[0m in \u001b[0;36m_get_samples\u001b[1;34m(self, batch_inds, env)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_memory_usage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0mnext_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_inds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mnext_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_inds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\buffers.py\u001b[0m in \u001b[0;36m_normalize_obs\u001b[1;34m(obs, env)\u001b[0m\n\u001b[0;32m    141\u001b[0m     ) -> Union[np.ndarray, Dict[str, np.ndarray]]:\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0menv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_normalize.py\u001b[0m in \u001b[0;36mnormalize_obs\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    173\u001b[0m                     \u001b[0mobs_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_rms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[0mobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_rms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobs_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_normalize.py\u001b[0m in \u001b[0;36m_normalize_obs\u001b[1;34m(self, obs, obs_rms)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnormalized\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \"\"\"\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mobs_rms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_rms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_unnormalize_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_rms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRunningMeanStd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "v_config_file = '../config-oanda.ini'\n",
    "\n",
    "v_online_algorithm, v_number_of_trials, v_train_look_back_period, v_total_timesteps = get_train_params(\n",
    "    v_config_file)\n",
    "\n",
    "for i in range(v_number_of_trials):\n",
    "    run_trial(v_online_algorithm, v_train_look_back_period, v_total_timesteps, v_config_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49f9931575a98e33eb634a54fb9d36b4827a32ff215341f2cd4bc7c20fc79f25"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
